{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad668a2d91218f05",
   "metadata": {},
   "source": [
    "Report for Task A based on Deep Neural Network using H2O and python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f56677cbd1e69",
   "metadata": {},
   "source": [
    "This imports the h2o library and connects with the h2o server. The server has to be running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T16:10:28.844388Z",
     "start_time": "2025-05-09T16:10:22.334931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>22 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Europe/Belgrade</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.7</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 28 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>adama</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>5.988 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.1 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         22 secs\n",
       "H2O_cluster_timezone:       Europe/Belgrade\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.7\n",
       "H2O_cluster_version_age:    1 month and 28 days\n",
       "H2O_cluster_name:           adama\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    5.988 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.1 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "\n",
    "# switch to java 8 \"sdk use java 8.0.452-tem\"\n",
    "# java -jar h2o.jar\n",
    "h2o.init(ip=\"localhost\", port=\"54321\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715d524ed396b3c",
   "metadata": {},
   "source": [
    "Helper function to build and test deep neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980f5465d658ff8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T16:10:42.327317Z",
     "start_time": "2025-05-09T16:10:42.314281Z"
    }
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "# def run_experiment(dataset, features, target, hidden, nfolds, activation):\n",
    "#     train, test = dataset.split_frame(ratios=[0.8])\n",
    "#     dnn = H2ODeepLearningEstimator(activation=activation, hidden=hidden, nfolds=nfolds)\n",
    "#     dnn.train(x=features, y=target, training_frame=train, validation_frame=test)\n",
    "#     print(dnn.show())\n",
    "mean_error_metrics = []\n",
    "mse_metrics = []\n",
    "rmse_metrics = []\n",
    "\n",
    "def run_experiment(dataset, features, target, hidden, nfolds, activation):\n",
    "    train, test = dataset.split_frame(ratios=[0.8], seed=42)\n",
    "    dnn = H2ODeepLearningEstimator(activation=activation, hidden=hidden, nfolds=nfolds, seed=42, reproducible=True)\n",
    "    dnn.train(x=features, y=target, training_frame=train, validation_frame=test)\n",
    "    #print(dnn.mean_per_class_error(xval=True))\n",
    "    #print(dnn.run_time / 1000)\n",
    "    # print(type(dnn))\n",
    "    # print(dnn.mse())\n",
    "    # print(dnn.rmse())\n",
    "    print(dnn.show())\n",
    "    mean_error_metrics.append([activation, \"None\" if nfolds == 0 else f\"{nfolds}-folds\", hidden, \n",
    "                    f\"{dnn.mean_per_class_error(train=True) * 100}%\", \n",
    "                    f\"{dnn.mean_per_class_error(valid=True) * 100}%\", \n",
    "                    f\"{dnn.mean_per_class_error(xval=True) * 100}%\" if nfolds != 0 else \"-\", \n",
    "                    f\"{dnn.run_time / 1000} s\"])\n",
    "    mse_metrics.append([activation, \"None\" if nfolds == 0 else f\"{nfolds}-folds\", hidden, \n",
    "                    f\"{dnn.mse(train=True)}\", \n",
    "                    f\"{dnn.mse(valid=True)}\",\n",
    "                    f\"{dnn.mse(xval=True)}\" if nfolds != 0 else \"-\"])\n",
    "    rmse_metrics.append([activation, \"None\" if nfolds == 0 else f\"{nfolds}-folds\", hidden, \n",
    "                    f\"{dnn.rmse(train=True)}\", \n",
    "                    f\"{dnn.rmse(valid=True)}\",\n",
    "                    f\"{dnn.rmse(xval=True)}\" if nfolds != 0 else \"-\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc86cd36a81b9b3",
   "metadata": {},
   "source": [
    "Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97f58f98e0803f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T16:10:49.966345Z",
     "start_time": "2025-05-09T16:10:49.188433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "col_names = [\"party\", \"handicapped-infants\", \"water-project-cost-sharing\", \"adoption-of-the-budget-resolution\", \"physician-fee-freeze\", \"el-salvador-aid\", \"religious-groups-in-schools\", \"anti-satellite-test-ban\", \"aid-to-nicaraguan-contras\", \"mx-missile\", \"immigration\", \"synfuels-corporation-cutback\", \"education-spending\", \"superfund-right-to-sue\", \"crime\", \"duty-free-exports\", \"export-administration-act-south-africa\"]\n",
    "votes = h2o.import_file(path=\"datasets/votes/house-votes-84.data\", col_names=col_names)\n",
    "\n",
    "features = col_names[1:]\n",
    "target = \"party\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f075a28271db5",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [5,5,], cross folds = 0, activation function = \"rectifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc234a5e46427bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T16:10:55.932849Z",
     "start_time": "2025-05-09T16:10:54.488661Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2696756</td>\n",
       "<td>0.4383763</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0063685</td>\n",
       "<td>0.1814740</td>\n",
       "<td>0.5651113</td>\n",
       "<td>0.0637361</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0085497</td>\n",
       "<td>0.0160413</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0665404</td>\n",
       "<td>0.4950789</td>\n",
       "<td>0.9434190</td>\n",
       "<td>0.0718842</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0056995</td>\n",
       "<td>0.0080034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0622111</td>\n",
       "<td>0.4061062</td>\n",
       "<td>1.1627541</td>\n",
       "<td>0.6661279</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015364</td>\n",
       "<td>0.0003694</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6811179</td>\n",
       "<td>1.0909319</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.1625813</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02484122938261853\n",
       "RMSE: 0.1576110065402113\n",
       "LogLoss: 0.09519415971222477\n",
       "Mean Per-Class Error: 0.024566048837893498\n",
       "AUC: 0.9920197116799058\n",
       "AUCPR: 0.979104947040616\n",
       "Gini: 0.9840394233598115</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-3.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-3 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-3 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-3 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-3 .h2o-table th,\n",
       "#h2o-table-3 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-3 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-3\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47264731686597217</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>199.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.034</td>\n",
       "<td> (7.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>201.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0266</td>\n",
       "<td> (9.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.4726473</td>\n",
       "<td>0.9665428</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4726473</td>\n",
       "<td>0.9774436</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7138028</td>\n",
       "<td>0.9662577</td>\n",
       "<td>59.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6135051</td>\n",
       "<td>0.9733728</td>\n",
       "<td>64.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9472054</td>\n",
       "<td>0.9900990</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0624061</td>\n",
       "<td>1.0</td>\n",
       "<td>89.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.9951456</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4726473</td>\n",
       "<td>0.9448926</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6135051</td>\n",
       "<td>0.9708738</td>\n",
       "<td>64.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4726473</td>\n",
       "<td>0.9754340</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9768400</td>\n",
       "<td>205.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9768400</td>\n",
       "<td>82.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000033</td>\n",
       "<td>206.0</td>\n",
       "<td>237.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0624061</td>\n",
       "<td>132.0</td>\n",
       "<td>89.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.9951456</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.6212121</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000033</td>\n",
       "<td>1.0</td>\n",
       "<td>237.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0624061</td>\n",
       "<td>1.0</td>\n",
       "<td>89.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-5.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-5 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-5 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-5 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-5 .h2o-table th,\n",
       "#h2o-table-5 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.11 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9768400</td>\n",
       "<td>2.5103981</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.3787879</td>\n",
       "<td>0.3787879</td>\n",
       "<td>151.0398099</td>\n",
       "<td>151.0398099</td>\n",
       "<td>0.3739335</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9767884</td>\n",
       "<td>0.0</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3787879</td>\n",
       "<td>-100.0</td>\n",
       "<td>151.0398099</td>\n",
       "<td>0.3739335</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.2218935</td>\n",
       "<td>0.9745402</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5264646</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9750303</td>\n",
       "<td>0.9866667</td>\n",
       "<td>0.9762609</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.5606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>152.6464646</td>\n",
       "<td>0.5557517</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9349184</td>\n",
       "<td>2.4657688</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9647372</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9732105</td>\n",
       "<td>0.1969697</td>\n",
       "<td>0.7575758</td>\n",
       "<td>146.5768799</td>\n",
       "<td>151.0398099</td>\n",
       "<td>0.7478670</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.5091885</td>\n",
       "<td>2.2502296</td>\n",
       "<td>2.4468013</td>\n",
       "<td>0.8787879</td>\n",
       "<td>0.8162877</td>\n",
       "<td>0.9555556</td>\n",
       "<td>0.9348516</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9772727</td>\n",
       "<td>125.0229568</td>\n",
       "<td>144.6801347</td>\n",
       "<td>0.9481465</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0269081</td>\n",
       "<td>0.2259358</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0882353</td>\n",
       "<td>0.1625590</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7794791</td>\n",
       "<td>0.0227273</td>\n",
       "<td>1.0</td>\n",
       "<td>-77.4064171</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0042904</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0099692</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6505957</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0010400</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0023372</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5599494</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0004091</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006078</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4895138</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001415</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002622</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4347948</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000033</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000656</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3910647</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.03226976880377741\n",
       "RMSE: 0.17963788242956275\n",
       "LogLoss: 0.11697303422900067\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.990974755242864\n",
       "Gini: 0.9881602914389798</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-6.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-6 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-6 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-6 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-6 .h2o-table th,\n",
       "#h2o-table-6 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-6 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-6\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.30527271696447134</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>59.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0328</td>\n",
       "<td> (2.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>60.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.0309</td>\n",
       "<td> (3.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3052727</td>\n",
       "<td>0.9589041</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3052727</td>\n",
       "<td>0.9668508</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7972536</td>\n",
       "<td>0.9756098</td>\n",
       "<td>13.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3052727</td>\n",
       "<td>0.9690722</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9768400</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0184682</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9768400</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3052727</td>\n",
       "<td>0.9343435</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3052727</td>\n",
       "<td>0.9672131</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3052727</td>\n",
       "<td>0.9697177</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9768400</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9768400</td>\n",
       "<td>17.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000111</td>\n",
       "<td>61.0</td>\n",
       "<td>76.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0184682</td>\n",
       "<td>36.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9768400</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.4722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000111</td>\n",
       "<td>1.0</td>\n",
       "<td>76.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0184682</td>\n",
       "<td>1.0</td>\n",
       "<td>25.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.57 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.1958763</td>\n",
       "<td>0.9768400</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9768400</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9768400</td>\n",
       "<td>0.5277778</td>\n",
       "<td>0.5277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9752029</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9752642</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9767612</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.8632625</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9461041</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9672469</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.1147828</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.6064856</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8747440</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0090641</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0320871</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7027732</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0026242</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0045790</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5944327</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0007053</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014125</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5072239</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0005148</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005742</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4480051</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0001080</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003134</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3965463</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000111</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000444</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3556698</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-9.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-9 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-9 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-9 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-9 .h2o-table th,\n",
       "#h2o-table-9 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-9 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-9\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:47:33</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.169 sec</td>\n",
       "<td>17789 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.5934409</td>\n",
       "<td>1.2097308</td>\n",
       "<td>-0.4796095</td>\n",
       "<td>0.9613122</td>\n",
       "<td>0.9424013</td>\n",
       "<td>2.5212121</td>\n",
       "<td>0.0976331</td>\n",
       "<td>0.5805649</td>\n",
       "<td>1.1732796</td>\n",
       "<td>-0.4441512</td>\n",
       "<td>0.9704007</td>\n",
       "<td>0.9490134</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0824742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.235 sec</td>\n",
       "<td>10730 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.2637676</td>\n",
       "<td>0.2464865</td>\n",
       "<td>0.7076958</td>\n",
       "<td>0.9715909</td>\n",
       "<td>0.9423941</td>\n",
       "<td>2.4621212</td>\n",
       "<td>0.0710059</td>\n",
       "<td>0.2591862</td>\n",
       "<td>0.2349209</td>\n",
       "<td>0.7121708</td>\n",
       "<td>0.9744991</td>\n",
       "<td>0.9572636</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.288 sec</td>\n",
       "<td>10453 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.2227407</td>\n",
       "<td>0.1796701</td>\n",
       "<td>0.7915551</td>\n",
       "<td>0.9799941</td>\n",
       "<td>0.9558020</td>\n",
       "<td>2.4805871</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.2377195</td>\n",
       "<td>0.2000976</td>\n",
       "<td>0.7578744</td>\n",
       "<td>0.9785974</td>\n",
       "<td>0.9663337</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0515464</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.353 sec</td>\n",
       "<td>9588 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.2062927</td>\n",
       "<td>0.1531687</td>\n",
       "<td>0.8212030</td>\n",
       "<td>0.9846646</td>\n",
       "<td>0.9688582</td>\n",
       "<td>2.5234958</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.2191439</td>\n",
       "<td>0.1730541</td>\n",
       "<td>0.7942358</td>\n",
       "<td>0.9817851</td>\n",
       "<td>0.9715097</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.399 sec</td>\n",
       "<td>10059 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1923995</td>\n",
       "<td>0.1349478</td>\n",
       "<td>0.8444750</td>\n",
       "<td>0.9865953</td>\n",
       "<td>0.9676451</td>\n",
       "<td>2.4852941</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.2197891</td>\n",
       "<td>0.1737430</td>\n",
       "<td>0.7930224</td>\n",
       "<td>0.9831512</td>\n",
       "<td>0.9736716</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.435 sec</td>\n",
       "<td>10787 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1816193</td>\n",
       "<td>0.1221948</td>\n",
       "<td>0.8614149</td>\n",
       "<td>0.9886180</td>\n",
       "<td>0.9702942</td>\n",
       "<td>2.4752525</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.2092738</td>\n",
       "<td>0.1572064</td>\n",
       "<td>0.8123533</td>\n",
       "<td>0.9854281</td>\n",
       "<td>0.9770254</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.469 sec</td>\n",
       "<td>11375 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1734851</td>\n",
       "<td>0.1130596</td>\n",
       "<td>0.8735507</td>\n",
       "<td>0.9899419</td>\n",
       "<td>0.9748364</td>\n",
       "<td>2.5024105</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.1974501</td>\n",
       "<td>0.1391744</td>\n",
       "<td>0.8329579</td>\n",
       "<td>0.9895264</td>\n",
       "<td>0.9824451</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.503 sec</td>\n",
       "<td>11859 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1663014</td>\n",
       "<td>0.1051287</td>\n",
       "<td>0.8838058</td>\n",
       "<td>0.9909532</td>\n",
       "<td>0.9763613</td>\n",
       "<td>2.5010571</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1936989</td>\n",
       "<td>0.1350823</td>\n",
       "<td>0.8392446</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9847051</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.534 sec</td>\n",
       "<td>12315 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1635421</td>\n",
       "<td>0.1016475</td>\n",
       "<td>0.8876297</td>\n",
       "<td>0.9913761</td>\n",
       "<td>0.9747097</td>\n",
       "<td>2.4752525</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1925965</td>\n",
       "<td>0.1376056</td>\n",
       "<td>0.8410693</td>\n",
       "<td>0.9913479</td>\n",
       "<td>0.9867603</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:34</td>\n",
       "<td> 0.563 sec</td>\n",
       "<td>12803 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1576110</td>\n",
       "<td>0.0951942</td>\n",
       "<td>0.8956325</td>\n",
       "<td>0.9920197</td>\n",
       "<td>0.9791049</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1796379</td>\n",
       "<td>0.1169730</td>\n",
       "<td>0.8617367</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9909748</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-10.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-10 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-10 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-10 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-10 .h2o-table th,\n",
       "#h2o-table-10 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-10 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-10\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.n</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0449175</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.8667819</td>\n",
       "<td>0.8667819</td>\n",
       "<td>0.0389337</td></tr>\n",
       "<tr><td>el-salvador-aid.?</td>\n",
       "<td>0.6971414</td>\n",
       "<td>0.6971414</td>\n",
       "<td>0.0313138</td></tr>\n",
       "<tr><td>water-project-cost-sharing.y</td>\n",
       "<td>0.6769725</td>\n",
       "<td>0.6769725</td>\n",
       "<td>0.0304079</td></tr>\n",
       "<tr><td>physician-fee-freeze.y</td>\n",
       "<td>0.6222080</td>\n",
       "<td>0.6222080</td>\n",
       "<td>0.0279480</td></tr>\n",
       "<tr><td>crime.n</td>\n",
       "<td>0.6218806</td>\n",
       "<td>0.6218806</td>\n",
       "<td>0.0279333</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.5932469</td>\n",
       "<td>0.5932469</td>\n",
       "<td>0.0266472</td></tr>\n",
       "<tr><td>el-salvador-aid.n</td>\n",
       "<td>0.5846873</td>\n",
       "<td>0.5846873</td>\n",
       "<td>0.0262627</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.5750024</td>\n",
       "<td>0.5750024</td>\n",
       "<td>0.0258277</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.n</td>\n",
       "<td>0.5583872</td>\n",
       "<td>0.5583872</td>\n",
       "<td>0.0250814</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  -----------------------  -------------------\n",
       "    1        64       Input      0.0\n",
       "    2        5        Rectifier  0.0        0.0   0.0   0.26967561226956605    0.4383763074874878     0.0         -0.0063685370201710615  0.181473970413208    0.5651113056292081       0.06373605132102966\n",
       "    3        5        Rectifier  0.0        0.0   0.0   0.00854968486353755    0.0160413458943367     0.0         -0.06654038399457932    0.4950789213180542   0.9434190147898665       0.07188418507575989\n",
       "    4        5        Rectifier  0.0        0.0   0.0   0.005699532681610435   0.008003383874893188   0.0         0.06221109122037888     0.40610623359680176  1.1627540761348671       0.6661279201507568\n",
       "    5        2        Softmax               0.0   0.0   0.0015363607555627823  0.0003694383194670081  0.0         1.6811179116368293      1.0909318923950195   -1.3877787807814457e-17  0.16258132457733154\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02484122938261853\n",
       "RMSE: 0.1576110065402113\n",
       "LogLoss: 0.09519415971222477\n",
       "Mean Per-Class Error: 0.024566048837893498\n",
       "AUC: 0.9920197116799058\n",
       "AUCPR: 0.979104947040616\n",
       "Gini: 0.9840394233598115\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.47264731686597217\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    199         7             0.034    (7.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       201         137           0.0266   (9.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.472647     0.966543  66\n",
       "max f2                       0.472647     0.977444  66\n",
       "max f0point5                 0.713803     0.966258  59\n",
       "max accuracy                 0.613505     0.973373  64\n",
       "max precision                0.947205     0.990099  32\n",
       "max recall                   0.0624061    1         89\n",
       "max specificity              0.97684      0.995146  0\n",
       "max absolute_mcc             0.472647     0.944893  66\n",
       "max min_per_class_accuracy   0.613505     0.970874  64\n",
       "max mean_per_class_accuracy  0.472647     0.975434  66\n",
       "max tns                      0.97684      205       0\n",
       "max fns                      0.97684      82        0\n",
       "max fps                      3.33231e-06  206       237\n",
       "max tps                      0.0624061    132       89\n",
       "max tnr                      0.97684      0.995146  0\n",
       "max fnr                      0.97684      0.621212  0\n",
       "max fpr                      3.33231e-06  1         237\n",
       "max tpr                      0.0624061    1         89\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.11 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.150888                    0.97684            2.5104    2.5104             0.980392         0.97684      0.980392                    0.97684             0.378788        0.378788                   151.04    151.04             0.373934\n",
       "2        0.150888                    0.976788           0         2.5104             0                0            0.980392                    0.97684             0               0.378788                   -100      151.04             0.373934\n",
       "3        0.221893                    0.97454            2.56061   2.52646            1                0.97503      0.986667                    0.976261            0.181818        0.560606                   156.061   152.646            0.555752\n",
       "4        0.301775                    0.934918           2.46577   2.5104             0.962963         0.964737     0.980392                    0.97321             0.19697         0.757576                   146.577   151.04             0.747867\n",
       "5        0.399408                    0.509188           2.25023   2.4468             0.878788         0.816288     0.955556                    0.934852            0.219697        0.977273                   125.023   144.68             0.948147\n",
       "6        0.5                         0.0269081          0.225936  2                  0.0882353        0.162559     0.781065                    0.779479            0.0227273       1                          -77.4064  100                0.820388\n",
       "7        0.600592                    0.0042904          0         1.66502            0                0.00996919   0.650246                    0.650596            0               1                          -100      66.5025            0.65534\n",
       "8        0.698225                    0.00104005         0         1.4322             0                0.00233717   0.559322                    0.559949            0               1                          -100      43.2203            0.495146\n",
       "9        0.798817                    0.000409113        0         1.25185            0                0.000607835  0.488889                    0.489514            0               1                          -100      25.1852            0.330097\n",
       "10       0.899408                    0.000141454        0         1.11184            0                0.000262183  0.434211                    0.434795            0               1                          -100      11.1842            0.165049\n",
       "11       1                           3.33231e-06        0         1                  0                6.5582e-05   0.390533                    0.391065            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.03226976880377741\n",
       "RMSE: 0.17963788242956275\n",
       "LogLoss: 0.11697303422900067\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.990974755242864\n",
       "Gini: 0.9881602914389798\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.30527271696447134\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    59          2             0.0328   (2.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       60          37            0.0309   (3.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.305273     0.958904  18\n",
       "max f2                       0.305273     0.966851  18\n",
       "max f0point5                 0.797254     0.97561   13\n",
       "max accuracy                 0.305273     0.969072  18\n",
       "max precision                0.97684      1         0\n",
       "max recall                   0.0184682    1         25\n",
       "max specificity              0.97684      1         0\n",
       "max absolute_mcc             0.305273     0.934344  18\n",
       "max min_per_class_accuracy   0.305273     0.967213  18\n",
       "max mean_per_class_accuracy  0.305273     0.969718  18\n",
       "max tns                      0.97684      61        0\n",
       "max fns                      0.97684      17        0\n",
       "max fps                      1.10789e-05  61        76\n",
       "max tps                      0.0184682    36        25\n",
       "max tnr                      0.97684      1         0\n",
       "max fnr                      0.97684      0.472222  0\n",
       "max fpr                      1.10789e-05  1         76\n",
       "max tpr                      0.0184682    1         25\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.57 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.195876                    0.97684            2.69444   2.69444            1                0.97684      1                           0.97684             0.527778        0.527778                   169.444   169.444            0.527778\n",
       "2        0.206186                    0.975203           2.69444   2.69444            1                0.975264     1                           0.976761            0.0277778       0.555556                   169.444   169.444            0.555556\n",
       "3        0.298969                    0.863263           2.69444   2.69444            1                0.946104     1                           0.967247            0.25            0.805556                   169.444   169.444            0.805556\n",
       "4        0.402062                    0.114783           1.61667   2.41809            0.6              0.606486     0.897436                    0.874744            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "5        0.505155                    0.00906409         0.269444  1.97959            0.1              0.0320871    0.734694                    0.702773            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "6        0.597938                    0.00262423         0         1.67241            0                0.00457901   0.62069                     0.594433            0               1                          -100      67.2414            0.639344\n",
       "7        0.701031                    0.000705253        0         1.42647            0                0.00141252   0.529412                    0.507224            0               1                          -100      42.6471            0.47541\n",
       "8        0.793814                    0.000514769        0         1.25974            0                0.000574202  0.467532                    0.448005            0               1                          -100      25.974             0.327869\n",
       "9        0.896907                    0.000108034        0         1.11494            0                0.000313366  0.413793                    0.396546            0               1                          -100      11.4943            0.163934\n",
       "10       1                           1.10789e-05        0         1                  0                4.44473e-05  0.371134                    0.35567             0               1                          -100      0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:47:33  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:47:34  0.169 sec   17789 obs/sec     1         1             338        0.593441         1.20973             -0.47961       0.961312        0.942401           2.52121          0.0976331                        0.580565           1.17328               -0.444151        0.970401          0.949013             2.69444            0.0824742\n",
       "    2025-05-26 14:47:34  0.235 sec   10730 obs/sec     2         2             676        0.263768         0.246487            0.707696       0.971591        0.942394           2.46212          0.0710059                        0.259186           0.234921              0.712171         0.974499          0.957264             2.69444            0.0618557\n",
       "    2025-05-26 14:47:34  0.288 sec   10453 obs/sec     3         3             1014       0.222741         0.17967             0.791555       0.979994        0.955802           2.48059          0.0502959                        0.237719           0.200098              0.757874         0.978597          0.966334             2.69444            0.0515464\n",
       "    2025-05-26 14:47:34  0.353 sec   9588 obs/sec      4         4             1352       0.206293         0.153169            0.821203       0.984665        0.968858           2.5235           0.0443787                        0.219144           0.173054              0.794236         0.981785          0.97151              2.69444            0.0412371\n",
       "    2025-05-26 14:47:34  0.399 sec   10059 obs/sec     5         5             1690       0.1924           0.134948            0.844475       0.986595        0.967645           2.48529          0.0414201                        0.219789           0.173743              0.793022         0.983151          0.973672             2.69444            0.0412371\n",
       "    2025-05-26 14:47:34  0.435 sec   10787 obs/sec     6         6             2028       0.181619         0.122195            0.861415       0.988618        0.970294           2.47525          0.035503                         0.209274           0.157206              0.812353         0.985428          0.977025             2.69444            0.0412371\n",
       "    2025-05-26 14:47:34  0.469 sec   11375 obs/sec     7         7             2366       0.173485         0.11306             0.873551       0.989942        0.974836           2.50241          0.0325444                        0.19745            0.139174              0.832958         0.989526          0.982445             2.69444            0.0412371\n",
       "    2025-05-26 14:47:34  0.503 sec   11859 obs/sec     8         8             2704       0.166301         0.105129            0.883806       0.990953        0.976361           2.50106          0.0266272                        0.193699           0.135082              0.839245         0.990437          0.984705             2.69444            0.0412371\n",
       "    2025-05-26 14:47:34  0.534 sec   12315 obs/sec     9         9             3042       0.163542         0.101648            0.88763        0.991376        0.97471            2.47525          0.0236686                        0.192596           0.137606              0.841069         0.991348          0.98676              2.69444            0.0412371\n",
       "    2025-05-26 14:47:34  0.563 sec   12803 obs/sec     10        10            3380       0.157611         0.0951942           0.895632       0.99202         0.979105           2.5104           0.0266272                        0.179638           0.116973              0.861737         0.99408           0.990975             2.69444            0.0309278\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.n                              1.0                    1.0                  0.044917497425805995\n",
       "synfuels-corporation-cutback.n                      0.8667819499969482     0.8667819499969482   0.038933676007723024\n",
       "el-salvador-aid.?                                   0.6971414089202881     0.6971414089202881   0.031313847440599805\n",
       "water-project-cost-sharing.y                        0.676972508430481      0.676972508430481    0.030407910904767556\n",
       "physician-fee-freeze.y                              0.6222079992294312     0.6222079992294312   0.027948026203703874\n",
       "crime.n                                             0.6218805909156799     0.6218805909156799   0.027933319841613766\n",
       "adoption-of-the-budget-resolution.y                 0.5932469367980957     0.5932469367980957   0.026647167756495758\n",
       "el-salvador-aid.n                                   0.5846872925758362     0.5846872925758362   0.026262689959176598\n",
       "aid-to-nicaraguan-contras.y                         0.5750024318695068     0.5750024318695068   0.02582767025333076\n",
       "adoption-of-the-budget-resolution.n                 0.5583871603012085     0.5583871603012085   0.025081353835432654\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[5,5,5], nfolds=0, activation=\"rectifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f147988128567ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bebcdcbc37cf69c5",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [20,20,20], cross folds = 0, activation function = \"rectifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ddd9c4568e0a57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:52:17.276795Z",
     "start_time": "2025-05-09T14:52:16.628473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_22\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-11.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-11 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-11 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-11 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-11 .h2o-table th,\n",
       "#h2o-table-11 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-11 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-11\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2607023</td>\n",
       "<td>0.4345999</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006352</td>\n",
       "<td>0.1590263</td>\n",
       "<td>0.5068950</td>\n",
       "<td>0.0374615</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042542</td>\n",
       "<td>0.0121036</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0045247</td>\n",
       "<td>0.2219957</td>\n",
       "<td>1.0009819</td>\n",
       "<td>0.0253099</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0524505</td>\n",
       "<td>0.2167541</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0091217</td>\n",
       "<td>0.2140646</td>\n",
       "<td>0.9964018</td>\n",
       "<td>0.0189424</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0535996</td>\n",
       "<td>0.2165443</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0369953</td>\n",
       "<td>1.1526084</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.0234636</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.014514370855168185\n",
       "RMSE: 0.12047560273834776\n",
       "LogLoss: 0.058711462923311385\n",
       "Mean Per-Class Error: 0.01379082082965578\n",
       "AUC: 0.9970947337452192\n",
       "AUCPR: 0.9939040192884351\n",
       "Gini: 0.9941894674904383</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-12.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-12 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-12 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-12 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-12 .h2o-table th,\n",
       "#h2o-table-12 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-12 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-12\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8375846872799153</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>205.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0049</td>\n",
       "<td> (1.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>3.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.0227</td>\n",
       "<td> (3.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>208.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0118</td>\n",
       "<td> (4.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-13.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-13 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-13 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-13 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-13 .h2o-table th,\n",
       "#h2o-table-13 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-13 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-13\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.8375847</td>\n",
       "<td>0.9847328</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4706957</td>\n",
       "<td>0.9909910</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8375847</td>\n",
       "<td>0.9892638</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8375847</td>\n",
       "<td>0.9881657</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9990386</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.4706957</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9990386</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8375847</td>\n",
       "<td>0.9751477</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7822413</td>\n",
       "<td>0.9848485</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6217808</td>\n",
       "<td>0.9865034</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9990386</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9990386</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000003</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.4706957</td>\n",
       "<td>132.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9990386</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9990386</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000003</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.4706957</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-14.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-14 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-14 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-14 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-14 .h2o-table th,\n",
       "#h2o-table-14 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-14 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-14\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 40.39 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.9989028</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9989408</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9989408</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0454545</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0454545</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9985975</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987684</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9989162</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9982394</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984174</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987348</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9981990</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982263</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986259</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9980104</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981822</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985476</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9968728</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974695</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980085</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9947261</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9959971</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973381</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2100592</td>\n",
       "<td>0.9933801</td>\n",
       "<td>2.4325758</td>\n",
       "<td>2.5245412</td>\n",
       "<td>0.95</td>\n",
       "<td>0.9938354</td>\n",
       "<td>0.9859155</td>\n",
       "<td>0.9963514</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.5303030</td>\n",
       "<td>143.2575758</td>\n",
       "<td>152.4541187</td>\n",
       "<td>0.5254487</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9821689</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5355021</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9878688</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9937733</td>\n",
       "<td>0.2348485</td>\n",
       "<td>0.7651515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.5899779</td>\n",
       "<td>2.3278237</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9051039</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9720986</td>\n",
       "<td>0.2272727</td>\n",
       "<td>0.9924242</td>\n",
       "<td>132.7823691</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0187285</td>\n",
       "<td>0.0753119</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.1493191</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.8065690</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0012320</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0056506</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6724250</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0002897</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006742</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5784938</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8076923</td>\n",
       "<td>0.0000653</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2380952</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001412</td>\n",
       "<td>0.4835165</td>\n",
       "<td>0.5001090</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.8095238</td>\n",
       "<td>0.3155340</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000176</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000376</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4491149</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000053</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.4039382</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.02548361499263075\n",
       "RMSE: 0.1596358825346944\n",
       "LogLoss: 0.09535819007322252\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.9903601378148524\n",
       "Gini: 0.9881602914389798</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-15.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-15 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-15 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-15 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-15 .h2o-table th,\n",
       "#h2o-table-15 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-15 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-15\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6199494827109913</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0164</td>\n",
       "<td> (1.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-16.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-16 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-16 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-16 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-16 .h2o-table th,\n",
       "#h2o-table-16 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-16 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-16\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6199495</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.6199495</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6199495</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6199495</td>\n",
       "<td>0.9793814</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9984458</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0296342</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9984458</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6199495</td>\n",
       "<td>0.9558288</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6199495</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6199495</td>\n",
       "<td>0.9779144</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9984458</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9984458</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000003</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0296342</td>\n",
       "<td>36.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9984458</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9984458</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000003</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0296342</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-17.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-17 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-17 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-17 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-17 .h2o-table th,\n",
       "#h2o-table-17 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-17 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-17\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.68 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9982408</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984458</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984458</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9982323</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982323</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983035</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9981882</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983035</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0833333</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9977903</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981822</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982732</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9976814</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9977157</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981617</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9972703</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9975060</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978338</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9954382</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9963730</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973469</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9933456</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9941355</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9965440</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.8797134</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9641658</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9864956</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.2093667</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.6588167</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.9024754</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0060940</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0334117</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7251154</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0018932</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0035232</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6131442</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0004059</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0009844</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5231207</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0001194</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002390</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4620047</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000414</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000896</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4089110</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000070</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3667559</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-18.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-18 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-18 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-18 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-18 .h2o-table th,\n",
       "#h2o-table-18 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-18 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-18\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.034 sec</td>\n",
       "<td>42250 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2442084</td>\n",
       "<td>0.1914721</td>\n",
       "<td>0.7494390</td>\n",
       "<td>0.9782657</td>\n",
       "<td>0.9632222</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0739645</td>\n",
       "<td>0.2653601</td>\n",
       "<td>0.2668435</td>\n",
       "<td>0.6982952</td>\n",
       "<td>0.9599271</td>\n",
       "<td>0.9498725</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0824742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.077 sec</td>\n",
       "<td>20484 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1991910</td>\n",
       "<td>0.1337020</td>\n",
       "<td>0.8333015</td>\n",
       "<td>0.9878641</td>\n",
       "<td>0.9776065</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0473373</td>\n",
       "<td>0.2442234</td>\n",
       "<td>0.2079910</td>\n",
       "<td>0.7444442</td>\n",
       "<td>0.9763206</td>\n",
       "<td>0.9681289</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0721649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.112 sec</td>\n",
       "<td>18777 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1667623</td>\n",
       "<td>0.1023519</td>\n",
       "<td>0.8831609</td>\n",
       "<td>0.9911739</td>\n",
       "<td>0.9799595</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.2209233</td>\n",
       "<td>0.1727135</td>\n",
       "<td>0.7908807</td>\n",
       "<td>0.9840619</td>\n",
       "<td>0.9771650</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.146 sec</td>\n",
       "<td>18026 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1548635</td>\n",
       "<td>0.0900348</td>\n",
       "<td>0.8992394</td>\n",
       "<td>0.9926817</td>\n",
       "<td>0.9842176</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.2063223</td>\n",
       "<td>0.1460797</td>\n",
       "<td>0.8176089</td>\n",
       "<td>0.9867942</td>\n",
       "<td>0.9804180</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0515464</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.185 sec</td>\n",
       "<td>16900 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1457774</td>\n",
       "<td>0.0807554</td>\n",
       "<td>0.9107162</td>\n",
       "<td>0.9939688</td>\n",
       "<td>0.9873278</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1937603</td>\n",
       "<td>0.1326955</td>\n",
       "<td>0.8391427</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9854463</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.225 sec</td>\n",
       "<td>16354 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1469839</td>\n",
       "<td>0.0811612</td>\n",
       "<td>0.9092322</td>\n",
       "<td>0.9949250</td>\n",
       "<td>0.9889383</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.2147133</td>\n",
       "<td>0.1613537</td>\n",
       "<td>0.8024719</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9849707</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.268 sec</td>\n",
       "<td>15668 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1302942</td>\n",
       "<td>0.0669045</td>\n",
       "<td>0.9286749</td>\n",
       "<td>0.9964695</td>\n",
       "<td>0.9930110</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1734686</td>\n",
       "<td>0.1102418</td>\n",
       "<td>0.8710703</td>\n",
       "<td>0.9931694</td>\n",
       "<td>0.9888850</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.314 sec</td>\n",
       "<td>15022 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1257635</td>\n",
       "<td>0.0626863</td>\n",
       "<td>0.9335490</td>\n",
       "<td>0.9968005</td>\n",
       "<td>0.9936383</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1701342</td>\n",
       "<td>0.1075819</td>\n",
       "<td>0.8759793</td>\n",
       "<td>0.9931694</td>\n",
       "<td>0.9884437</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.356 sec</td>\n",
       "<td>14625 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1352762</td>\n",
       "<td>0.0704332</td>\n",
       "<td>0.9231161</td>\n",
       "<td>0.9964328</td>\n",
       "<td>0.9920966</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.2001105</td>\n",
       "<td>0.1420475</td>\n",
       "<td>0.8284263</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:42</td>\n",
       "<td> 0.399 sec</td>\n",
       "<td>14322 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1204756</td>\n",
       "<td>0.0587115</td>\n",
       "<td>0.9390196</td>\n",
       "<td>0.9970947</td>\n",
       "<td>0.9939040</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1596359</td>\n",
       "<td>0.0953582</td>\n",
       "<td>0.8908127</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-19.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-19 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-19 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-19 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-19 .h2o-table th,\n",
       "#h2o-table-19 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-19 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-19\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>el-salvador-aid.?</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0269992</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.9807851</td>\n",
       "<td>0.9807851</td>\n",
       "<td>0.0264804</td></tr>\n",
       "<tr><td>crime.?</td>\n",
       "<td>0.9742751</td>\n",
       "<td>0.9742751</td>\n",
       "<td>0.0263046</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9653293</td>\n",
       "<td>0.9653293</td>\n",
       "<td>0.0260631</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.9524176</td>\n",
       "<td>0.9524176</td>\n",
       "<td>0.0257145</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.?</td>\n",
       "<td>0.9314176</td>\n",
       "<td>0.9314176</td>\n",
       "<td>0.0251475</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9299356</td>\n",
       "<td>0.9299356</td>\n",
       "<td>0.0251075</td></tr>\n",
       "<tr><td>superfund-right-to-sue.y</td>\n",
       "<td>0.9285814</td>\n",
       "<td>0.9285814</td>\n",
       "<td>0.0250709</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.y</td>\n",
       "<td>0.8764246</td>\n",
       "<td>0.8764246</td>\n",
       "<td>0.0236627</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.8569631</td>\n",
       "<td>0.8569631</td>\n",
       "<td>0.0231373</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_22\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight           weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  --------------------  ----------  --------------------  -------------------  ----------------------  --------------------\n",
       "    1        64       Input      0.0\n",
       "    2        20       Rectifier  0.0        0.0   0.0   0.2607023372629101    0.4345998764038086    0.0         0.000635204364607489  0.15902632474899292  0.5068950222268198      0.0374615341424942\n",
       "    3        20       Rectifier  0.0        0.0   0.0   0.004254248169454513  0.012103579938411713  0.0         0.004524674203203176  0.22199571132659912  1.0009818604902923      0.025309868156909943\n",
       "    4        20       Rectifier  0.0        0.0   0.0   0.052450510103553824  0.21675407886505127   0.0         0.009121749889745843  0.2140645980834961   0.9964017500557858      0.018942423164844513\n",
       "    5        2        Softmax               0.0   0.0   0.05359956882020924   0.2165442705154419    0.0         0.03699527545832097   1.1526083946228027   -6.938893903907228e-18  0.023463621735572815\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.014514370855168185\n",
       "RMSE: 0.12047560273834776\n",
       "LogLoss: 0.058711462923311385\n",
       "Mean Per-Class Error: 0.01379082082965578\n",
       "AUC: 0.9970947337452192\n",
       "AUCPR: 0.9939040192884351\n",
       "Gini: 0.9941894674904383\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8375846872799153\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    205         1             0.0049   (1.0/206.0)\n",
       "republican  3           129           0.0227   (3.0/132.0)\n",
       "Total       208         130           0.0118   (4.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.837585     0.984733  91\n",
       "max f2                       0.470696     0.990991  99\n",
       "max f0point5                 0.837585     0.989264  91\n",
       "max accuracy                 0.837585     0.988166  91\n",
       "max precision                0.999039     1         0\n",
       "max recall                   0.470696     1         99\n",
       "max specificity              0.999039     1         0\n",
       "max absolute_mcc             0.837585     0.975148  91\n",
       "max min_per_class_accuracy   0.782241     0.984848  94\n",
       "max mean_per_class_accuracy  0.621781     0.986503  96\n",
       "max tns                      0.999039     206       0\n",
       "max fns                      0.999039     131       0\n",
       "max fps                      3.32293e-07  206       269\n",
       "max tps                      0.470696     132       99\n",
       "max tnr                      0.999039     1         0\n",
       "max fnr                      0.999039     0.992424  0\n",
       "max fpr                      3.32293e-07  1         269\n",
       "max tpr                      0.470696     1         99\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 40.39 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0177515                   0.998903           2.56061    2.56061            1                0.998941     1                           0.998941            0.0454545       0.0454545                  156.061   156.061            0.0454545\n",
       "2        0.0207101                   0.998598           2.56061    2.56061            1                0.998768     1                           0.998916            0.00757576      0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.998239           2.56061    2.56061            1                0.998417     1                           0.998735            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.998199           2.56061    2.56061            1                0.998226     1                           0.998626            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.99801            2.56061    2.56061            1                0.998182     1                           0.998548            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.996873           2.56061    2.56061            1                0.99747      1                           0.998009            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.994726           2.56061    2.56061            1                0.995997     1                           0.997338            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.210059                    0.99338            2.43258    2.52454            0.95             0.993835     0.985915                    0.996351            0.143939        0.530303                   143.258   152.454            0.525449\n",
       "9        0.301775                    0.982169           2.56061    2.5355             1                0.987869     0.990196                    0.993773            0.234848        0.765152                   156.061   153.55             0.760297\n",
       "10       0.399408                    0.589978           2.32782    2.48474            0.909091         0.905104     0.97037                     0.972099            0.227273        0.992424                   132.782   148.474            0.973007\n",
       "11       0.5                         0.0187285          0.0753119  2                  0.0294118        0.149319     0.781065                    0.806569            0.00757576      1                          -92.4688  100                0.820388\n",
       "12       0.600592                    0.00123204         0          1.66502            0                0.00565062   0.650246                    0.672425            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.000289717        0          1.4322             0                0.000674166  0.559322                    0.578494            0               1                          -100      43.2203            0.495146\n",
       "14       0.807692                    6.53372e-05        0          1.2381             0                0.000141164  0.483516                    0.500109            0               1                          -100      23.8095            0.315534\n",
       "15       0.899408                    1.75992e-05        0          1.11184            0                3.75604e-05  0.434211                    0.449115            0               1                          -100      11.1842            0.165049\n",
       "16       1                           3.32293e-07        0          1                  0                5.32973e-06  0.390533                    0.403938            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.02548361499263075\n",
       "RMSE: 0.1596358825346944\n",
       "LogLoss: 0.09535819007322252\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.9903601378148524\n",
       "Gini: 0.9881602914389798\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6199494827109913\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    60          1             0.0164   (1.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       61          36            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.619949     0.972222  32\n",
       "max f2                       0.619949     0.972222  32\n",
       "max f0point5                 0.619949     0.972222  32\n",
       "max accuracy                 0.619949     0.979381  32\n",
       "max precision                0.998446     1         0\n",
       "max recall                   0.0296342    1         39\n",
       "max specificity              0.998446     1         0\n",
       "max absolute_mcc             0.619949     0.955829  32\n",
       "max min_per_class_accuracy   0.619949     0.972222  32\n",
       "max mean_per_class_accuracy  0.619949     0.977914  32\n",
       "max tns                      0.998446     61        0\n",
       "max fns                      0.998446     35        0\n",
       "max fps                      3.32293e-07  61        91\n",
       "max tps                      0.0296342    36        39\n",
       "max tnr                      0.998446     1         0\n",
       "max fnr                      0.998446     0.972222  0\n",
       "max fpr                      3.32293e-07  1         91\n",
       "max tpr                      0.0296342    1         39\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.68 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0103093                   0.998241           2.69444   2.69444            1                0.998446     1                           0.998446            0.0277778       0.0277778                  169.444   169.444            0.0277778\n",
       "2        0.0309278                   0.998232           2.69444   2.69444            1                0.998232     1                           0.998303            0.0555556       0.0833333                  169.444   169.444            0.0833333\n",
       "3        0.0309278                   0.998188           0         2.69444            0                0            1                           0.998303            0               0.0833333                  -100      169.444            0.0833333\n",
       "4        0.0412371                   0.99779            2.69444   2.69444            1                0.998182     1                           0.998273            0.0277778       0.111111                   169.444   169.444            0.111111\n",
       "5        0.0515464                   0.997681           2.69444   2.69444            1                0.997716     1                           0.998162            0.0277778       0.138889                   169.444   169.444            0.138889\n",
       "6        0.103093                    0.99727            2.69444   2.69444            1                0.997506     1                           0.997834            0.138889        0.277778                   169.444   169.444            0.277778\n",
       "7        0.154639                    0.995438           2.69444   2.69444            1                0.996373     1                           0.997347            0.138889        0.416667                   169.444   169.444            0.416667\n",
       "8        0.206186                    0.993346           2.69444   2.69444            1                0.994136     1                           0.996544            0.138889        0.555556                   169.444   169.444            0.555556\n",
       "9        0.298969                    0.879713           2.69444   2.69444            1                0.964166     1                           0.986496            0.25            0.805556                   169.444   169.444            0.805556\n",
       "10       0.402062                    0.209367           1.61667   2.41809            0.6              0.658817     0.897436                    0.902475            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "11       0.505155                    0.00609401         0.269444  1.97959            0.1              0.0334117    0.734694                    0.725115            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "12       0.597938                    0.00189319         0         1.67241            0                0.00352316   0.62069                     0.613144            0               1                          -100      67.2414            0.639344\n",
       "13       0.701031                    0.000405892        0         1.42647            0                0.00098441   0.529412                    0.523121            0               1                          -100      42.6471            0.47541\n",
       "14       0.793814                    0.000119413        0         1.25974            0                0.000239008  0.467532                    0.462005            0               1                          -100      25.974             0.327869\n",
       "15       0.896907                    4.14255e-05        0         1.11494            0                8.96275e-05  0.413793                    0.408911            0               1                          -100      11.4943            0.163934\n",
       "16       1                           3.32293e-07        0         1                  0                7.01386e-06  0.371134                    0.366756            0               1                          -100      0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:47:42  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:47:42  0.034 sec   42250 obs/sec     1         1             338        0.244208         0.191472            0.749439       0.978266        0.963222           2.56061          0.0739645                        0.26536            0.266844              0.698295         0.959927          0.949872             2.69444            0.0824742\n",
       "    2025-05-26 14:47:42  0.077 sec   20484 obs/sec     2         2             676        0.199191         0.133702            0.833301       0.987864        0.977607           2.56061          0.0473373                        0.244223           0.207991              0.744444         0.976321          0.968129             2.69444            0.0721649\n",
       "    2025-05-26 14:47:42  0.112 sec   18777 obs/sec     3         3             1014       0.166762         0.102352            0.883161       0.991174        0.97996            2.56061          0.0266272                        0.220923           0.172713              0.790881         0.984062          0.977165             2.69444            0.0618557\n",
       "    2025-05-26 14:47:42  0.146 sec   18026 obs/sec     4         4             1352       0.154864         0.0900348           0.899239       0.992682        0.984218           2.56061          0.0236686                        0.206322           0.14608               0.817609         0.986794          0.980418             2.69444            0.0515464\n",
       "    2025-05-26 14:47:42  0.185 sec   16900 obs/sec     5         5             1690       0.145777         0.0807554           0.910716       0.993969        0.987328           2.56061          0.0207101                        0.19376            0.132695              0.839143         0.990437          0.985446             2.69444            0.0412371\n",
       "    2025-05-26 14:47:42  0.225 sec   16354 obs/sec     6         6             2028       0.146984         0.0811612           0.909232       0.994925        0.988938           2.56061          0.0207101                        0.214713           0.161354              0.802472         0.990437          0.984971             2.69444            0.0412371\n",
       "    2025-05-26 14:47:42  0.268 sec   15668 obs/sec     7         7             2366       0.130294         0.0669045           0.928675       0.99647         0.993011           2.56061          0.0177515                        0.173469           0.110242              0.87107          0.993169          0.988885             2.69444            0.0206186\n",
       "    2025-05-26 14:47:42  0.314 sec   15022 obs/sec     8         8             2704       0.125763         0.0626863           0.933549       0.996801        0.993638           2.56061          0.0177515                        0.170134           0.107582              0.875979         0.993169          0.988444             2.69444            0.0206186\n",
       "    2025-05-26 14:47:42  0.356 sec   14625 obs/sec     9         9             3042       0.135276         0.0704332           0.923116       0.996433        0.992097           2.56061          0.0147929                        0.20011            0.142048              0.828426         0.99408           0.99036              2.69444            0.0206186\n",
       "    2025-05-26 14:47:42  0.399 sec   14322 obs/sec     10        10            3380       0.120476         0.0587115           0.93902        0.997095        0.993904           2.56061          0.0118343                        0.159636           0.0953582             0.890813         0.99408           0.99036              2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "el-salvador-aid.?                                   1.0                    1.0                  0.026999170242835897\n",
       "duty-free-exports.?                                 0.980785071849823      0.980785071849823    0.026480383126505407\n",
       "crime.?                                             0.9742751121520996     0.9742751121520996   0.02630461961635257\n",
       "synfuels-corporation-cutback.n                      0.9653292894363403     0.9653292894363403   0.026063089825887557\n",
       "adoption-of-the-budget-resolution.y                 0.9524175524711609     0.9524175524711609   0.02571448364143396\n",
       "synfuels-corporation-cutback.?                      0.9314176440238953     0.9314176440238953   0.025147503538182268\n",
       "physician-fee-freeze.n                              0.9299356341362        0.9299356341362      0.025107490500922817\n",
       "superfund-right-to-sue.y                            0.9285814166069031     0.9285814166069031   0.0250709277513035\n",
       "export-administration-act-south-africa.y            0.8764245510101318     0.8764245510101318   0.02366273565772356\n",
       "mx-missile.n                                        0.8569630980491638     0.8569630980491638   0.02313729257605744\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[20,20,20], nfolds=0, activation=\"rectifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801cd662b9b5221",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [100,100,100], cross folds = 0, activation function = \"rectifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eddea99920b2f575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:52:39.032756Z",
     "start_time": "2025-05-09T14:52:38.045045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_43\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-20.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-20 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-20 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-20 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-20 .h2o-table th,\n",
       "#h2o-table-20 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-20 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-20\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2535174</td>\n",
       "<td>0.4306761</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0022138</td>\n",
       "<td>0.1097956</td>\n",
       "<td>0.4916553</td>\n",
       "<td>0.0163321</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0063053</td>\n",
       "<td>0.0064325</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0027844</td>\n",
       "<td>0.1012193</td>\n",
       "<td>0.9928183</td>\n",
       "<td>0.0077233</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0990008</td>\n",
       "<td>0.2692043</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004198</td>\n",
       "<td>0.1005705</td>\n",
       "<td>0.9993520</td>\n",
       "<td>0.0018503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0924141</td>\n",
       "<td>0.2819918</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0074745</td>\n",
       "<td>0.5522544</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0000513</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.021223530932150892\n",
       "RMSE: 0.14568298092828447\n",
       "LogLoss: 0.0788892250668668\n",
       "Mean Per-Class Error: 0.019711679905854665\n",
       "AUC: 0.9974992644895558\n",
       "AUCPR: 0.9959878357501917\n",
       "Gini: 0.9949985289791117</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8012458466893759</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>201.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0243</td>\n",
       "<td> (5.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>203.0</td>\n",
       "<td>135.0</td>\n",
       "<td>0.0207</td>\n",
       "<td> (7.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-22.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-22 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-22 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-22 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-22 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-22 .h2o-table th,\n",
       "#h2o-table-22 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-22 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-22\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.8012458</td>\n",
       "<td>0.9737828</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1224211</td>\n",
       "<td>0.9806835</td>\n",
       "<td>106.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9731240</td>\n",
       "<td>0.9827044</td>\n",
       "<td>87.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9101404</td>\n",
       "<td>0.9792899</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1224211</td>\n",
       "<td>1.0</td>\n",
       "<td>106.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8012458</td>\n",
       "<td>0.9568364</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9101404</td>\n",
       "<td>0.9772727</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8012458</td>\n",
       "<td>0.9802883</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999996</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1224211</td>\n",
       "<td>132.0</td>\n",
       "<td>106.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1224211</td>\n",
       "<td>1.0</td>\n",
       "<td>106.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-23.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-23 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-23 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-23 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-23 .h2o-table th,\n",
       "#h2o-table-23 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-23 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-23\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 40.77 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9999987</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999991</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999991</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9999982</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999985</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.9999975</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999976</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999983</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0909091</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0909091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9999951</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999960</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999980</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9999930</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999935</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999972</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1065089</td>\n",
       "<td>0.9999851</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999894</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999931</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.2727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2727273</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9999584</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999783</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999887</td>\n",
       "<td>0.1136364</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2100592</td>\n",
       "<td>0.9998292</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998794</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999579</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.5378788</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5378788</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9983780</td>\n",
       "<td>2.4780059</td>\n",
       "<td>2.5355021</td>\n",
       "<td>0.9677419</td>\n",
       "<td>0.9995889</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9998458</td>\n",
       "<td>0.2272727</td>\n",
       "<td>0.7651515</td>\n",
       "<td>147.8005865</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.7205854</td>\n",
       "<td>2.2502296</td>\n",
       "<td>2.4657688</td>\n",
       "<td>0.8787879</td>\n",
       "<td>0.9741172</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9935566</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9848485</td>\n",
       "<td>125.0229568</td>\n",
       "<td>146.5768799</td>\n",
       "<td>0.9605766</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0013968</td>\n",
       "<td>0.1506239</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.1074285</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.8152823</td>\n",
       "<td>0.0151515</td>\n",
       "<td>1.0</td>\n",
       "<td>-84.9376114</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0003327</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007047</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6788506</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0000620</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001437</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5839466</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8017751</td>\n",
       "<td>0.0000193</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2472325</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000428</td>\n",
       "<td>0.4870849</td>\n",
       "<td>0.5085347</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.7232472</td>\n",
       "<td>0.3252427</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000025</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000078</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4533328</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000007</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.4077313</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.017432937306248498\n",
       "RMSE: 0.13203384909275537\n",
       "LogLoss: 0.05124615323243683\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-24.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-24 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-24 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-24 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-24 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-24 .h2o-table th,\n",
       "#h2o-table-24 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-24 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-24\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8748662997053561</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>62.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (1.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-25.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-25 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-25 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-25 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-25 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-25 .h2o-table th,\n",
       "#h2o-table-25 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-25 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-25\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.8748663</td>\n",
       "<td>0.9859155</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1164795</td>\n",
       "<td>0.9890110</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8748663</td>\n",
       "<td>0.9943182</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8748663</td>\n",
       "<td>0.9896907</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1164795</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8748663</td>\n",
       "<td>0.9780293</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.8748663</td>\n",
       "<td>0.9722222</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8748663</td>\n",
       "<td>0.9861111</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999989</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999989</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000001</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1164795</td>\n",
       "<td>36.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000001</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1164795</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-26.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-26 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-26 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-26 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-26 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-26 .h2o-table th,\n",
       "#h2o-table-26 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-26 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-26\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 37.38 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9999928</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9999919</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999925</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999957</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9999876</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999944</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0618557</td>\n",
       "<td>0.9999870</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999870</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999907</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1666667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1666667</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9999836</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999859</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999888</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9999739</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999777</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999851</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9999099</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999537</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999772</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9897226</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993609</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997860</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0567770</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.7171996</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9273279</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0010670</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0080520</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7397206</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0003488</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007634</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6250548</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0000767</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001838</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5331620</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0000171</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000454</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4708497</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000018</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000075</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4167299</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000007</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3737681</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-27.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-27 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-27 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-27 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-27 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-27 .h2o-table th,\n",
       "#h2o-table-27 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-27 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-27\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.094 sec</td>\n",
       "<td>5121 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2341813</td>\n",
       "<td>0.2406872</td>\n",
       "<td>0.7695925</td>\n",
       "<td>0.9933436</td>\n",
       "<td>0.9898243</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.2176876</td>\n",
       "<td>0.1812659</td>\n",
       "<td>0.7969615</td>\n",
       "<td>0.9936248</td>\n",
       "<td>0.9903706</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.181 sec</td>\n",
       "<td>4970 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.2074964</td>\n",
       "<td>0.1892519</td>\n",
       "<td>0.8191105</td>\n",
       "<td>0.9966167</td>\n",
       "<td>0.9949132</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0295858</td>\n",
       "<td>0.1914497</td>\n",
       "<td>0.1444949</td>\n",
       "<td>0.8429563</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9956647</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.270 sec</td>\n",
       "<td>4922 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1456830</td>\n",
       "<td>0.0788892</td>\n",
       "<td>0.9108318</td>\n",
       "<td>0.9974993</td>\n",
       "<td>0.9959878</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1320338</td>\n",
       "<td>0.0512462</td>\n",
       "<td>0.9253067</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.354 sec</td>\n",
       "<td>4916 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1538868</td>\n",
       "<td>0.0799338</td>\n",
       "<td>0.9005064</td>\n",
       "<td>0.9980509</td>\n",
       "<td>0.9968213</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1727893</td>\n",
       "<td>0.1198918</td>\n",
       "<td>0.8720782</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.438 sec</td>\n",
       "<td>4927 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1438360</td>\n",
       "<td>0.0870605</td>\n",
       "<td>0.9130785</td>\n",
       "<td>0.9977935</td>\n",
       "<td>0.9965341</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1370946</td>\n",
       "<td>0.0689280</td>\n",
       "<td>0.9194711</td>\n",
       "<td>0.9977231</td>\n",
       "<td>0.9964044</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.531 sec</td>\n",
       "<td>4828 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1238290</td>\n",
       "<td>0.0488185</td>\n",
       "<td>0.9355776</td>\n",
       "<td>0.9988600</td>\n",
       "<td>0.9982412</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1389756</td>\n",
       "<td>0.0677223</td>\n",
       "<td>0.9172462</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9984564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:47</td>\n",
       "<td> 0.617 sec</td>\n",
       "<td>4828 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1429047</td>\n",
       "<td>0.0739717</td>\n",
       "<td>0.9142004</td>\n",
       "<td>0.9989703</td>\n",
       "<td>0.9984075</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1270877</td>\n",
       "<td>0.0523032</td>\n",
       "<td>0.9307981</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:48</td>\n",
       "<td> 0.720 sec</td>\n",
       "<td>4727 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1352205</td>\n",
       "<td>0.0645180</td>\n",
       "<td>0.9231794</td>\n",
       "<td>0.9991542</td>\n",
       "<td>0.9987009</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1838890</td>\n",
       "<td>0.1442605</td>\n",
       "<td>0.8551152</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9976512</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:48</td>\n",
       "<td> 0.819 sec</td>\n",
       "<td>4658 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1413051</td>\n",
       "<td>0.0767080</td>\n",
       "<td>0.9161104</td>\n",
       "<td>0.9990438</td>\n",
       "<td>0.9985396</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1823697</td>\n",
       "<td>0.1993980</td>\n",
       "<td>0.8574995</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9955992</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:48</td>\n",
       "<td> 0.905 sec</td>\n",
       "<td>4674 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1939040</td>\n",
       "<td>0.1496363</td>\n",
       "<td>0.8420333</td>\n",
       "<td>0.9991909</td>\n",
       "<td>0.9987274</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1652579</td>\n",
       "<td>0.1126568</td>\n",
       "<td>0.8829866</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:48</td>\n",
       "<td> 0.927 sec</td>\n",
       "<td>4655 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1456830</td>\n",
       "<td>0.0788892</td>\n",
       "<td>0.9108318</td>\n",
       "<td>0.9974993</td>\n",
       "<td>0.9959878</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1320338</td>\n",
       "<td>0.0512462</td>\n",
       "<td>0.9253067</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-28.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-28 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-28 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-28 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-28 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-28 .h2o-table th,\n",
       "#h2o-table-28 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-28 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-28\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241260</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9502996</td>\n",
       "<td>0.9502996</td>\n",
       "<td>0.0229269</td></tr>\n",
       "<tr><td>physician-fee-freeze.?</td>\n",
       "<td>0.9371831</td>\n",
       "<td>0.9371831</td>\n",
       "<td>0.0226105</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.?</td>\n",
       "<td>0.9279426</td>\n",
       "<td>0.9279426</td>\n",
       "<td>0.0223875</td></tr>\n",
       "<tr><td>religious-groups-in-schools.n</td>\n",
       "<td>0.9276773</td>\n",
       "<td>0.9276773</td>\n",
       "<td>0.0223811</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9257167</td>\n",
       "<td>0.9257167</td>\n",
       "<td>0.0223338</td></tr>\n",
       "<tr><td>superfund-right-to-sue.n</td>\n",
       "<td>0.9240755</td>\n",
       "<td>0.9240755</td>\n",
       "<td>0.0222942</td></tr>\n",
       "<tr><td>handicapped-infants.y</td>\n",
       "<td>0.9174811</td>\n",
       "<td>0.9174811</td>\n",
       "<td>0.0221351</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.9174040</td>\n",
       "<td>0.9174040</td>\n",
       "<td>0.0221333</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.y</td>\n",
       "<td>0.9128744</td>\n",
       "<td>0.9128744</td>\n",
       "<td>0.0220240</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_43\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  ----------------------  ---------------------\n",
       "    1        64       Input      0.0\n",
       "    2        100      Rectifier  0.0        0.0   0.0   0.25351739970712517   0.43067610263824463   0.0         0.0022138433337661923  0.10979557037353516  0.4916553172481135      0.01633206009864807\n",
       "    3        100      Rectifier  0.0        0.0   0.0   0.006305315609421814  0.006432496011257172  0.0         -0.00278441449620816   0.10121926665306091  0.9928183312808858      0.007723288610577583\n",
       "    4        100      Rectifier  0.0        0.0   0.0   0.09900077089754632   0.2692042589187622    0.0         0.0004197641423509353  0.10057049989700317  0.9993520426318344      0.001850338652729988\n",
       "    5        2        Softmax               0.0   0.0   0.09241412103234324   0.2819918394088745    0.0         -0.007474530169274658  0.5522544384002686   1.4941661189565858e-18  5.129433702677488e-05\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.021223530932150892\n",
       "RMSE: 0.14568298092828447\n",
       "LogLoss: 0.0788892250668668\n",
       "Mean Per-Class Error: 0.019711679905854665\n",
       "AUC: 0.9974992644895558\n",
       "AUCPR: 0.9959878357501917\n",
       "Gini: 0.9949985289791117\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8012458466893759\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    201         5             0.0243   (5.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       203         135           0.0207   (7.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.801246     0.973783  96\n",
       "max f2                       0.122421     0.980684  106\n",
       "max f0point5                 0.973124     0.982704  87\n",
       "max accuracy                 0.91014      0.97929   94\n",
       "max precision                1            1         0\n",
       "max recall                   0.122421     1         106\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.801246     0.956836  96\n",
       "max min_per_class_accuracy   0.91014      0.977273  94\n",
       "max mean_per_class_accuracy  0.801246     0.980288  96\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      1.00753e-08  206       269\n",
       "max tps                      0.122421     132       106\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      1.00753e-08  1         269\n",
       "max tpr                      0.122421     1         106\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 40.77 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.999999           2.56061   2.56061            1                0.999999     1                           0.999999            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.999998           2.56061   2.56061            1                0.999999     1                           0.999999            0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.035503                    0.999998           2.56061   2.56061            1                0.999998     1                           0.999998            0.0378788       0.0909091                  156.061   156.061            0.0909091\n",
       "4        0.0414201                   0.999995           2.56061   2.56061            1                0.999996     1                           0.999998            0.0151515       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.999993           2.56061   2.56061            1                0.999994     1                           0.999997            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.106509                    0.999985           2.56061   2.56061            1                0.999989     1                           0.999993            0.143939        0.272727                   156.061   156.061            0.272727\n",
       "7        0.150888                    0.999958           2.56061   2.56061            1                0.999978     1                           0.999989            0.113636        0.386364                   156.061   156.061            0.386364\n",
       "8        0.210059                    0.999829           2.56061   2.56061            1                0.999879     1                           0.999958            0.151515        0.537879                   156.061   156.061            0.537879\n",
       "9        0.301775                    0.998378           2.47801   2.5355             0.967742         0.999589     0.990196                    0.999846            0.227273        0.765152                   147.801   153.55             0.760297\n",
       "10       0.399408                    0.720585           2.25023   2.46577            0.878788         0.974117     0.962963                    0.993557            0.219697        0.984848                   125.023   146.577            0.960577\n",
       "11       0.5                         0.00139679         0.150624  2                  0.0588235        0.107429     0.781065                    0.815282            0.0151515       1                          -84.9376  100                0.820388\n",
       "12       0.600592                    0.000332688        0         1.66502            0                0.000704657  0.650246                    0.678851            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    6.20208e-05        0         1.4322             0                0.000143729  0.559322                    0.583947            0               1                          -100      43.2203            0.495146\n",
       "14       0.801775                    1.93316e-05        0         1.24723            0                4.27914e-05  0.487085                    0.508535            0               1                          -100      24.7232            0.325243\n",
       "15       0.899408                    2.52732e-06        0         1.11184            0                7.77726e-06  0.434211                    0.453333            0               1                          -100      11.1842            0.165049\n",
       "16       1                           1.00753e-08        0         1                  0                7.16964e-07  0.390533                    0.407731            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.017432937306248498\n",
       "RMSE: 0.13203384909275537\n",
       "LogLoss: 0.05124615323243683\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8748662997053561\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    61          0             0        (0.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       62          35            0.0103   (1.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.874866     0.985915  31\n",
       "max f2                       0.116479     0.989011  34\n",
       "max f0point5                 0.874866     0.994318  31\n",
       "max accuracy                 0.874866     0.989691  31\n",
       "max precision                0.999999     1         0\n",
       "max recall                   0.116479     1         34\n",
       "max specificity              0.999999     1         0\n",
       "max absolute_mcc             0.874866     0.978029  31\n",
       "max min_per_class_accuracy   0.874866     0.972222  31\n",
       "max mean_per_class_accuracy  0.874866     0.986111  31\n",
       "max tns                      0.999999     61        0\n",
       "max fns                      0.999999     35        0\n",
       "max fps                      8.48929e-08  61        91\n",
       "max tps                      0.116479     36        34\n",
       "max tnr                      0.999999     1         0\n",
       "max fnr                      0.999999     0.972222  0\n",
       "max fpr                      8.48929e-08  1         91\n",
       "max tpr                      0.116479     1         34\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 37.38 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   0.999993           2.69444  2.69444            1                0.999999     1                           0.999999            0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   0.999992           2.69444  2.69444            1                0.999993     1                           0.999996            0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0309278                   0.999988           2.69444  2.69444            1                0.999992     1                           0.999994            0.0277778       0.0833333                  169.444  169.444            0.0833333\n",
       "4        0.0618557                   0.999987           2.69444  2.69444            1                0.999987     1                           0.999991            0.0833333       0.166667                   169.444  169.444            0.166667\n",
       "5        0.103093                    0.999984           2.69444  2.69444            1                0.999986     1                           0.999989            0.111111        0.277778                   169.444  169.444            0.277778\n",
       "6        0.154639                    0.999974           2.69444  2.69444            1                0.999978     1                           0.999985            0.138889        0.416667                   169.444  169.444            0.416667\n",
       "7        0.206186                    0.99991            2.69444  2.69444            1                0.999954     1                           0.999977            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "8        0.298969                    0.989723           2.69444  2.69444            1                0.999361     1                           0.999786            0.25            0.805556                   169.444  169.444            0.805556\n",
       "9        0.402062                    0.056777           1.88611  2.48718            0.7              0.7172       0.923077                    0.927328            0.194444        1                          88.6111  148.718            0.95082\n",
       "10       0.505155                    0.00106696         0        1.97959            0                0.00805197   0.734694                    0.739721            0               1                          -100     97.9592            0.786885\n",
       "11       0.597938                    0.000348777        0        1.67241            0                0.000763428  0.62069                     0.625055            0               1                          -100     67.2414            0.639344\n",
       "12       0.701031                    7.66696e-05        0        1.42647            0                0.000183762  0.529412                    0.533162            0               1                          -100     42.6471            0.47541\n",
       "13       0.793814                    1.7083e-05         0        1.25974            0                4.5393e-05   0.467532                    0.47085             0               1                          -100     25.974             0.327869\n",
       "14       0.896907                    1.82398e-06        0        1.11494            0                7.50767e-06  0.413793                    0.41673             0               1                          -100     11.4943            0.163934\n",
       "15       1                           8.48929e-08        0        1                  0                7.44273e-07  0.371134                    0.373768            0               1                          -100     0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:47:47  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:47:47  0.094 sec   5121 obs/sec      1         1             338        0.234181         0.240687            0.769593       0.993344        0.989824           2.56061          0.035503                         0.217688           0.181266              0.796962         0.993625          0.990371             2.69444            0.0309278\n",
       "    2025-05-26 14:47:47  0.181 sec   4970 obs/sec      2         2             676        0.207496         0.189252            0.81911        0.996617        0.994913           2.56061          0.0295858                        0.19145            0.144495              0.842956         0.997268          0.995665             2.69444            0.0206186\n",
       "    2025-05-26 14:47:47  0.270 sec   4922 obs/sec      3         3             1014       0.145683         0.0788892           0.910832       0.997499        0.995988           2.56061          0.0207101                        0.132034           0.0512462             0.925307         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:47:47  0.354 sec   4916 obs/sec      4         4             1352       0.153887         0.0799338           0.900506       0.998051        0.996821           2.56061          0.0207101                        0.172789           0.119892              0.872078         0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:47:47  0.438 sec   4927 obs/sec      5         5             1690       0.143836         0.0870605           0.913078       0.997793        0.996534           2.56061          0.0207101                        0.137095           0.068928              0.919471         0.997723          0.996404             2.69444            0.0206186\n",
       "    2025-05-26 14:47:47  0.531 sec   4828 obs/sec      6         6             2028       0.123829         0.0488185           0.935578       0.99886         0.998241           2.56061          0.0177515                        0.138976           0.0677223             0.917246         0.999089          0.998456             2.69444            0.0103093\n",
       "    2025-05-26 14:47:47  0.617 sec   4828 obs/sec      7         7             2366       0.142905         0.0739717           0.9142         0.99897         0.998408           2.56061          0.0147929                        0.127088           0.0523032             0.930798         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:47:48  0.720 sec   4727 obs/sec      8         8             2704       0.135221         0.064518            0.923179       0.999154        0.998701           2.56061          0.0118343                        0.183889           0.14426               0.855115         0.998634          0.997651             2.69444            0.0103093\n",
       "    2025-05-26 14:47:48  0.819 sec   4658 obs/sec      9         9             3042       0.141305         0.076708            0.91611        0.999044        0.99854            2.56061          0.0118343                        0.18237            0.199398              0.857499         0.997268          0.995599             2.69444            0.0206186\n",
       "    2025-05-26 14:47:48  0.905 sec   4674 obs/sec      10        10            3380       0.193904         0.149636            0.842033       0.999191        0.998727           2.56061          0.0118343                        0.165258           0.112657              0.882987         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:47:48  0.927 sec   4655 obs/sec      10        10            3380       0.145683         0.0788892           0.910832       0.997499        0.995988           2.56061          0.0207101                        0.132034           0.0512462             0.925307         0.999089          0.998518             2.69444            0.0103093\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.024125987705392746\n",
       "synfuels-corporation-cutback.n                      0.9502995610237122     0.9502995610237122   0.022926915525698203\n",
       "physician-fee-freeze.?                              0.937183141708374      0.937183141708374    0.022610468954557577\n",
       "adoption-of-the-budget-resolution.?                 0.9279425740242004     0.9279425740242004   0.022387531132218356\n",
       "religious-groups-in-schools.n                       0.92767733335495       0.92767733335495     0.02238113193909305\n",
       "physician-fee-freeze.n                              0.9257166981697083     0.9257166981697083   0.022333829678719146\n",
       "superfund-right-to-sue.n                            0.9240755438804626     0.9240755438804626   0.022294235210514157\n",
       "handicapped-infants.y                               0.9174811244010925     0.9174811244010925   0.02213513832723067\n",
       "aid-to-nicaraguan-contras.y                         0.9174039959907532     0.9174039959907532   0.022133277528151085\n",
       "export-administration-act-south-africa.y            0.9128744006156921     0.9128744006156921   0.02202399656582196\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[100,100,100], nfolds=0, activation=\"rectifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc67b535d9b8f8",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [5,5,5], cross folds = 5, activation function = \"rectifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f24e63a3bcc61dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:52:49.200382Z",
     "start_time": "2025-05-09T14:52:48.547849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_66\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-29.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-29 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-29 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-29 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-29 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-29 .h2o-table th,\n",
       "#h2o-table-29 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-29 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-29\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2696786</td>\n",
       "<td>0.4383750</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0065526</td>\n",
       "<td>0.1819432</td>\n",
       "<td>0.5640372</td>\n",
       "<td>0.0629817</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0086211</td>\n",
       "<td>0.0162925</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0663704</td>\n",
       "<td>0.4954164</td>\n",
       "<td>0.9437224</td>\n",
       "<td>0.0729509</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0052012</td>\n",
       "<td>0.0071499</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0624972</td>\n",
       "<td>0.4076147</td>\n",
       "<td>1.1628882</td>\n",
       "<td>0.6667528</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014566</td>\n",
       "<td>0.0003413</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6811175</td>\n",
       "<td>1.0931277</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.1634747</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02357065678931948\n",
       "RMSE: 0.15352738123644094\n",
       "LogLoss: 0.09121775368549542\n",
       "Mean Per-Class Error: 0.02213886437187408\n",
       "AUC: 0.9923323036187113\n",
       "AUCPR: 0.9789850679136286\n",
       "Gini: 0.9846646072374226</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-30.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-30 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-30 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-30 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-30 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-30 .h2o-table th,\n",
       "#h2o-table-30 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-30 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-30\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4651299332629031</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>200.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0291</td>\n",
       "<td> (6.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>202.0</td>\n",
       "<td>136.0</td>\n",
       "<td>0.0237</td>\n",
       "<td> (8.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-31.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-31 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-31 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-31 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-31 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-31 .h2o-table th,\n",
       "#h2o-table-31 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-31 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-31\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9701493</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9789157</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6108206</td>\n",
       "<td>0.9696970</td>\n",
       "<td>63.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6108206</td>\n",
       "<td>0.9763314</td>\n",
       "<td>63.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9134778</td>\n",
       "<td>0.9902913</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0551605</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.9951456</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9508393</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5368153</td>\n",
       "<td>0.9757282</td>\n",
       "<td>65.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9778611</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>205.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>87.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000026</td>\n",
       "<td>206.0</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0551605</td>\n",
       "<td>132.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.9951456</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.6590909</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000026</td>\n",
       "<td>1.0</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0551605</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-32.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-32 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-32 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-32 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-32 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-32 .h2o-table th,\n",
       "#h2o-table-32 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-32 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-32\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.40 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.1360947</td>\n",
       "<td>0.9775661</td>\n",
       "<td>2.5049407</td>\n",
       "<td>2.5049407</td>\n",
       "<td>0.9782609</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.9782609</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.3409091</td>\n",
       "<td>0.3409091</td>\n",
       "<td>150.4940711</td>\n",
       "<td>150.4940711</td>\n",
       "<td>0.3360547</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.1568047</td>\n",
       "<td>0.9756318</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5122927</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9759588</td>\n",
       "<td>0.9811321</td>\n",
       "<td>0.9773538</td>\n",
       "<td>0.0530303</td>\n",
       "<td>0.3939394</td>\n",
       "<td>156.0606061</td>\n",
       "<td>151.2292739</td>\n",
       "<td>0.3890850</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.2218935</td>\n",
       "<td>0.9726074</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5264646</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9730034</td>\n",
       "<td>0.9866667</td>\n",
       "<td>0.9760777</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.5606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>152.6464646</td>\n",
       "<td>0.5557517</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9261521</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5355021</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9628542</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9725774</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.7651515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4783132</td>\n",
       "<td>2.1726354</td>\n",
       "<td>2.4468013</td>\n",
       "<td>0.8484848</td>\n",
       "<td>0.7811503</td>\n",
       "<td>0.9555556</td>\n",
       "<td>0.9257841</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.9772727</td>\n",
       "<td>117.2635445</td>\n",
       "<td>144.6801347</td>\n",
       "<td>0.9481465</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0221940</td>\n",
       "<td>0.2259358</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0882353</td>\n",
       "<td>0.1311074</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7659083</td>\n",
       "<td>0.0227273</td>\n",
       "<td>1.0</td>\n",
       "<td>-77.4064171</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0036235</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0077592</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6389277</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0008198</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0018242</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5498412</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0003127</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004849</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4806630</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001133</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002076</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4269278</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000026</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000536</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3839878</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.0313699851476705\n",
       "RMSE: 0.17711573941259567\n",
       "LogLoss: 0.11711592294593795\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.994535519125683\n",
       "AUCPR: 0.9918040042192442\n",
       "Gini: 0.9890710382513661</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-33.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-33 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-33 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-33 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-33 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-33 .h2o-table th,\n",
       "#h2o-table-33 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-33 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-33\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2668740561060711</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>59.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0328</td>\n",
       "<td> (2.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>60.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.0309</td>\n",
       "<td> (3.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-34.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-34 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-34 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-34 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-34 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-34 .h2o-table th,\n",
       "#h2o-table-34 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-34 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-34\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9589041</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9668508</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7220286</td>\n",
       "<td>0.9821429</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7220286</td>\n",
       "<td>0.9690722</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0131959</td>\n",
       "<td>1.0</td>\n",
       "<td>27.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7220286</td>\n",
       "<td>0.9347181</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9672131</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9697177</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000094</td>\n",
       "<td>61.0</td>\n",
       "<td>78.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0131959</td>\n",
       "<td>36.0</td>\n",
       "<td>27.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.5277778</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000094</td>\n",
       "<td>1.0</td>\n",
       "<td>78.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0131959</td>\n",
       "<td>1.0</td>\n",
       "<td>27.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-35.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-35 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-35 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-35 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-35 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-35 .h2o-table th,\n",
       "#h2o-table-35 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-35 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-35\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.95 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.1752577</td>\n",
       "<td>0.9775661</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.4722222</td>\n",
       "<td>0.4722222</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4722222</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9750734</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9764260</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9773951</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.8444647</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9389353</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9654593</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0904979</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.5602224</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8615524</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0065238</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0245879</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.6907433</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0021160</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0036660</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5841279</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0005463</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0011275</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.4983925</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0004147</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004592</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4401925</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000880</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002519</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3896246</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000094</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000366</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3494609</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.045365285386998806\n",
       "RMSE: 0.21299128007267998\n",
       "LogLoss: 0.17370145001620638\n",
       "Mean Per-Class Error: 0.053508384819064427\n",
       "AUC: 0.9787621359223301\n",
       "AUCPR: 0.9683618656971925\n",
       "Gini: 0.9575242718446602</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-36.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-36 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-36 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-36 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-36 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-36 .h2o-table th,\n",
       "#h2o-table-36 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-36 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-36\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6758263066539283</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>198.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0388</td>\n",
       "<td> (8.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>9.0</td>\n",
       "<td>123.0</td>\n",
       "<td>0.0682</td>\n",
       "<td> (9.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>207.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0503</td>\n",
       "<td> (17.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-37.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-37 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-37 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-37 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-37 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-37 .h2o-table th,\n",
       "#h2o-table-37 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-37 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-37\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6758263</td>\n",
       "<td>0.9353612</td>\n",
       "<td>85.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1600071</td>\n",
       "<td>0.9555556</td>\n",
       "<td>101.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7177266</td>\n",
       "<td>0.9413580</td>\n",
       "<td>83.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7177266</td>\n",
       "<td>0.9497041</td>\n",
       "<td>83.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9805892</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0001479</td>\n",
       "<td>1.0</td>\n",
       "<td>247.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9805892</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6758263</td>\n",
       "<td>0.8942173</td>\n",
       "<td>85.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6378124</td>\n",
       "<td>0.9393939</td>\n",
       "<td>88.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6758263</td>\n",
       "<td>0.9464916</td>\n",
       "<td>85.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9805892</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9805892</td>\n",
       "<td>122.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000094</td>\n",
       "<td>206.0</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0001479</td>\n",
       "<td>132.0</td>\n",
       "<td>247.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9805892</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9805892</td>\n",
       "<td>0.9242424</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000094</td>\n",
       "<td>1.0</td>\n",
       "<td>284.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0001479</td>\n",
       "<td>1.0</td>\n",
       "<td>247.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-38.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-38 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-38 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-38 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-38 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-38 .h2o-table th,\n",
       "#h2o-table-38 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-38 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-38\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.48 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0295858</td>\n",
       "<td>0.9805892</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9805892</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9805892</td>\n",
       "<td>0.0757576</td>\n",
       "<td>0.0757576</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0757576</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9803998</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9804428</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9805759</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9791913</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9796746</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9803828</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0532544</td>\n",
       "<td>0.9785741</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9787285</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9800151</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1363636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1363636</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9722424</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9750070</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9776584</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9690367</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9697533</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9750233</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9549403</td>\n",
       "<td>2.2593583</td>\n",
       "<td>2.4852941</td>\n",
       "<td>0.8823529</td>\n",
       "<td>0.9627483</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9719546</td>\n",
       "<td>0.1136364</td>\n",
       "<td>0.5</td>\n",
       "<td>125.9358289</td>\n",
       "<td>148.5294118</td>\n",
       "<td>0.4902913</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9048432</td>\n",
       "<td>2.4852941</td>\n",
       "<td>2.4852941</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9211200</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9550097</td>\n",
       "<td>0.25</td>\n",
       "<td>0.75</td>\n",
       "<td>148.5294118</td>\n",
       "<td>148.5294118</td>\n",
       "<td>0.7354369</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.5120756</td>\n",
       "<td>1.9398531</td>\n",
       "<td>2.3519641</td>\n",
       "<td>0.7575758</td>\n",
       "<td>0.8025134</td>\n",
       "<td>0.9185185</td>\n",
       "<td>0.9177328</td>\n",
       "<td>0.1893939</td>\n",
       "<td>0.9393939</td>\n",
       "<td>93.9853076</td>\n",
       "<td>135.1964085</td>\n",
       "<td>0.8859959</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0382583</td>\n",
       "<td>0.5271836</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.2058824</td>\n",
       "<td>0.1612221</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7655354</td>\n",
       "<td>0.0530303</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-47.2816399</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0053159</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6524108</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0158220</td>\n",
       "<td>0.6453202</td>\n",
       "<td>0.6399677</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>65.2410808</td>\n",
       "<td>0.6429097</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0015075</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4213534</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029218</td>\n",
       "<td>0.5550847</td>\n",
       "<td>0.5508892</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.1353364</td>\n",
       "<td>0.4827155</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0004246</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2423681</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0007706</td>\n",
       "<td>0.4851852</td>\n",
       "<td>0.4816150</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.2368126</td>\n",
       "<td>0.3176670</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001160</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0002405</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4277771</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>9.43e-06</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000561</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3847519</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-39.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-39 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-39 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-39 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-39 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-39 .h2o-table th,\n",
       "#h2o-table-39 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-39 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-39\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9573698</td>\n",
       "<td>0.0256576</td>\n",
       "<td>0.9523810</td>\n",
       "<td>0.9493671</td>\n",
       "<td>0.9545454</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9305556</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.983349</td>\n",
       "<td>0.0120884</td>\n",
       "<td>0.9726744</td>\n",
       "<td>0.9715762</td>\n",
       "<td>0.9906015</td>\n",
       "<td>1.0</td>\n",
       "<td>0.981893</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0426302</td>\n",
       "<td>0.0256576</td>\n",
       "<td>0.0476191</td>\n",
       "<td>0.0506329</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0694445</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>3.0</td>\n",
       "<td>1.8708287</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9291124</td>\n",
       "<td>0.0458699</td>\n",
       "<td>0.8928571</td>\n",
       "<td>0.9308510</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8843538</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9471656</td>\n",
       "<td>0.0327746</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9459459</td>\n",
       "<td>0.9473684</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9122807</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9663776</td>\n",
       "<td>0.0214867</td>\n",
       "<td>0.9708738</td>\n",
       "<td>0.9615384</td>\n",
       "<td>0.9574468</td>\n",
       "<td>1.0</td>\n",
       "<td>0.942029</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.3110318</td>\n",
       "<td>0.4709629</td>\n",
       "<td>1.575</td>\n",
       "<td>2.1944444</td>\n",
       "<td>2.357143</td>\n",
       "<td>2.7619047</td>\n",
       "<td>2.6666667</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9130176</td>\n",
       "<td>0.0523245</td>\n",
       "<td>0.8993875</td>\n",
       "<td>0.8995539</td>\n",
       "<td>0.9078227</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8583237</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9618416</td>\n",
       "<td>0.0236161</td>\n",
       "<td>0.9651163</td>\n",
       "<td>0.9512274</td>\n",
       "<td>0.9558271</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9370371</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0381584</td>\n",
       "<td>0.0236161</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.0487726</td>\n",
       "<td>0.0441729</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0629630</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0436031</td>\n",
       "<td>0.0202925</td>\n",
       "<td>0.0425606</td>\n",
       "<td>0.0620349</td>\n",
       "<td>0.0441915</td>\n",
       "<td>0.0106938</td>\n",
       "<td>0.0585349</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9563107</td>\n",
       "<td>0.0613834</td>\n",
       "<td>0.8484626</td>\n",
       "<td>0.9729828</td>\n",
       "<td>0.9880001</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9721083</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9176638</td>\n",
       "<td>0.0545062</td>\n",
       "<td>0.8695652</td>\n",
       "<td>0.9210526</td>\n",
       "<td>0.9310345</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8666667</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8153016</td>\n",
       "<td>0.0833901</td>\n",
       "<td>0.8035778</td>\n",
       "<td>0.7498966</td>\n",
       "<td>0.8190807</td>\n",
       "<td>0.9537016</td>\n",
       "<td>0.7502512</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9798942</td>\n",
       "<td>0.0186925</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.2021877</td>\n",
       "<td>0.0583444</td>\n",
       "<td>0.2063022</td>\n",
       "<td>0.2490682</td>\n",
       "<td>0.2102177</td>\n",
       "<td>0.1034108</td>\n",
       "<td>0.2419398</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9437889</td>\n",
       "<td>0.0339407</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9473684</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9111111</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-40.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-40 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-40 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-40 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-40 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-40 .h2o-table th,\n",
       "#h2o-table-40 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-40 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-40\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.135 sec</td>\n",
       "<td>112666 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.5934409</td>\n",
       "<td>1.2097308</td>\n",
       "<td>-0.4796095</td>\n",
       "<td>0.9613122</td>\n",
       "<td>0.9424013</td>\n",
       "<td>2.5212121</td>\n",
       "<td>0.0976331</td>\n",
       "<td>0.5805649</td>\n",
       "<td>1.1732796</td>\n",
       "<td>-0.4441512</td>\n",
       "<td>0.9704007</td>\n",
       "<td>0.9490134</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0824742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.160 sec</td>\n",
       "<td>35578 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.2637676</td>\n",
       "<td>0.2464865</td>\n",
       "<td>0.7076958</td>\n",
       "<td>0.9715909</td>\n",
       "<td>0.9423941</td>\n",
       "<td>2.4621212</td>\n",
       "<td>0.0710059</td>\n",
       "<td>0.2591862</td>\n",
       "<td>0.2349209</td>\n",
       "<td>0.7121708</td>\n",
       "<td>0.9744991</td>\n",
       "<td>0.9572636</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.182 sec</td>\n",
       "<td>31687 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.2227407</td>\n",
       "<td>0.1796701</td>\n",
       "<td>0.7915551</td>\n",
       "<td>0.9799941</td>\n",
       "<td>0.9558020</td>\n",
       "<td>2.4805871</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.2377195</td>\n",
       "<td>0.2000976</td>\n",
       "<td>0.7578744</td>\n",
       "<td>0.9785974</td>\n",
       "<td>0.9663337</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0515464</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.207 sec</td>\n",
       "<td>28765 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.2062927</td>\n",
       "<td>0.1531687</td>\n",
       "<td>0.8212030</td>\n",
       "<td>0.9846646</td>\n",
       "<td>0.9688582</td>\n",
       "<td>2.5234958</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.2191439</td>\n",
       "<td>0.1730541</td>\n",
       "<td>0.7942358</td>\n",
       "<td>0.9817851</td>\n",
       "<td>0.9715097</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.231 sec</td>\n",
       "<td>27258 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1923995</td>\n",
       "<td>0.1349478</td>\n",
       "<td>0.8444750</td>\n",
       "<td>0.9865953</td>\n",
       "<td>0.9676451</td>\n",
       "<td>2.4852941</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.2197891</td>\n",
       "<td>0.1737430</td>\n",
       "<td>0.7930224</td>\n",
       "<td>0.9831512</td>\n",
       "<td>0.9736716</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.257 sec</td>\n",
       "<td>26000 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1816193</td>\n",
       "<td>0.1221948</td>\n",
       "<td>0.8614149</td>\n",
       "<td>0.9886180</td>\n",
       "<td>0.9702942</td>\n",
       "<td>2.4752525</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.2092738</td>\n",
       "<td>0.1572064</td>\n",
       "<td>0.8123533</td>\n",
       "<td>0.9854281</td>\n",
       "<td>0.9770254</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.277 sec</td>\n",
       "<td>26000 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1734851</td>\n",
       "<td>0.1130596</td>\n",
       "<td>0.8735507</td>\n",
       "<td>0.9899419</td>\n",
       "<td>0.9748364</td>\n",
       "<td>2.5024105</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.1974501</td>\n",
       "<td>0.1391744</td>\n",
       "<td>0.8329579</td>\n",
       "<td>0.9895264</td>\n",
       "<td>0.9824451</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.299 sec</td>\n",
       "<td>26000 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1663014</td>\n",
       "<td>0.1051287</td>\n",
       "<td>0.8838058</td>\n",
       "<td>0.9909532</td>\n",
       "<td>0.9763613</td>\n",
       "<td>2.5010571</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1936989</td>\n",
       "<td>0.1350823</td>\n",
       "<td>0.8392446</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9847051</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.321 sec</td>\n",
       "<td>25779 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1635421</td>\n",
       "<td>0.1016475</td>\n",
       "<td>0.8876297</td>\n",
       "<td>0.9913761</td>\n",
       "<td>0.9747097</td>\n",
       "<td>2.4752525</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1925965</td>\n",
       "<td>0.1376056</td>\n",
       "<td>0.8410693</td>\n",
       "<td>0.9913479</td>\n",
       "<td>0.9867603</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.347 sec</td>\n",
       "<td>25037 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1576110</td>\n",
       "<td>0.0951942</td>\n",
       "<td>0.8956325</td>\n",
       "<td>0.9920197</td>\n",
       "<td>0.9791049</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1796379</td>\n",
       "<td>0.1169730</td>\n",
       "<td>0.8617367</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9909748</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:52</td>\n",
       "<td> 1.372 sec</td>\n",
       "<td>24622 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1535274</td>\n",
       "<td>0.0912178</td>\n",
       "<td>0.9009706</td>\n",
       "<td>0.9923323</td>\n",
       "<td>0.9789851</td>\n",
       "<td>2.5049407</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1771157</td>\n",
       "<td>0.1171159</td>\n",
       "<td>0.8655919</td>\n",
       "<td>0.9945355</td>\n",
       "<td>0.9918040</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-41.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-41 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-41 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-41 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-41 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-41 .h2o-table th,\n",
       "#h2o-table-41 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-41 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-41\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.n</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0458977</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.8481766</td>\n",
       "<td>0.8481766</td>\n",
       "<td>0.0389293</td></tr>\n",
       "<tr><td>el-salvador-aid.?</td>\n",
       "<td>0.6823165</td>\n",
       "<td>0.6823165</td>\n",
       "<td>0.0313168</td></tr>\n",
       "<tr><td>water-project-cost-sharing.y</td>\n",
       "<td>0.6660596</td>\n",
       "<td>0.6660596</td>\n",
       "<td>0.0305706</td></tr>\n",
       "<tr><td>physician-fee-freeze.y</td>\n",
       "<td>0.6104475</td>\n",
       "<td>0.6104475</td>\n",
       "<td>0.0280181</td></tr>\n",
       "<tr><td>crime.n</td>\n",
       "<td>0.6070755</td>\n",
       "<td>0.6070755</td>\n",
       "<td>0.0278634</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.5845112</td>\n",
       "<td>0.5845112</td>\n",
       "<td>0.0268277</td></tr>\n",
       "<tr><td>el-salvador-aid.n</td>\n",
       "<td>0.5741304</td>\n",
       "<td>0.5741304</td>\n",
       "<td>0.0263513</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.5629772</td>\n",
       "<td>0.5629772</td>\n",
       "<td>0.0258394</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.n</td>\n",
       "<td>0.5458343</td>\n",
       "<td>0.5458343</td>\n",
       "<td>0.0250525</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_66\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -----------------------  -------------------\n",
       "    1        64       Input      0.0\n",
       "    2        5        Rectifier  0.0        0.0   0.0   0.26967864367388755   0.43837499618530273     0.0         -0.006552608267702454  0.18194323778152466  0.5640372000500701       0.06298166513442993\n",
       "    3        5        Rectifier  0.0        0.0   0.0   0.008621125557110644  0.016292452812194824    0.0         -0.06637037634849548   0.49541640281677246  0.9437223901522694       0.07295086979866028\n",
       "    4        5        Rectifier  0.0        0.0   0.0   0.005201225398341194  0.007149899378418922    0.0         0.06249721698462963    0.40761470794677734  1.1628881981617805       0.666752815246582\n",
       "    5        2        Softmax               0.0   0.0   0.001456583570688963  0.00034134811721742153  0.0         1.681117482483387      1.093127727508545    -2.7755575615628914e-17  0.1634746789932251\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02357065678931948\n",
       "RMSE: 0.15352738123644094\n",
       "LogLoss: 0.09121775368549542\n",
       "Mean Per-Class Error: 0.02213886437187408\n",
       "AUC: 0.9923323036187113\n",
       "AUCPR: 0.9789850679136286\n",
       "Gini: 0.9846646072374226\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4651299332629031\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    200         6             0.0291   (6.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       202         136           0.0237   (8.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.46513      0.970149  67\n",
       "max f2                       0.46513      0.978916  67\n",
       "max f0point5                 0.610821     0.969697  63\n",
       "max accuracy                 0.610821     0.976331  63\n",
       "max precision                0.913478     0.990291  36\n",
       "max recall                   0.0551605    1         91\n",
       "max specificity              0.977566     0.995146  0\n",
       "max absolute_mcc             0.46513      0.950839  67\n",
       "max min_per_class_accuracy   0.536815     0.975728  65\n",
       "max mean_per_class_accuracy  0.46513      0.977861  67\n",
       "max tns                      0.977566     205       0\n",
       "max fns                      0.977566     87        0\n",
       "max fps                      2.562e-06    206       239\n",
       "max tps                      0.0551605    132       91\n",
       "max tnr                      0.977566     0.995146  0\n",
       "max fnr                      0.977566     0.659091  0\n",
       "max fpr                      2.562e-06    1         239\n",
       "max tpr                      0.0551605    1         91\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.40 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.136095                    0.977566           2.50494   2.50494            0.978261         0.977566     0.978261                    0.977566            0.340909        0.340909                   150.494   150.494            0.336055\n",
       "2        0.156805                    0.975632           2.56061   2.51229            1                0.975959     0.981132                    0.977354            0.0530303       0.393939                   156.061   151.229            0.389085\n",
       "3        0.221893                    0.972607           2.56061   2.52646            1                0.973003     0.986667                    0.976078            0.166667        0.560606                   156.061   152.646            0.555752\n",
       "4        0.301775                    0.926152           2.56061   2.5355             1                0.962854     0.990196                    0.972577            0.204545        0.765152                   156.061   153.55             0.760297\n",
       "5        0.399408                    0.478313           2.17264   2.4468             0.848485         0.78115      0.955556                    0.925784            0.212121        0.977273                   117.264   144.68             0.948147\n",
       "6        0.5                         0.022194           0.225936  2                  0.0882353        0.131107     0.781065                    0.765908            0.0227273       1                          -77.4064  100                0.820388\n",
       "7        0.600592                    0.00362354         0         1.66502            0                0.00775922   0.650246                    0.638928            0               1                          -100      66.5025            0.65534\n",
       "8        0.698225                    0.000819781        0         1.4322             0                0.00182422   0.559322                    0.549841            0               1                          -100      43.2203            0.495146\n",
       "9        0.798817                    0.000312737        0         1.25185            0                0.000484883  0.488889                    0.480663            0               1                          -100      25.1852            0.330097\n",
       "10       0.899408                    0.00011333         0         1.11184            0                0.000207602  0.434211                    0.426928            0               1                          -100      11.1842            0.165049\n",
       "11       1                           2.562e-06          0         1                  0                5.36447e-05  0.390533                    0.383988            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.0313699851476705\n",
       "RMSE: 0.17711573941259567\n",
       "LogLoss: 0.11711592294593795\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.994535519125683\n",
       "AUCPR: 0.9918040042192442\n",
       "Gini: 0.9890710382513661\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2668740561060711\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    59          2             0.0328   (2.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       60          37            0.0309   (3.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.266874     0.958904  20\n",
       "max f2                       0.266874     0.966851  20\n",
       "max f0point5                 0.722029     0.982143  16\n",
       "max accuracy                 0.722029     0.969072  16\n",
       "max precision                0.977566     1         0\n",
       "max recall                   0.0131959    1         27\n",
       "max specificity              0.977566     1         0\n",
       "max absolute_mcc             0.722029     0.934718  16\n",
       "max min_per_class_accuracy   0.266874     0.967213  20\n",
       "max mean_per_class_accuracy  0.266874     0.969718  20\n",
       "max tns                      0.977566     61        0\n",
       "max fns                      0.977566     19        0\n",
       "max fps                      9.42667e-06  61        78\n",
       "max tps                      0.0131959    36        27\n",
       "max tnr                      0.977566     1         0\n",
       "max fnr                      0.977566     0.527778  0\n",
       "max fpr                      9.42667e-06  1         78\n",
       "max tpr                      0.0131959    1         27\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.95 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.175258                    0.977566           2.69444   2.69444            1                0.977566     1                           0.977566            0.472222        0.472222                   169.444   169.444            0.472222\n",
       "2        0.206186                    0.975073           2.69444   2.69444            1                0.976426     1                           0.977395            0.0833333       0.555556                   169.444   169.444            0.555556\n",
       "3        0.298969                    0.844465           2.69444   2.69444            1                0.938935     1                           0.965459            0.25            0.805556                   169.444   169.444            0.805556\n",
       "4        0.402062                    0.0904979          1.61667   2.41809            0.6              0.560222     0.897436                    0.861552            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "5        0.505155                    0.00652377         0.269444  1.97959            0.1              0.0245879    0.734694                    0.690743            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "6        0.597938                    0.00211604         0         1.67241            0                0.00366596   0.62069                     0.584128            0               1                          -100      67.2414            0.639344\n",
       "7        0.701031                    0.000546271        0         1.42647            0                0.0011275    0.529412                    0.498393            0               1                          -100      42.6471            0.47541\n",
       "8        0.793814                    0.0004147          0         1.25974            0                0.000459181  0.467532                    0.440193            0               1                          -100      25.974             0.327869\n",
       "9        0.896907                    8.79503e-05        0         1.11494            0                0.00025194   0.413793                    0.389625            0               1                          -100      11.4943            0.163934\n",
       "10       1                           9.42667e-06        0         1                  0                3.66146e-05  0.371134                    0.349461            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.045365285386998806\n",
       "RMSE: 0.21299128007267998\n",
       "LogLoss: 0.17370145001620638\n",
       "Mean Per-Class Error: 0.053508384819064427\n",
       "AUC: 0.9787621359223301\n",
       "AUCPR: 0.9683618656971925\n",
       "Gini: 0.9575242718446602\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6758263066539283\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    198         8             0.0388   (8.0/206.0)\n",
       "republican  9           123           0.0682   (9.0/132.0)\n",
       "Total       207         131           0.0503   (17.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.675826     0.935361  85\n",
       "max f2                       0.160007     0.955556  101\n",
       "max f0point5                 0.717727     0.941358  83\n",
       "max accuracy                 0.717727     0.949704  83\n",
       "max precision                0.980589     1         0\n",
       "max recall                   0.000147943  1         247\n",
       "max specificity              0.980589     1         0\n",
       "max absolute_mcc             0.675826     0.894217  85\n",
       "max min_per_class_accuracy   0.637812     0.939394  88\n",
       "max mean_per_class_accuracy  0.675826     0.946492  85\n",
       "max tns                      0.980589     206       0\n",
       "max fns                      0.980589     122       0\n",
       "max fps                      9.42542e-06  206       284\n",
       "max tps                      0.000147943  132       247\n",
       "max tnr                      0.980589     1         0\n",
       "max fnr                      0.980589     0.924242  0\n",
       "max fpr                      9.42542e-06  1         284\n",
       "max tpr                      0.000147943  1         247\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.48 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0295858                   0.980589           2.56061    2.56061            1                0.980589     1                           0.980589            0.0757576       0.0757576                  156.061   156.061            0.0757576\n",
       "2        0.0325444                   0.9804             2.56061    2.56061            1                0.980443     1                           0.980576            0.00757576      0.0833333                  156.061   156.061            0.0833333\n",
       "3        0.0414201                   0.979191           2.56061    2.56061            1                0.979675     1                           0.980383            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "4        0.0532544                   0.978574           2.56061    2.56061            1                0.978729     1                           0.980015            0.030303        0.136364                   156.061   156.061            0.136364\n",
       "5        0.100592                    0.972242           2.56061    2.56061            1                0.975007     1                           0.977658            0.121212        0.257576                   156.061   156.061            0.257576\n",
       "6        0.150888                    0.969037           2.56061    2.56061            1                0.969753     1                           0.975023            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "7        0.201183                    0.95494            2.25936    2.48529            0.882353         0.962748     0.970588                    0.971955            0.113636        0.5                        125.936   148.529            0.490291\n",
       "8        0.301775                    0.904843           2.48529    2.48529            0.970588         0.92112      0.970588                    0.95501             0.25            0.75                       148.529   148.529            0.735437\n",
       "9        0.399408                    0.512076           1.93985    2.35196            0.757576         0.802513     0.918519                    0.917733            0.189394        0.939394                   93.9853   135.196            0.885996\n",
       "10       0.5                         0.0382583          0.527184   1.98485            0.205882         0.161222     0.775148                    0.765535            0.0530303       0.992424                   -47.2816  98.4848            0.807958\n",
       "11       0.600592                    0.00531591         0          1.65241            0                0.015822     0.64532                     0.639968            0               0.992424                   -100      65.2411            0.64291\n",
       "12       0.698225                    0.00150747         0          1.42135            0                0.00292184   0.555085                    0.550889            0               0.992424                   -100      42.1353            0.482716\n",
       "13       0.798817                    0.000424642        0          1.24237            0                0.000770554  0.485185                    0.481615            0               0.992424                   -100      24.2368            0.317667\n",
       "14       0.899408                    0.000115977        0.0753119  1.11184            0.0294118        0.000240454  0.434211                    0.427777            0.00757576      1                          -92.4688  11.1842            0.165049\n",
       "15       1                           9.43e-06           0          1                  0                5.61221e-05  0.390533                    0.384752            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.9573698    0.025657585  0.95238096    0.9493671     0.95454544    1.0           0.9305556\n",
       "aic                      nan          0.0          nan           nan           nan           nan           nan\n",
       "auc                      0.983349     0.012088418  0.9726744     0.9715762     0.9906015     1.0           0.981893\n",
       "err                      0.04263019   0.025657585  0.04761905    0.050632913   0.045454547   0.0           0.06944445\n",
       "err_count                3.0          1.8708287    3.0           4.0           3.0           0.0           5.0\n",
       "f0point5                 0.9291124    0.045869946  0.89285713    0.93085104    0.9375        1.0           0.88435376\n",
       "f1                       0.94716555   0.032774556  0.9302326     0.9459459     0.94736844    1.0           0.9122807\n",
       "f2                       0.9663776    0.021486698  0.9708738     0.96153843    0.9574468     1.0           0.942029\n",
       "lift_top_group           2.3110318    0.4709629    1.575         2.1944444     2.357143      2.7619047     2.6666667\n",
       "loglikelihood            nan          0.0          nan           nan           nan           nan           nan\n",
       "---                      ---          ---          ---           ---           ---           ---           ---\n",
       "mcc                      0.9130176    0.052324463  0.8993875     0.8995539     0.9078227     1.0           0.8583237\n",
       "mean_per_class_accuracy  0.9618416    0.023616146  0.96511626    0.95122737    0.95582706    1.0           0.93703705\n",
       "mean_per_class_error     0.038158447  0.023616146  0.034883723   0.04877261    0.04417293    0.0           0.062962964\n",
       "mse                      0.043603137  0.020292524  0.042560603   0.062034946   0.044191487   0.010693788   0.05853486\n",
       "pr_auc                   0.95631075   0.061383415  0.84846264    0.97298276    0.9880001     1.0           0.9721083\n",
       "precision                0.9176638    0.05450617   0.8695652     0.92105263    0.9310345     1.0           0.8666667\n",
       "r2                       0.8153016    0.0833901    0.80357784    0.7498966     0.8190807     0.95370156    0.75025123\n",
       "recall                   0.97989416   0.018692493  1.0           0.9722222     0.96428573    1.0           0.962963\n",
       "rmse                     0.20218773   0.058344446  0.20630221    0.24906816    0.21021771    0.10341077    0.24193978\n",
       "specificity              0.94378895   0.03394071   0.9302326     0.9302326     0.94736844    1.0           0.9111111\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:47:52  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:47:52  1.135 sec   112666 obs/sec    1         1             338        0.593441         1.20973             -0.47961       0.961312        0.942401           2.52121          0.0976331                        0.580565           1.17328               -0.444151        0.970401          0.949013             2.69444            0.0824742\n",
       "    2025-05-26 14:47:52  1.160 sec   35578 obs/sec     2         2             676        0.263768         0.246487            0.707696       0.971591        0.942394           2.46212          0.0710059                        0.259186           0.234921              0.712171         0.974499          0.957264             2.69444            0.0618557\n",
       "    2025-05-26 14:47:52  1.182 sec   31687 obs/sec     3         3             1014       0.222741         0.17967             0.791555       0.979994        0.955802           2.48059          0.0502959                        0.237719           0.200098              0.757874         0.978597          0.966334             2.69444            0.0515464\n",
       "    2025-05-26 14:47:52  1.207 sec   28765 obs/sec     4         4             1352       0.206293         0.153169            0.821203       0.984665        0.968858           2.5235           0.0443787                        0.219144           0.173054              0.794236         0.981785          0.97151              2.69444            0.0412371\n",
       "    2025-05-26 14:47:52  1.231 sec   27258 obs/sec     5         5             1690       0.1924           0.134948            0.844475       0.986595        0.967645           2.48529          0.0414201                        0.219789           0.173743              0.793022         0.983151          0.973672             2.69444            0.0412371\n",
       "    2025-05-26 14:47:52  1.257 sec   26000 obs/sec     6         6             2028       0.181619         0.122195            0.861415       0.988618        0.970294           2.47525          0.035503                         0.209274           0.157206              0.812353         0.985428          0.977025             2.69444            0.0412371\n",
       "    2025-05-26 14:47:52  1.277 sec   26000 obs/sec     7         7             2366       0.173485         0.11306             0.873551       0.989942        0.974836           2.50241          0.0325444                        0.19745            0.139174              0.832958         0.989526          0.982445             2.69444            0.0412371\n",
       "    2025-05-26 14:47:52  1.299 sec   26000 obs/sec     8         8             2704       0.166301         0.105129            0.883806       0.990953        0.976361           2.50106          0.0266272                        0.193699           0.135082              0.839245         0.990437          0.984705             2.69444            0.0412371\n",
       "    2025-05-26 14:47:52  1.321 sec   25779 obs/sec     9         9             3042       0.163542         0.101648            0.88763        0.991376        0.97471            2.47525          0.0236686                        0.192596           0.137606              0.841069         0.991348          0.98676              2.69444            0.0412371\n",
       "    2025-05-26 14:47:52  1.347 sec   25037 obs/sec     10        10            3380       0.157611         0.0951942           0.895632       0.99202         0.979105           2.5104           0.0266272                        0.179638           0.116973              0.861737         0.99408           0.990975             2.69444            0.0309278\n",
       "    2025-05-26 14:47:52  1.372 sec   24622 obs/sec     11        11            3718       0.153527         0.0912178           0.900971       0.992332        0.978985           2.50494          0.0236686                        0.177116           0.117116              0.865592         0.994536          0.991804             2.69444            0.0309278\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.n                              1.0                    1.0                  0.04589768747785366\n",
       "synfuels-corporation-cutback.n                      0.8481765985488892     0.8481765985488892   0.03892934444622586\n",
       "el-salvador-aid.?                                   0.6823165416717529     0.6823165416717529   0.031316751390620026\n",
       "water-project-cost-sharing.y                        0.6660595536231995     0.6660595536231995   0.03057059323383632\n",
       "physician-fee-freeze.y                              0.6104474663734436     0.6104474663734436   0.028018127033255895\n",
       "crime.n                                             0.6070754528045654     0.6070754528045654   0.027863359408300443\n",
       "adoption-of-the-budget-resolution.y                 0.5845112204551697     0.5845112204551697   0.0268277133237502\n",
       "el-salvador-aid.n                                   0.5741303563117981     0.5741303563117981   0.026351255665547673\n",
       "aid-to-nicaraguan-contras.y                         0.5629771947860718     0.5629771947860718   0.025839351343449866\n",
       "adoption-of-the-budget-resolution.n                 0.5458343029022217     0.5458343029022217   0.02505253224929828\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[5,5,5], nfolds=5, activation=\"rectifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25e2cfec7e9f51",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [20,20,20], cross folds = 5, activation function = \"rectifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a1ea0298715d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:52:57.706023Z",
     "start_time": "2025-05-09T14:52:56.995506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_229\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-42.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-42 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-42 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-42 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-42 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-42 .h2o-table th,\n",
       "#h2o-table-42 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-42 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-42\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2607449</td>\n",
       "<td>0.4345804</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005905</td>\n",
       "<td>0.1591191</td>\n",
       "<td>0.5065914</td>\n",
       "<td>0.0370423</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042765</td>\n",
       "<td>0.0121264</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042644</td>\n",
       "<td>0.2220984</td>\n",
       "<td>1.0005179</td>\n",
       "<td>0.0247876</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0525343</td>\n",
       "<td>0.2167396</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0093173</td>\n",
       "<td>0.2141045</td>\n",
       "<td>0.9965032</td>\n",
       "<td>0.0184232</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0536754</td>\n",
       "<td>0.2165301</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0369952</td>\n",
       "<td>1.1533446</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.0230692</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.012480409338631761\n",
       "RMSE: 0.1117157524193959\n",
       "LogLoss: 0.05231274762045036\n",
       "Mean Per-Class Error: 0.012135922330097087\n",
       "AUC: 0.9973153868784936\n",
       "AUCPR: 0.9946770169199727\n",
       "Gini: 0.9946307737569873</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-43.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-43 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-43 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-43 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-43 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-43 .h2o-table th,\n",
       "#h2o-table-43 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-43 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-43\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3643252864977982</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>201.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0243</td>\n",
       "<td> (5.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>0.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>201.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0148</td>\n",
       "<td> (5.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-44.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-44 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-44 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-44 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-44 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-44 .h2o-table th,\n",
       "#h2o-table-44 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-44 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-44\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9814126</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9924812</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7518913</td>\n",
       "<td>0.9860248</td>\n",
       "<td>89.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6601833</td>\n",
       "<td>0.9852071</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9986951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3643253</td>\n",
       "<td>1.0</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9986951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9695966</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6601833</td>\n",
       "<td>0.9848485</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9878641</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9986951</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9986951</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000001</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.3643253</td>\n",
       "<td>132.0</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9986951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9986951</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000001</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.3643253</td>\n",
       "<td>1.0</td>\n",
       "<td>98.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-45.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-45 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-45 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-45 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-45 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-45 .h2o-table th,\n",
       "#h2o-table-45 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-45 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-45\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.25 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.9986603</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986709</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986709</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0454545</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0454545</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9982512</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985914</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986596</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9978483</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979905</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984163</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9976263</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982198</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9973750</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974802</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981328</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9960824</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9968098</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974713</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9930050</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9949553</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966326</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2071006</td>\n",
       "<td>0.9911866</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920798</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9953969</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.5303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5303030</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9758081</td>\n",
       "<td>2.4805871</td>\n",
       "<td>2.5355021</td>\n",
       "<td>0.96875</td>\n",
       "<td>0.9839651</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9918104</td>\n",
       "<td>0.2348485</td>\n",
       "<td>0.7651515</td>\n",
       "<td>148.0587121</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4472810</td>\n",
       "<td>2.3278237</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.8555675</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9585066</td>\n",
       "<td>0.2272727</td>\n",
       "<td>0.9924242</td>\n",
       "<td>132.7823691</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0079393</td>\n",
       "<td>0.0753119</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0928559</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7843520</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0006303</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0027220</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6534386</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0001070</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003059</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5621107</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8076923</td>\n",
       "<td>0.0000244</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2380952</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000571</td>\n",
       "<td>0.4835165</td>\n",
       "<td>0.4859350</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.8095238</td>\n",
       "<td>0.3155340</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000064</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000151</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4363839</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000020</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3924875</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.02497777782325209\n",
       "RMSE: 0.15804359469226234\n",
       "LogLoss: 0.09661960962432892\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.9903601378148524\n",
       "Gini: 0.9881602914389798</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-46.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-46 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-46 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-46 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-46 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-46 .h2o-table th,\n",
       "#h2o-table-46 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-46 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-46\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.55041510917735</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0164</td>\n",
       "<td> (1.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-47.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-47 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-47 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-47 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-47 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-47 .h2o-table th,\n",
       "#h2o-table-47 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-47 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-47\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9793814</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0186975</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9558288</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9779144</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9981316</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9981316</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000001</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0186975</td>\n",
       "<td>36.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9981316</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000001</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0186975</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-48.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-48 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-48 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-48 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-48 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-48 .h2o-table th,\n",
       "#h2o-table-48 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-48 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-48\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.44 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9978607</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981316</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9978494</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978494</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979435</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9976531</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979435</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0833333</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9972988</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976263</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978642</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9971110</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9972364</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9977386</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9965325</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9968606</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9972996</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9937892</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9953205</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966399</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9912272</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9923227</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9955606</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.8122057</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9466246</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9803735</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.1201933</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.5742891</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8762493</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0027337</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0181709</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7011313</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0009026</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016231</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5925869</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0001708</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004711</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5055110</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0000564</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001082</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4464380</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000187</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000381</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3951277</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000029</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3543931</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.03850106687593611\n",
       "RMSE: 0.19621688733627415\n",
       "LogLoss: 0.13218943553222182\n",
       "Mean Per-Class Error: 0.052441894674904385\n",
       "AUC: 0.989298323036187\n",
       "AUCPR: 0.9839598348497094\n",
       "Gini: 0.9785966460723741</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-49.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-49 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-49 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-49 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-49 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-49 .h2o-table th,\n",
       "#h2o-table-49 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-49 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-49\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6510281431932028</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>200.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0291</td>\n",
       "<td> (6.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>10.0</td>\n",
       "<td>122.0</td>\n",
       "<td>0.0758</td>\n",
       "<td> (10.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>210.0</td>\n",
       "<td>128.0</td>\n",
       "<td>0.0473</td>\n",
       "<td> (16.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-50.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-50 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-50 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-50 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-50 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-50 .h2o-table th,\n",
       "#h2o-table-50 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-50 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-50\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6510281</td>\n",
       "<td>0.9384615</td>\n",
       "<td>115.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2212637</td>\n",
       "<td>0.9629630</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8879437</td>\n",
       "<td>0.9503425</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6510281</td>\n",
       "<td>0.9526627</td>\n",
       "<td>115.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9990595</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0034831</td>\n",
       "<td>1.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9990595</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6510281</td>\n",
       "<td>0.9002961</td>\n",
       "<td>115.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5073643</td>\n",
       "<td>0.9469697</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2212637</td>\n",
       "<td>0.9511621</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9990595</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9990595</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000010</td>\n",
       "<td>206.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0034831</td>\n",
       "<td>132.0</td>\n",
       "<td>183.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9990595</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9990595</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000010</td>\n",
       "<td>1.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0034831</td>\n",
       "<td>1.0</td>\n",
       "<td>183.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-51.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-51 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-51 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-51 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-51 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-51 .h2o-table th,\n",
       "#h2o-table-51 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-51 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-51\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.41 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.9980777</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983312</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983312</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0454545</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0454545</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9975006</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976869</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982391</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9970750</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9972863</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978926</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9964706</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9967137</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976400</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9955652</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962275</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973907</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1035503</td>\n",
       "<td>0.9929729</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9940890</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9956927</td>\n",
       "<td>0.1363636</td>\n",
       "<td>0.2651515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2651515</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.9905460</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9915587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943412</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3939394</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3939394</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2041420</td>\n",
       "<td>0.9827868</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872403</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925917</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5227273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5227273</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9483370</td>\n",
       "<td>2.4830119</td>\n",
       "<td>2.5355021</td>\n",
       "<td>0.9696970</td>\n",
       "<td>0.9711307</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9856484</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7651515</td>\n",
       "<td>148.3011938</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.5023577</td>\n",
       "<td>1.8622590</td>\n",
       "<td>2.3709315</td>\n",
       "<td>0.7272727</td>\n",
       "<td>0.7799690</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.9353712</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.9469697</td>\n",
       "<td>86.2258953</td>\n",
       "<td>137.0931538</td>\n",
       "<td>0.8984260</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0243000</td>\n",
       "<td>0.4518717</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.1945930</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7863389</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-54.8128342</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0023807</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0080145</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6559792</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0005504</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0011112</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5644086</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0001531</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003199</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4933752</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000271</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000740</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4382034</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>1e-06</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000091</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3941247</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-52.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-52 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-52 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-52 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-52 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-52 .h2o-table th,\n",
       "#h2o-table-52 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-52 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-52\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9675959</td>\n",
       "<td>0.0365551</td>\n",
       "<td>0.9682540</td>\n",
       "<td>0.9113924</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9583333</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9874926</td>\n",
       "<td>0.0121372</td>\n",
       "<td>0.9802325</td>\n",
       "<td>0.9728682</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9843621</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0324041</td>\n",
       "<td>0.0365551</td>\n",
       "<td>0.0317460</td>\n",
       "<td>0.0886076</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0416667</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>2.4</td>\n",
       "<td>2.8809721</td>\n",
       "<td>2.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9515834</td>\n",
       "<td>0.0464254</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.8967391</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9352518</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.960389</td>\n",
       "<td>0.0405974</td>\n",
       "<td>0.9523810</td>\n",
       "<td>0.9041096</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9454545</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9695753</td>\n",
       "<td>0.0371373</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9116022</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9558824</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6260316</td>\n",
       "<td>0.3718952</td>\n",
       "<td>3.15</td>\n",
       "<td>2.1944444</td>\n",
       "<td>2.357143</td>\n",
       "<td>2.7619047</td>\n",
       "<td>2.6666667</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9330472</td>\n",
       "<td>0.0736982</td>\n",
       "<td>0.931025</td>\n",
       "<td>0.8220518</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9121593</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9695650</td>\n",
       "<td>0.0365534</td>\n",
       "<td>0.9767442</td>\n",
       "<td>0.9118217</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9592593</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0304350</td>\n",
       "<td>0.0365534</td>\n",
       "<td>0.0232558</td>\n",
       "<td>0.0881783</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0407407</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0361900</td>\n",
       "<td>0.0277137</td>\n",
       "<td>0.0354948</td>\n",
       "<td>0.0806653</td>\n",
       "<td>0.0125921</td>\n",
       "<td>0.0131927</td>\n",
       "<td>0.0390052</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9777763</td>\n",
       "<td>0.0255855</td>\n",
       "<td>0.9381166</td>\n",
       "<td>0.9705698</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9801950</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9459109</td>\n",
       "<td>0.0510531</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.8918919</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8471762</td>\n",
       "<td>0.1111754</td>\n",
       "<td>0.8361872</td>\n",
       "<td>0.6747855</td>\n",
       "<td>0.9484481</td>\n",
       "<td>0.9428825</td>\n",
       "<td>0.8335779</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9759259</td>\n",
       "<td>0.0368048</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1793977</td>\n",
       "<td>0.0707680</td>\n",
       "<td>0.1884007</td>\n",
       "<td>0.2840163</td>\n",
       "<td>0.1122146</td>\n",
       "<td>0.1148596</td>\n",
       "<td>0.1974973</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9632042</td>\n",
       "<td>0.0388017</td>\n",
       "<td>0.9534883</td>\n",
       "<td>0.9069768</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9555556</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-53.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-53 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-53 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-53 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-53 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-53 .h2o-table th,\n",
       "#h2o-table-53 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-53 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-53\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.443 sec</td>\n",
       "<td>56333 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2442084</td>\n",
       "<td>0.1914721</td>\n",
       "<td>0.7494390</td>\n",
       "<td>0.9782657</td>\n",
       "<td>0.9632222</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0739645</td>\n",
       "<td>0.2653601</td>\n",
       "<td>0.2668435</td>\n",
       "<td>0.6982952</td>\n",
       "<td>0.9599271</td>\n",
       "<td>0.9498725</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0824742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.481 sec</td>\n",
       "<td>20484 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1991910</td>\n",
       "<td>0.1337020</td>\n",
       "<td>0.8333015</td>\n",
       "<td>0.9878641</td>\n",
       "<td>0.9776065</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0473373</td>\n",
       "<td>0.2442234</td>\n",
       "<td>0.2079910</td>\n",
       "<td>0.7444442</td>\n",
       "<td>0.9763206</td>\n",
       "<td>0.9681289</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0721649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.524 sec</td>\n",
       "<td>17186 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1667623</td>\n",
       "<td>0.1023519</td>\n",
       "<td>0.8831609</td>\n",
       "<td>0.9911739</td>\n",
       "<td>0.9799595</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.2209233</td>\n",
       "<td>0.1727135</td>\n",
       "<td>0.7908807</td>\n",
       "<td>0.9840619</td>\n",
       "<td>0.9771650</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.555 sec</td>\n",
       "<td>17113 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1548635</td>\n",
       "<td>0.0900348</td>\n",
       "<td>0.8992394</td>\n",
       "<td>0.9926817</td>\n",
       "<td>0.9842176</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.2063223</td>\n",
       "<td>0.1460797</td>\n",
       "<td>0.8176089</td>\n",
       "<td>0.9867942</td>\n",
       "<td>0.9804180</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0515464</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.591 sec</td>\n",
       "<td>17244 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1457774</td>\n",
       "<td>0.0807554</td>\n",
       "<td>0.9107162</td>\n",
       "<td>0.9939688</td>\n",
       "<td>0.9873278</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1937603</td>\n",
       "<td>0.1326955</td>\n",
       "<td>0.8391427</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9854463</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.621 sec</td>\n",
       "<td>17186 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1469839</td>\n",
       "<td>0.0811612</td>\n",
       "<td>0.9092322</td>\n",
       "<td>0.9949250</td>\n",
       "<td>0.9889383</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.2147133</td>\n",
       "<td>0.1613537</td>\n",
       "<td>0.8024719</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9849707</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.651 sec</td>\n",
       "<td>17144 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1302942</td>\n",
       "<td>0.0669045</td>\n",
       "<td>0.9286749</td>\n",
       "<td>0.9964695</td>\n",
       "<td>0.9930110</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1734686</td>\n",
       "<td>0.1102418</td>\n",
       "<td>0.8710703</td>\n",
       "<td>0.9931694</td>\n",
       "<td>0.9888850</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.685 sec</td>\n",
       "<td>17006 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1257635</td>\n",
       "<td>0.0626863</td>\n",
       "<td>0.9335490</td>\n",
       "<td>0.9968005</td>\n",
       "<td>0.9936383</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1701342</td>\n",
       "<td>0.1075819</td>\n",
       "<td>0.8759793</td>\n",
       "<td>0.9931694</td>\n",
       "<td>0.9884437</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.712 sec</td>\n",
       "<td>17089 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1352762</td>\n",
       "<td>0.0704332</td>\n",
       "<td>0.9231161</td>\n",
       "<td>0.9964328</td>\n",
       "<td>0.9920966</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.2001105</td>\n",
       "<td>0.1420475</td>\n",
       "<td>0.8284263</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.742 sec</td>\n",
       "<td>17157 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1204756</td>\n",
       "<td>0.0587115</td>\n",
       "<td>0.9390196</td>\n",
       "<td>0.9970947</td>\n",
       "<td>0.9939040</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1596359</td>\n",
       "<td>0.0953582</td>\n",
       "<td>0.8908127</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:47:58</td>\n",
       "<td> 1.773 sec</td>\n",
       "<td>16977 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1117158</td>\n",
       "<td>0.0523127</td>\n",
       "<td>0.9475650</td>\n",
       "<td>0.9973154</td>\n",
       "<td>0.9946770</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1580436</td>\n",
       "<td>0.0966196</td>\n",
       "<td>0.8929800</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-54.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-54 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-54 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-54 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-54 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-54 .h2o-table th,\n",
       "#h2o-table-54 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-54 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-54\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>el-salvador-aid.?</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0269998</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.9803649</td>\n",
       "<td>0.9803649</td>\n",
       "<td>0.0264697</td></tr>\n",
       "<tr><td>crime.?</td>\n",
       "<td>0.9715016</td>\n",
       "<td>0.9715016</td>\n",
       "<td>0.0262304</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9657401</td>\n",
       "<td>0.9657401</td>\n",
       "<td>0.0260748</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.9546074</td>\n",
       "<td>0.9546074</td>\n",
       "<td>0.0257742</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9333184</td>\n",
       "<td>0.9333184</td>\n",
       "<td>0.0251994</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.?</td>\n",
       "<td>0.9329675</td>\n",
       "<td>0.9329675</td>\n",
       "<td>0.0251900</td></tr>\n",
       "<tr><td>superfund-right-to-sue.y</td>\n",
       "<td>0.9286214</td>\n",
       "<td>0.9286214</td>\n",
       "<td>0.0250726</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.y</td>\n",
       "<td>0.8797601</td>\n",
       "<td>0.8797601</td>\n",
       "<td>0.0237534</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.8578669</td>\n",
       "<td>0.8578669</td>\n",
       "<td>0.0231623</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_229\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight            weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  -------------------  ----------  ---------------------  -------------------  -----------------------  --------------------\n",
       "    1        64       Input      0.0\n",
       "    2        20       Rectifier  0.0        0.0   0.0   0.26074486959576004   0.4345804452896118   0.0         0.0005905363869032953  0.15911906957626343  0.506591416448452        0.03704230487346649\n",
       "    3        20       Rectifier  0.0        0.0   0.0   0.004276484863075893  0.0121263787150383   0.0         0.004264391815522686   0.22209841012954712  1.0005178812546662       0.02478756010532379\n",
       "    4        20       Rectifier  0.0        0.0   0.0   0.05253426652980124   0.21673959493637085  0.0         0.00931727505492745    0.2141045331954956   0.9965031925472785       0.018423162400722504\n",
       "    5        2        Softmax               0.0   0.0   0.05367538485006662   0.21653014421463013  0.0         0.036995189543813464   1.1533446311950684   -1.0408340855860843e-17  0.023069165647029877\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.012480409338631761\n",
       "RMSE: 0.1117157524193959\n",
       "LogLoss: 0.05231274762045036\n",
       "Mean Per-Class Error: 0.012135922330097087\n",
       "AUC: 0.9973153868784936\n",
       "AUCPR: 0.9946770169199727\n",
       "Gini: 0.9946307737569873\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3643252864977982\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    201         5             0.0243   (5.0/206.0)\n",
       "republican  0           132           0        (0.0/132.0)\n",
       "Total       201         137           0.0148   (5.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.364325     0.981413  98\n",
       "max f2                       0.364325     0.992481  98\n",
       "max f0point5                 0.751891     0.986025  89\n",
       "max accuracy                 0.660183     0.985207  94\n",
       "max precision                0.998695     1         0\n",
       "max recall                   0.364325     1         98\n",
       "max specificity              0.998695     1         0\n",
       "max absolute_mcc             0.364325     0.969597  98\n",
       "max min_per_class_accuracy   0.660183     0.984848  94\n",
       "max mean_per_class_accuracy  0.364325     0.987864  98\n",
       "max tns                      0.998695     206       0\n",
       "max fns                      0.998695     131       0\n",
       "max fps                      9.94648e-08  206       269\n",
       "max tps                      0.364325     132       98\n",
       "max tnr                      0.998695     1         0\n",
       "max fnr                      0.998695     0.992424  0\n",
       "max fpr                      9.94648e-08  1         269\n",
       "max tpr                      0.364325     1         98\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.25 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0177515                   0.99866            2.56061    2.56061            1                0.998671     1                           0.998671            0.0454545       0.0454545                  156.061   156.061            0.0454545\n",
       "2        0.0207101                   0.998251           2.56061    2.56061            1                0.998591     1                           0.99866             0.00757576      0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.997848           2.56061    2.56061            1                0.997991     1                           0.998416            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0443787                   0.997626           2.56061    2.56061            1                0.99768      1                           0.99822             0.030303        0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.997375           2.56061    2.56061            1                0.99748      1                           0.998133            0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.996082           2.56061    2.56061            1                0.99681      1                           0.997471            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.993005           2.56061    2.56061            1                0.994955     1                           0.996633            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.207101                    0.991187           2.56061    2.56061            1                0.99208      1                           0.995397            0.143939        0.530303                   156.061   156.061            0.530303\n",
       "9        0.301775                    0.975808           2.48059    2.5355             0.96875          0.983965     0.990196                    0.99181             0.234848        0.765152                   148.059   153.55             0.760297\n",
       "10       0.399408                    0.447281           2.32782    2.48474            0.909091         0.855567     0.97037                     0.958507            0.227273        0.992424                   132.782   148.474            0.973007\n",
       "11       0.5                         0.00793931         0.0753119  2                  0.0294118        0.0928559    0.781065                    0.784352            0.00757576      1                          -92.4688  100                0.820388\n",
       "12       0.600592                    0.000630331        0          1.66502            0                0.00272203   0.650246                    0.653439            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.00010698         0          1.4322             0                0.000305936  0.559322                    0.562111            0               1                          -100      43.2203            0.495146\n",
       "14       0.807692                    2.44045e-05        0          1.2381             0                5.70641e-05  0.483516                    0.485935            0               1                          -100      23.8095            0.315534\n",
       "15       0.899408                    6.4403e-06         0          1.11184            0                1.51499e-05  0.434211                    0.436384            0               1                          -100      11.1842            0.165049\n",
       "16       1                           9.94648e-08        0          1                  0                2.0128e-06   0.390533                    0.392488            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.02497777782325209\n",
       "RMSE: 0.15804359469226234\n",
       "LogLoss: 0.09661960962432892\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.9903601378148524\n",
       "Gini: 0.9881602914389798\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.55041510917735\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    60          1             0.0164   (1.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       61          36            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.550415     0.972222  32\n",
       "max f2                       0.550415     0.972222  32\n",
       "max f0point5                 0.550415     0.972222  32\n",
       "max accuracy                 0.550415     0.979381  32\n",
       "max precision                0.998132     1         0\n",
       "max recall                   0.0186975    1         39\n",
       "max specificity              0.998132     1         0\n",
       "max absolute_mcc             0.550415     0.955829  32\n",
       "max min_per_class_accuracy   0.550415     0.972222  32\n",
       "max mean_per_class_accuracy  0.550415     0.977914  32\n",
       "max tns                      0.998132     61        0\n",
       "max fns                      0.998132     35        0\n",
       "max fps                      9.94648e-08  61        91\n",
       "max tps                      0.0186975    36        39\n",
       "max tnr                      0.998132     1         0\n",
       "max fnr                      0.998132     0.972222  0\n",
       "max fpr                      9.94648e-08  1         91\n",
       "max tpr                      0.0186975    1         39\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.44 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0103093                   0.997861           2.69444   2.69444            1                0.998132     1                           0.998132            0.0277778       0.0277778                  169.444   169.444            0.0277778\n",
       "2        0.0309278                   0.997849           2.69444   2.69444            1                0.997849     1                           0.997943            0.0555556       0.0833333                  169.444   169.444            0.0833333\n",
       "3        0.0309278                   0.997653           0         2.69444            0                0            1                           0.997943            0               0.0833333                  -100      169.444            0.0833333\n",
       "4        0.0412371                   0.997299           2.69444   2.69444            1                0.997626     1                           0.997864            0.0277778       0.111111                   169.444   169.444            0.111111\n",
       "5        0.0515464                   0.997111           2.69444   2.69444            1                0.997236     1                           0.997739            0.0277778       0.138889                   169.444   169.444            0.138889\n",
       "6        0.103093                    0.996533           2.69444   2.69444            1                0.996861     1                           0.9973              0.138889        0.277778                   169.444   169.444            0.277778\n",
       "7        0.154639                    0.993789           2.69444   2.69444            1                0.995321     1                           0.99664             0.138889        0.416667                   169.444   169.444            0.416667\n",
       "8        0.206186                    0.991227           2.69444   2.69444            1                0.992323     1                           0.995561            0.138889        0.555556                   169.444   169.444            0.555556\n",
       "9        0.298969                    0.812206           2.69444   2.69444            1                0.946625     1                           0.980374            0.25            0.805556                   169.444   169.444            0.805556\n",
       "10       0.402062                    0.120193           1.61667   2.41809            0.6              0.574289     0.897436                    0.876249            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "11       0.505155                    0.00273365         0.269444  1.97959            0.1              0.0181709    0.734694                    0.701131            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "12       0.597938                    0.000902566        0         1.67241            0                0.00162306   0.62069                     0.592587            0               1                          -100      67.2414            0.639344\n",
       "13       0.701031                    0.00017083         0         1.42647            0                0.000471052  0.529412                    0.505511            0               1                          -100      42.6471            0.47541\n",
       "14       0.793814                    5.64032e-05        0         1.25974            0                0.000108226  0.467532                    0.446438            0               1                          -100      25.974             0.327869\n",
       "15       0.896907                    1.87338e-05        0         1.11494            0                3.81128e-05  0.413793                    0.395128            0               1                          -100      11.4943            0.163934\n",
       "16       1                           9.94648e-08        0         1                  0                2.92246e-06  0.371134                    0.354393            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.03850106687593611\n",
       "RMSE: 0.19621688733627415\n",
       "LogLoss: 0.13218943553222182\n",
       "Mean Per-Class Error: 0.052441894674904385\n",
       "AUC: 0.989298323036187\n",
       "AUCPR: 0.9839598348497094\n",
       "Gini: 0.9785966460723741\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6510281431932028\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    200         6             0.0291   (6.0/206.0)\n",
       "republican  10          122           0.0758   (10.0/132.0)\n",
       "Total       210         128           0.0473   (16.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.651028     0.938462  115\n",
       "max f2                       0.221264     0.962963  134\n",
       "max f0point5                 0.887944     0.950342  100\n",
       "max accuracy                 0.651028     0.952663  115\n",
       "max precision                0.999059     1         0\n",
       "max recall                   0.00348308   1         183\n",
       "max specificity              0.999059     1         0\n",
       "max absolute_mcc             0.651028     0.900296  115\n",
       "max min_per_class_accuracy   0.507364     0.94697   122\n",
       "max mean_per_class_accuracy  0.221264     0.951162  134\n",
       "max tns                      0.999059     206       0\n",
       "max fns                      0.999059     131       0\n",
       "max fps                      9.98531e-07  206       317\n",
       "max tps                      0.00348308   132       183\n",
       "max tnr                      0.999059     1         0\n",
       "max fnr                      0.999059     0.992424  0\n",
       "max fpr                      9.98531e-07  1         317\n",
       "max tpr                      0.00348308   1         183\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.41 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0177515                   0.998078           2.56061    2.56061            1                0.998331     1                           0.998331            0.0454545       0.0454545                  156.061   156.061            0.0454545\n",
       "2        0.0207101                   0.997501           2.56061    2.56061            1                0.997687     1                           0.998239            0.00757576      0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.997075           2.56061    2.56061            1                0.997286     1                           0.997893            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.996471           2.56061    2.56061            1                0.996714     1                           0.99764             0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.995565           2.56061    2.56061            1                0.996228     1                           0.997391            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.10355                     0.992973           2.56061    2.56061            1                0.994089     1                           0.995693            0.136364        0.265152                   156.061   156.061            0.265152\n",
       "7        0.153846                    0.990546           2.56061    2.56061            1                0.991559     1                           0.994341            0.128788        0.393939                   156.061   156.061            0.393939\n",
       "8        0.204142                    0.982787           2.56061    2.56061            1                0.98724      1                           0.992592            0.128788        0.522727                   156.061   156.061            0.522727\n",
       "9        0.301775                    0.948337           2.48301    2.5355             0.969697         0.971131     0.990196                    0.985648            0.242424        0.765152                   148.301   153.55             0.760297\n",
       "10       0.399408                    0.502358           1.86226    2.37093            0.727273         0.779969     0.925926                    0.935371            0.181818        0.94697                    86.2259   137.093            0.898426\n",
       "11       0.5                         0.0243             0.451872   1.98485            0.176471         0.194593     0.775148                    0.786339            0.0454545       0.992424                   -54.8128  98.4848            0.807958\n",
       "12       0.600592                    0.00238067         0.0753119  1.66502            0.0294118        0.00801448   0.650246                    0.655979            0.00757576      1                          -92.4688  66.5025            0.65534\n",
       "13       0.698225                    0.00055044         0          1.4322             0                0.00111115   0.559322                    0.564409            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    0.000153078        0          1.25185            0                0.000319898  0.488889                    0.493375            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    2.7061e-05         0          1.11184            0                7.39779e-05  0.434211                    0.438203            0               1                          -100      11.1842            0.165049\n",
       "16       1                           1e-06              0          1                  0                9.10765e-06  0.390533                    0.394125            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.96759593   0.036555137  0.96825397    0.9113924     1.0           1.0           0.9583333\n",
       "aic                      nan          0.0          nan           nan           nan           nan           nan\n",
       "auc                      0.98749256   0.012137243  0.98023254    0.9728682     1.0           1.0           0.9843621\n",
       "err                      0.032404058  0.036555137  0.031746034   0.088607594   0.0           0.0           0.041666668\n",
       "err_count                2.4          2.8809721    2.0           7.0           0.0           0.0           3.0\n",
       "f0point5                 0.9515834    0.046425357  0.9259259     0.8967391     1.0           1.0           0.9352518\n",
       "f1                       0.960389     0.04059742   0.95238096    0.9041096     1.0           1.0           0.94545454\n",
       "f2                       0.96957535   0.037137263  0.98039216    0.9116022     1.0           1.0           0.9558824\n",
       "lift_top_group           2.6260316    0.37189522   3.15          2.1944444     2.357143      2.7619047     2.6666667\n",
       "loglikelihood            nan          0.0          nan           nan           nan           nan           nan\n",
       "---                      ---          ---          ---           ---           ---           ---           ---\n",
       "mcc                      0.93304724   0.07369824   0.931025      0.8220518     1.0           1.0           0.9121593\n",
       "mean_per_class_accuracy  0.96956503   0.03655344   0.9767442     0.9118217     1.0           1.0           0.9592593\n",
       "mean_per_class_error     0.03043497   0.03655344   0.023255814   0.08817829    0.0           0.0           0.04074074\n",
       "mse                      0.03619002   0.027713686  0.035494823   0.08066527    0.012592108   0.01319272    0.03900519\n",
       "pr_auc                   0.9777763    0.025585463  0.93811655    0.9705698     1.0           1.0           0.98019505\n",
       "precision                0.9459109    0.051053118  0.90909094    0.8918919     1.0           1.0           0.9285714\n",
       "r2                       0.84717625   0.11117542   0.83618724    0.67478555    0.9484481     0.9428825     0.8335779\n",
       "recall                   0.9759259    0.03680483   1.0           0.9166667     1.0           1.0           0.962963\n",
       "rmse                     0.17939769   0.07076802   0.1884007     0.2840163     0.112214565   0.114859566   0.19749732\n",
       "specificity              0.96320415   0.0388017    0.95348835    0.90697676    1.0           1.0           0.95555556\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:47:58  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:47:58  1.443 sec   56333 obs/sec     1         1             338        0.244208         0.191472            0.749439       0.978266        0.963222           2.56061          0.0739645                        0.26536            0.266844              0.698295         0.959927          0.949872             2.69444            0.0824742\n",
       "    2025-05-26 14:47:58  1.481 sec   20484 obs/sec     2         2             676        0.199191         0.133702            0.833301       0.987864        0.977607           2.56061          0.0473373                        0.244223           0.207991              0.744444         0.976321          0.968129             2.69444            0.0721649\n",
       "    2025-05-26 14:47:58  1.524 sec   17186 obs/sec     3         3             1014       0.166762         0.102352            0.883161       0.991174        0.97996            2.56061          0.0266272                        0.220923           0.172713              0.790881         0.984062          0.977165             2.69444            0.0618557\n",
       "    2025-05-26 14:47:58  1.555 sec   17113 obs/sec     4         4             1352       0.154864         0.0900348           0.899239       0.992682        0.984218           2.56061          0.0236686                        0.206322           0.14608               0.817609         0.986794          0.980418             2.69444            0.0515464\n",
       "    2025-05-26 14:47:58  1.591 sec   17244 obs/sec     5         5             1690       0.145777         0.0807554           0.910716       0.993969        0.987328           2.56061          0.0207101                        0.19376            0.132695              0.839143         0.990437          0.985446             2.69444            0.0412371\n",
       "    2025-05-26 14:47:58  1.621 sec   17186 obs/sec     6         6             2028       0.146984         0.0811612           0.909232       0.994925        0.988938           2.56061          0.0207101                        0.214713           0.161354              0.802472         0.990437          0.984971             2.69444            0.0412371\n",
       "    2025-05-26 14:47:58  1.651 sec   17144 obs/sec     7         7             2366       0.130294         0.0669045           0.928675       0.99647         0.993011           2.56061          0.0177515                        0.173469           0.110242              0.87107          0.993169          0.988885             2.69444            0.0206186\n",
       "    2025-05-26 14:47:58  1.685 sec   17006 obs/sec     8         8             2704       0.125763         0.0626863           0.933549       0.996801        0.993638           2.56061          0.0177515                        0.170134           0.107582              0.875979         0.993169          0.988444             2.69444            0.0206186\n",
       "    2025-05-26 14:47:58  1.712 sec   17089 obs/sec     9         9             3042       0.135276         0.0704332           0.923116       0.996433        0.992097           2.56061          0.0147929                        0.20011            0.142048              0.828426         0.99408           0.99036              2.69444            0.0206186\n",
       "    2025-05-26 14:47:58  1.742 sec   17157 obs/sec     10        10            3380       0.120476         0.0587115           0.93902        0.997095        0.993904           2.56061          0.0118343                        0.159636           0.0953582             0.890813         0.99408           0.99036              2.69444            0.0206186\n",
       "    2025-05-26 14:47:58  1.773 sec   16977 obs/sec     11        11            3718       0.111716         0.0523127           0.947565       0.997315        0.994677           2.56061          0.0147929                        0.158044           0.0966196             0.89298          0.99408           0.99036              2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "el-salvador-aid.?                                   1.0                    1.0                  0.026999829121300226\n",
       "duty-free-exports.?                                 0.9803648591041565     0.9803648591041565   0.026469683672339796\n",
       "crime.?                                             0.9715016484260559     0.9715016484260559   0.026230378498564997\n",
       "synfuels-corporation-cutback.n                      0.9657400846481323     0.9657400846481323   0.026074817261089588\n",
       "adoption-of-the-budget-resolution.y                 0.9546074271202087     0.9546074271202087   0.025774237410169695\n",
       "physician-fee-freeze.n                              0.9333184361457825     0.9333184361457825   0.02519943829169528\n",
       "synfuels-corporation-cutback.?                      0.9329675436019897     0.9329675436019897   0.02518996425297294\n",
       "superfund-right-to-sue.y                            0.9286213517189026     0.9286213517189026   0.025072617814801204\n",
       "export-administration-act-south-africa.y            0.8797601461410522     0.8797601461410522   0.023753373613538523\n",
       "mx-missile.n                                        0.8578668832778931     0.8578668832778931   0.02316225925732552\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[20,20,20], nfolds=5, activation=\"rectifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678061c7fcfc8d0c",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [100,100,100], cross folds = 5, activation function = \"rectifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3bf6be6e288e00b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:53:08.817323Z",
     "start_time": "2025-05-09T14:53:06.267864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_398\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-55.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-55 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-55 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-55 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-55 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-55 .h2o-table th,\n",
       "#h2o-table-55 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-55 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-55\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2531760</td>\n",
       "<td>0.4307860</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014980</td>\n",
       "<td>0.1101663</td>\n",
       "<td>0.4858640</td>\n",
       "<td>0.0238759</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0063497</td>\n",
       "<td>0.0084670</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0052929</td>\n",
       "<td>0.1014859</td>\n",
       "<td>0.9869213</td>\n",
       "<td>0.0116448</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0730199</td>\n",
       "<td>0.2197148</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0002623</td>\n",
       "<td>0.1006887</td>\n",
       "<td>0.9984620</td>\n",
       "<td>0.0033485</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0679939</td>\n",
       "<td>0.2369123</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0074745</td>\n",
       "<td>0.5512197</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0005024</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.037598742595516474\n",
       "RMSE: 0.19390395198529728\n",
       "LogLoss: 0.14963630711691328\n",
       "Mean Per-Class Error: 0.009708737864077669\n",
       "AUC: 0.9991909385113269\n",
       "AUCPR: 0.9987273854685967\n",
       "Gini: 0.9983818770226538</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-56.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-56 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-56 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-56 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-56 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-56 .h2o-table th,\n",
       "#h2o-table-56 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-56 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-56\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9625960973110883</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>202.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0194</td>\n",
       "<td> (4.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>0.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>202.0</td>\n",
       "<td>136.0</td>\n",
       "<td>0.0118</td>\n",
       "<td> (4.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-57.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-57 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-57 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-57 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-57 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-57 .h2o-table th,\n",
       "#h2o-table-57 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-57 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-57\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.9625961</td>\n",
       "<td>0.9850746</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.9625961</td>\n",
       "<td>0.9939759</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9996196</td>\n",
       "<td>0.9855769</td>\n",
       "<td>84.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9948693</td>\n",
       "<td>0.9881657</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.9625961</td>\n",
       "<td>1.0</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9625961</td>\n",
       "<td>0.9755726</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9948693</td>\n",
       "<td>0.9854369</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9625961</td>\n",
       "<td>0.9902913</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.9625961</td>\n",
       "<td>132.0</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.9625961</td>\n",
       "<td>1.0</td>\n",
       "<td>97.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-58.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-58 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-58 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-58 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-58 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-58 .h2o-table th,\n",
       "#h2o-table-58 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-58 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-58\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 43.81 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0236686</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0606061</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0532544</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1363636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1363636</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1363636</td>\n",
       "<td>0.3939394</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3939394</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9999996</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9999972</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.9648643</td>\n",
       "<td>2.2502296</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.8787879</td>\n",
       "<td>0.9985596</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9996477</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9924242</td>\n",
       "<td>125.0229568</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0059328</td>\n",
       "<td>0.0753119</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.3845872</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.8759077</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0002744</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015777</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.7294682</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0000335</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000898</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.6274788</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0000076</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000170</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.5484651</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000027</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4871239</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.4381233</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.027310181729469443\n",
       "RMSE: 0.16525792486131927\n",
       "LogLoss: 0.11265675456486371\n",
       "Mean Per-Class Error: 0.01639344262295082\n",
       "AUC: 0.9986338797814207\n",
       "AUCPR: 0.9977359063574717\n",
       "Gini: 0.9972677595628414</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-59.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-59 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-59 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-59 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-59 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-59 .h2o-table th,\n",
       "#h2o-table-59 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-59 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-59\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7588237642672655</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>59.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0328</td>\n",
       "<td> (2.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>0.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>59.0</td>\n",
       "<td>38.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-60.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-60 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-60 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-60 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-60 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-60 .h2o-table th,\n",
       "#h2o-table-60 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-60 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-60\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.7588238</td>\n",
       "<td>0.9729730</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.7588238</td>\n",
       "<td>0.9890110</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9981728</td>\n",
       "<td>0.9883721</td>\n",
       "<td>30.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9981728</td>\n",
       "<td>0.9793814</td>\n",
       "<td>30.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.7588238</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7588238</td>\n",
       "<td>0.9572393</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9974307</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7588238</td>\n",
       "<td>0.9836066</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.7588238</td>\n",
       "<td>36.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.7588238</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-61.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-61 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-61 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-61 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-61 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-61 .h2o-table th,\n",
       "#h2o-table-61 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-61 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-61\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 40.29 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0618557</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1666667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1666667</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1030928</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1546392</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2061856</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9999649</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999943</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999982</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.6308987</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.9341065</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9831029</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0054567</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0725729</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7972805</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0004519</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015301</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6738020</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0000337</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002727</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5747536</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0000112</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000182</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.5075767</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000013</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000054</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4492352</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.4029223</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.030483246542344196\n",
       "RMSE: 0.17459452036746226\n",
       "LogLoss: 0.11193598513180077\n",
       "Mean Per-Class Error: 0.03320829655781112\n",
       "AUC: 0.9944101206237128\n",
       "AUCPR: 0.9915398602508056\n",
       "Gini: 0.9888202412474256</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-62.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-62 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-62 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-62 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-62 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-62 .h2o-table th,\n",
       "#h2o-table-62 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-62 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-62\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19840922521394078</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>197.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0437</td>\n",
       "<td> (9.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>3.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.0227</td>\n",
       "<td> (3.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>200.0</td>\n",
       "<td>138.0</td>\n",
       "<td>0.0355</td>\n",
       "<td> (12.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-63.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-63 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-63 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-63 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-63 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-63 .h2o-table th,\n",
       "#h2o-table-63 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-63 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-63\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1984092</td>\n",
       "<td>0.9555556</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1984092</td>\n",
       "<td>0.9684685</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8895871</td>\n",
       "<td>0.9651899</td>\n",
       "<td>112.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4708151</td>\n",
       "<td>0.9644970</td>\n",
       "<td>119.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0067229</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1984092</td>\n",
       "<td>0.9266573</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4386508</td>\n",
       "<td>0.9621212</td>\n",
       "<td>121.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1984092</td>\n",
       "<td>0.9667917</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999995</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999995</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0067229</td>\n",
       "<td>132.0</td>\n",
       "<td>144.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999995</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0067229</td>\n",
       "<td>1.0</td>\n",
       "<td>144.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-64.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-64 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-64 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-64 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-64 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-64 .h2o-table th,\n",
       "#h2o-table-64 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-64 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-64\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.99 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9999962</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999980</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999980</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9999917</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999934</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999961</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9999857</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999887</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999934</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9999835</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999844</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999915</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9999784</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999810</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999896</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9999516</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999680</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999788</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9996916</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999413</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9990133</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998008</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9928392</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9967795</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987937</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.3234857</td>\n",
       "<td>1.9398531</td>\n",
       "<td>2.4088664</td>\n",
       "<td>0.7575758</td>\n",
       "<td>0.8572111</td>\n",
       "<td>0.9407407</td>\n",
       "<td>0.9641846</td>\n",
       "<td>0.1893939</td>\n",
       "<td>0.9621212</td>\n",
       "<td>93.9853076</td>\n",
       "<td>140.8866442</td>\n",
       "<td>0.9232863</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0008096</td>\n",
       "<td>0.3765597</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1470588</td>\n",
       "<td>0.0471212</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7796867</td>\n",
       "<td>0.0378788</td>\n",
       "<td>1.0</td>\n",
       "<td>-62.3440285</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0000859</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003429</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6491562</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0000266</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000438</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5583905</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>5.682e-06</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000143</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4880764</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000012</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000026</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4334892</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3898839</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-65.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-65 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-65 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-65 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-65 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-65 .h2o-table th,\n",
       "#h2o-table-65 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-65 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-65\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9720163</td>\n",
       "<td>0.0257485</td>\n",
       "<td>0.9523810</td>\n",
       "<td>0.9493671</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9583333</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9930826</td>\n",
       "<td>0.0079489</td>\n",
       "<td>0.9930233</td>\n",
       "<td>0.9806202</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9917695</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0279837</td>\n",
       "<td>0.0257485</td>\n",
       "<td>0.0476191</td>\n",
       "<td>0.0506329</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0416667</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>2.0</td>\n",
       "<td>1.8708287</td>\n",
       "<td>3.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9545107</td>\n",
       "<td>0.0458583</td>\n",
       "<td>0.8928571</td>\n",
       "<td>0.9444444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9352518</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9640263</td>\n",
       "<td>0.0333863</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9444444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9454545</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9742401</td>\n",
       "<td>0.0253143</td>\n",
       "<td>0.9708738</td>\n",
       "<td>0.9444444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9558824</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6260316</td>\n",
       "<td>0.3718952</td>\n",
       "<td>3.15</td>\n",
       "<td>2.1944444</td>\n",
       "<td>2.357143</td>\n",
       "<td>2.7619047</td>\n",
       "<td>2.6666667</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9418959</td>\n",
       "<td>0.0533295</td>\n",
       "<td>0.8993875</td>\n",
       "<td>0.8979328</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9121593</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9746684</td>\n",
       "<td>0.0238362</td>\n",
       "<td>0.9651163</td>\n",
       "<td>0.9489664</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9592593</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0253316</td>\n",
       "<td>0.0238362</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.0510336</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0407407</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0291705</td>\n",
       "<td>0.0206101</td>\n",
       "<td>0.0407371</td>\n",
       "<td>0.0528598</td>\n",
       "<td>0.0027387</td>\n",
       "<td>0.0132136</td>\n",
       "<td>0.0363032</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9902069</td>\n",
       "<td>0.0098234</td>\n",
       "<td>0.9857498</td>\n",
       "<td>0.9771707</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9881138</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9485162</td>\n",
       "<td>0.0546553</td>\n",
       "<td>0.8695652</td>\n",
       "<td>0.9444444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8751134</td>\n",
       "<td>0.0868484</td>\n",
       "<td>0.8119935</td>\n",
       "<td>0.7868875</td>\n",
       "<td>0.9887877</td>\n",
       "<td>0.9427921</td>\n",
       "<td>0.8451064</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.0261891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9444444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1579128</td>\n",
       "<td>0.0727498</td>\n",
       "<td>0.2018343</td>\n",
       "<td>0.2299126</td>\n",
       "<td>0.0523328</td>\n",
       "<td>0.1149505</td>\n",
       "<td>0.1905340</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9678553</td>\n",
       "<td>0.0309828</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9534883</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9555556</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-66.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-66 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-66 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-66 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-66 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-66 .h2o-table th,\n",
       "#h2o-table-66 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-66 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-66\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:03</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 1.626 sec</td>\n",
       "<td>5044 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2341813</td>\n",
       "<td>0.2406872</td>\n",
       "<td>0.7695925</td>\n",
       "<td>0.9933436</td>\n",
       "<td>0.9898243</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.2176876</td>\n",
       "<td>0.1812659</td>\n",
       "<td>0.7969615</td>\n",
       "<td>0.9936248</td>\n",
       "<td>0.9903706</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 1.708 sec</td>\n",
       "<td>5044 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.2074964</td>\n",
       "<td>0.1892519</td>\n",
       "<td>0.8191105</td>\n",
       "<td>0.9966167</td>\n",
       "<td>0.9949132</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0295858</td>\n",
       "<td>0.1914497</td>\n",
       "<td>0.1444949</td>\n",
       "<td>0.8429563</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9956647</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 1.788 sec</td>\n",
       "<td>5070 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1456830</td>\n",
       "<td>0.0788892</td>\n",
       "<td>0.9108318</td>\n",
       "<td>0.9974993</td>\n",
       "<td>0.9959878</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1320338</td>\n",
       "<td>0.0512462</td>\n",
       "<td>0.9253067</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 1.881 sec</td>\n",
       "<td>4845 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1538868</td>\n",
       "<td>0.0799338</td>\n",
       "<td>0.9005064</td>\n",
       "<td>0.9980509</td>\n",
       "<td>0.9968213</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1727893</td>\n",
       "<td>0.1198918</td>\n",
       "<td>0.8720782</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 1.958 sec</td>\n",
       "<td>4912 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1438360</td>\n",
       "<td>0.0870605</td>\n",
       "<td>0.9130785</td>\n",
       "<td>0.9977935</td>\n",
       "<td>0.9965341</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1370946</td>\n",
       "<td>0.0689280</td>\n",
       "<td>0.9194711</td>\n",
       "<td>0.9977231</td>\n",
       "<td>0.9964044</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 2.049 sec</td>\n",
       "<td>4805 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1238290</td>\n",
       "<td>0.0488185</td>\n",
       "<td>0.9355776</td>\n",
       "<td>0.9988600</td>\n",
       "<td>0.9982412</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1389756</td>\n",
       "<td>0.0677223</td>\n",
       "<td>0.9172462</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9984564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 2.138 sec</td>\n",
       "<td>4760 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1429047</td>\n",
       "<td>0.0739717</td>\n",
       "<td>0.9142004</td>\n",
       "<td>0.9989703</td>\n",
       "<td>0.9984075</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1270877</td>\n",
       "<td>0.0523032</td>\n",
       "<td>0.9307981</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 2.215 sec</td>\n",
       "<td>4811 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1352205</td>\n",
       "<td>0.0645180</td>\n",
       "<td>0.9231794</td>\n",
       "<td>0.9991542</td>\n",
       "<td>0.9987009</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1838890</td>\n",
       "<td>0.1442605</td>\n",
       "<td>0.8551152</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9976512</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 2.292 sec</td>\n",
       "<td>4851 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1413051</td>\n",
       "<td>0.0767080</td>\n",
       "<td>0.9161104</td>\n",
       "<td>0.9990438</td>\n",
       "<td>0.9985396</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1823697</td>\n",
       "<td>0.1993980</td>\n",
       "<td>0.8574995</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9955992</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:04</td>\n",
       "<td> 2.382 sec</td>\n",
       "<td>4801 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1939040</td>\n",
       "<td>0.1496363</td>\n",
       "<td>0.8420333</td>\n",
       "<td>0.9991909</td>\n",
       "<td>0.9987274</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1652579</td>\n",
       "<td>0.1126568</td>\n",
       "<td>0.8829866</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-67.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-67 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-67 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-67 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-67 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-67 .h2o-table th,\n",
       "#h2o-table-67 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-67 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-67\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0244740</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9382487</td>\n",
       "<td>0.9382487</td>\n",
       "<td>0.0229627</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9353270</td>\n",
       "<td>0.9353270</td>\n",
       "<td>0.0228912</td></tr>\n",
       "<tr><td>physician-fee-freeze.?</td>\n",
       "<td>0.9255664</td>\n",
       "<td>0.9255664</td>\n",
       "<td>0.0226523</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.?</td>\n",
       "<td>0.9135779</td>\n",
       "<td>0.9135779</td>\n",
       "<td>0.0223589</td></tr>\n",
       "<tr><td>superfund-right-to-sue.n</td>\n",
       "<td>0.9134547</td>\n",
       "<td>0.9134547</td>\n",
       "<td>0.0223559</td></tr>\n",
       "<tr><td>religious-groups-in-schools.n</td>\n",
       "<td>0.9087586</td>\n",
       "<td>0.9087586</td>\n",
       "<td>0.0222410</td></tr>\n",
       "<tr><td>handicapped-infants.y</td>\n",
       "<td>0.8998351</td>\n",
       "<td>0.8998351</td>\n",
       "<td>0.0220226</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.8997151</td>\n",
       "<td>0.8997151</td>\n",
       "<td>0.0220197</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.8950516</td>\n",
       "<td>0.8950516</td>\n",
       "<td>0.0219055</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_398\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight             weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  --------------------  ----------  ----------------------  -------------------  ----------------------  ---------------------\n",
       "    1        64       Input      0.0\n",
       "    2        100      Rectifier  0.0        0.0   0.0   0.25317598584423195   0.43078601360321045   0.0         0.001498042455518771    0.11016631126403809  0.48586404208152467     0.023875869810581207\n",
       "    3        100      Rectifier  0.0        0.0   0.0   0.006349660054181004  0.008466988801956177  0.0         -0.00529289683494253    0.10148590803146362  0.9869213140279145      0.011644832789897919\n",
       "    4        100      Rectifier  0.0        0.0   0.0   0.07301987967599416   0.21971482038497925   0.0         -0.0002623463712330704  0.10068872570991516  0.998461964173011       0.0033484846353530884\n",
       "    5        2        Softmax               0.0   0.0   0.06799390562751796   0.2369123101234436    0.0         -0.007474518812960014   0.5512197017669678   3.2526065174565133e-18  0.0005023693665862083\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.037598742595516474\n",
       "RMSE: 0.19390395198529728\n",
       "LogLoss: 0.14963630711691328\n",
       "Mean Per-Class Error: 0.009708737864077669\n",
       "AUC: 0.9991909385113269\n",
       "AUCPR: 0.9987273854685967\n",
       "Gini: 0.9983818770226538\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9625960973110883\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    202         4             0.0194   (4.0/206.0)\n",
       "republican  0           132           0        (0.0/132.0)\n",
       "Total       202         136           0.0118   (4.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.962596     0.985075  97\n",
       "max f2                       0.962596     0.993976  97\n",
       "max f0point5                 0.99962      0.985577  84\n",
       "max accuracy                 0.994869     0.988166  95\n",
       "max precision                1            1         0\n",
       "max recall                   0.962596     1         97\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.962596     0.975573  97\n",
       "max min_per_class_accuracy   0.994869     0.985437  95\n",
       "max mean_per_class_accuracy  0.962596     0.990291  97\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      9.99608e-10  206       269\n",
       "max tps                      0.962596     132       97\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      9.99608e-10  1         269\n",
       "max tpr                      0.962596     1         97\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 43.81 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   1                  2.56061    2.56061            1                1            1                           1                   0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0236686                   1                  2.56061    2.56061            1                1            1                           1                   0.030303        0.0606061                  156.061   156.061            0.0606061\n",
       "3        0.0325444                   1                  2.56061    2.56061            1                1            1                           1                   0.0227273       0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   1                  2.56061    2.56061            1                1            1                           1                   0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0532544                   1                  2.56061    2.56061            1                1            1                           1                   0.030303        0.136364                   156.061   156.061            0.136364\n",
       "6        0.100592                    1                  2.56061    2.56061            1                1            1                           1                   0.121212        0.257576                   156.061   156.061            0.257576\n",
       "7        0.153846                    1                  2.56061    2.56061            1                1            1                           1                   0.136364        0.393939                   156.061   156.061            0.393939\n",
       "8        0.201183                    1                  2.56061    2.56061            1                1            1                           1                   0.121212        0.515152                   156.061   156.061            0.515152\n",
       "9        0.301775                    0.999997           2.56061    2.56061            1                0.999999     1                           1                   0.257576        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.964864           2.25023    2.48474            0.878788         0.99856      0.97037                     0.999648            0.219697        0.992424                   125.023   148.474            0.973007\n",
       "11       0.5                         0.00593283         0.0753119  2                  0.0294118        0.384587     0.781065                    0.875908            0.00757576      1                          -92.4688  100                0.820388\n",
       "12       0.600592                    0.000274381        0          1.66502            0                0.00157774   0.650246                    0.729468            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    3.35435e-05        0          1.4322             0                8.97841e-05  0.559322                    0.627479            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    7.61707e-06        0          1.25185            0                1.70343e-05  0.488889                    0.548465            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    5.47285e-07        0          1.11184            0                2.68195e-06  0.434211                    0.487124            0               1                          -100      11.1842            0.165049\n",
       "16       1                           9.99608e-10        0          1                  0                1.27474e-07  0.390533                    0.438123            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.027310181729469443\n",
       "RMSE: 0.16525792486131927\n",
       "LogLoss: 0.11265675456486371\n",
       "Mean Per-Class Error: 0.01639344262295082\n",
       "AUC: 0.9986338797814207\n",
       "AUCPR: 0.9977359063574717\n",
       "Gini: 0.9972677595628414\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7588237642672655\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    59          2             0.0328   (2.0/61.0)\n",
       "republican  0           36            0        (0.0/36.0)\n",
       "Total       59          38            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.758824     0.972973  34\n",
       "max f2                       0.758824     0.989011  34\n",
       "max f0point5                 0.998173     0.988372  30\n",
       "max accuracy                 0.998173     0.979381  30\n",
       "max precision                1            1         0\n",
       "max recall                   0.758824     1         34\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.758824     0.957239  34\n",
       "max min_per_class_accuracy   0.997431     0.972222  32\n",
       "max mean_per_class_accuracy  0.758824     0.983607  34\n",
       "max tns                      1            61        0\n",
       "max fns                      1            35        0\n",
       "max fps                      5.37155e-09  61        91\n",
       "max tps                      0.758824     36        34\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.972222  0\n",
       "max fpr                      5.37155e-09  1         91\n",
       "max tpr                      0.758824     1         34\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 40.29 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0309278                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0833333                  169.444  169.444            0.0833333\n",
       "4        0.0618557                   1                  2.69444  2.69444            1                1            1                           1                   0.0833333       0.166667                   169.444  169.444            0.166667\n",
       "5        0.103093                    1                  2.69444  2.69444            1                1            1                           1                   0.111111        0.277778                   169.444  169.444            0.277778\n",
       "6        0.154639                    1                  2.69444  2.69444            1                1            1                           1                   0.138889        0.416667                   169.444  169.444            0.416667\n",
       "7        0.206186                    1                  2.69444  2.69444            1                1            1                           1                   0.138889        0.555556                   169.444  169.444            0.555556\n",
       "8        0.298969                    0.999965           2.69444  2.69444            1                0.999994     1                           0.999998            0.25            0.805556                   169.444  169.444            0.805556\n",
       "9        0.402062                    0.630899           1.88611  2.48718            0.7              0.934107     0.923077                    0.983103            0.194444        1                          88.6111  148.718            0.95082\n",
       "10       0.505155                    0.00545666         0        1.97959            0                0.0725729    0.734694                    0.79728             0               1                          -100     97.9592            0.786885\n",
       "11       0.597938                    0.000451902        0        1.67241            0                0.00153013   0.62069                     0.673802            0               1                          -100     67.2414            0.639344\n",
       "12       0.701031                    3.36829e-05        0        1.42647            0                0.000272724  0.529412                    0.574754            0               1                          -100     42.6471            0.47541\n",
       "13       0.793814                    1.12091e-05        0        1.25974            0                1.81683e-05  0.467532                    0.507577            0               1                          -100     25.974             0.327869\n",
       "14       0.896907                    1.29419e-06        0        1.11494            0                5.41884e-06  0.413793                    0.449235            0               1                          -100     11.4943            0.163934\n",
       "15       1                           5.37155e-09        0        1                  0                1.82567e-07  0.371134                    0.402922            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.030483246542344196\n",
       "RMSE: 0.17459452036746226\n",
       "LogLoss: 0.11193598513180077\n",
       "Mean Per-Class Error: 0.03320829655781112\n",
       "AUC: 0.9944101206237128\n",
       "AUCPR: 0.9915398602508056\n",
       "Gini: 0.9888202412474256\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19840922521394078\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    197         9             0.0437   (9.0/206.0)\n",
       "republican  3           129           0.0227   (3.0/132.0)\n",
       "Total       200         138           0.0355   (12.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.198409     0.955556  125\n",
       "max f2                       0.198409     0.968468  125\n",
       "max f0point5                 0.889587     0.96519   112\n",
       "max accuracy                 0.470815     0.964497  119\n",
       "max precision                1            1         0\n",
       "max recall                   0.00672293   1         144\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.198409     0.926657  125\n",
       "max min_per_class_accuracy   0.438651     0.962121  121\n",
       "max mean_per_class_accuracy  0.198409     0.966792  125\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      2.64235e-09  206       317\n",
       "max tps                      0.00672293   132       144\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      2.64235e-09  1         317\n",
       "max tpr                      0.00672293   1         144\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.99 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0118343                   0.999996           2.56061  2.56061            1                0.999998     1                           0.999998            0.030303        0.030303                   156.061  156.061            0.030303\n",
       "2        0.0207101                   0.999992           2.56061  2.56061            1                0.999993     1                           0.999996            0.0227273       0.0530303                  156.061  156.061            0.0530303\n",
       "3        0.0325444                   0.999986           2.56061  2.56061            1                0.999989     1                           0.999993            0.030303        0.0833333                  156.061  156.061            0.0833333\n",
       "4        0.0414201                   0.999984           2.56061  2.56061            1                0.999984     1                           0.999991            0.0227273       0.106061                   156.061  156.061            0.106061\n",
       "5        0.0502959                   0.999978           2.56061  2.56061            1                0.999981     1                           0.99999             0.0227273       0.128788                   156.061  156.061            0.128788\n",
       "6        0.100592                    0.999952           2.56061  2.56061            1                0.999968     1                           0.999979            0.128788        0.257576                   156.061  156.061            0.257576\n",
       "7        0.150888                    0.999692           2.56061  2.56061            1                0.999866     1                           0.999941            0.128788        0.386364                   156.061  156.061            0.386364\n",
       "8        0.201183                    0.999013           2.56061  2.56061            1                0.99938      1                           0.999801            0.128788        0.515152                   156.061  156.061            0.515152\n",
       "9        0.301775                    0.992839           2.56061  2.56061            1                0.99678      1                           0.998794            0.257576        0.772727                   156.061  156.061            0.772727\n",
       "10       0.399408                    0.323486           1.93985  2.40887            0.757576         0.857211     0.940741                    0.964185            0.189394        0.962121                   93.9853  140.887            0.923286\n",
       "11       0.5                         0.00080958         0.37656  2                  0.147059         0.0471212    0.781065                    0.779687            0.0378788       1                          -62.344  100                0.820388\n",
       "12       0.600592                    8.5876e-05         0        1.66502            0                0.000342936  0.650246                    0.649156            0               1                          -100     66.5025            0.65534\n",
       "13       0.698225                    2.6619e-05         0        1.4322             0                4.3807e-05   0.559322                    0.55839             0               1                          -100     43.2203            0.495146\n",
       "14       0.798817                    5.682e-06          0        1.25185            0                1.42556e-05  0.488889                    0.488076            0               1                          -100     25.1852            0.330097\n",
       "15       0.899408                    1.187e-06          0        1.11184            0                2.58912e-06  0.434211                    0.433489            0               1                          -100     11.1842            0.165049\n",
       "16       1                           0                  0        1                  0                4.98235e-07  0.390533                    0.389884            0               1                          -100     0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.9720163    0.025748458   0.95238096    0.9493671     1.0           1.0           0.9583333\n",
       "aic                      nan          0.0           nan           nan           nan           nan           nan\n",
       "auc                      0.9930826    0.0079489155  0.9930233     0.98062015    1.0           1.0           0.99176955\n",
       "err                      0.027983725  0.025748458   0.04761905    0.050632913   0.0           0.0           0.041666668\n",
       "err_count                2.0          1.8708287     3.0           4.0           0.0           0.0           3.0\n",
       "f0point5                 0.9545107    0.04585834    0.89285713    0.9444444     1.0           1.0           0.9352518\n",
       "f1                       0.96402633   0.03338634    0.9302326     0.9444444     1.0           1.0           0.94545454\n",
       "f2                       0.9742401    0.025314348   0.9708738     0.9444444     1.0           1.0           0.9558824\n",
       "lift_top_group           2.6260316    0.37189522    3.15          2.1944444     2.357143      2.7619047     2.6666667\n",
       "loglikelihood            nan          0.0           nan           nan           nan           nan           nan\n",
       "---                      ---          ---           ---           ---           ---           ---           ---\n",
       "mcc                      0.9418959    0.053329527   0.8993875     0.8979328     1.0           1.0           0.9121593\n",
       "mean_per_class_accuracy  0.9746684    0.023836195   0.96511626    0.9489664     1.0           1.0           0.9592593\n",
       "mean_per_class_error     0.02533161   0.023836195   0.034883723   0.05103359    0.0           0.0           0.04074074\n",
       "mse                      0.029170487  0.020610105   0.0407371     0.052859813   0.0027387266  0.013213612   0.03630319\n",
       "pr_auc                   0.9902069    0.009823424   0.98574984    0.9771707     1.0           1.0           0.9881138\n",
       "precision                0.9485162    0.05465527    0.8695652     0.9444444     1.0           1.0           0.9285714\n",
       "r2                       0.8751134    0.0868484     0.81199354    0.7868875     0.9887877     0.94279206    0.8451064\n",
       "recall                   0.9814815    0.02618914    1.0           0.9444444     1.0           1.0           0.962963\n",
       "rmse                     0.15791285   0.07274975    0.20183434    0.22991262    0.052332845   0.11495048    0.19053395\n",
       "specificity              0.9678553    0.030982763   0.9302326     0.95348835    1.0           1.0           0.95555556\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:03  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:04  1.626 sec   5044 obs/sec      1         1             338        0.234181         0.240687            0.769593       0.993344        0.989824           2.56061          0.035503                         0.217688           0.181266              0.796962         0.993625          0.990371             2.69444            0.0309278\n",
       "    2025-05-26 14:48:04  1.708 sec   5044 obs/sec      2         2             676        0.207496         0.189252            0.81911        0.996617        0.994913           2.56061          0.0295858                        0.19145            0.144495              0.842956         0.997268          0.995665             2.69444            0.0206186\n",
       "    2025-05-26 14:48:04  1.788 sec   5070 obs/sec      3         3             1014       0.145683         0.0788892           0.910832       0.997499        0.995988           2.56061          0.0207101                        0.132034           0.0512462             0.925307         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:04  1.881 sec   4845 obs/sec      4         4             1352       0.153887         0.0799338           0.900506       0.998051        0.996821           2.56061          0.0207101                        0.172789           0.119892              0.872078         0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:48:04  1.958 sec   4912 obs/sec      5         5             1690       0.143836         0.0870605           0.913078       0.997793        0.996534           2.56061          0.0207101                        0.137095           0.068928              0.919471         0.997723          0.996404             2.69444            0.0206186\n",
       "    2025-05-26 14:48:04  2.049 sec   4805 obs/sec      6         6             2028       0.123829         0.0488185           0.935578       0.99886         0.998241           2.56061          0.0177515                        0.138976           0.0677223             0.917246         0.999089          0.998456             2.69444            0.0103093\n",
       "    2025-05-26 14:48:04  2.138 sec   4760 obs/sec      7         7             2366       0.142905         0.0739717           0.9142         0.99897         0.998408           2.56061          0.0147929                        0.127088           0.0523032             0.930798         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:04  2.215 sec   4811 obs/sec      8         8             2704       0.135221         0.064518            0.923179       0.999154        0.998701           2.56061          0.0118343                        0.183889           0.14426               0.855115         0.998634          0.997651             2.69444            0.0103093\n",
       "    2025-05-26 14:48:04  2.292 sec   4851 obs/sec      9         9             3042       0.141305         0.076708            0.91611        0.999044        0.99854            2.56061          0.0118343                        0.18237            0.199398              0.857499         0.997268          0.995599             2.69444            0.0206186\n",
       "    2025-05-26 14:48:04  2.382 sec   4801 obs/sec      10        10            3380       0.193904         0.149636            0.842033       0.999191        0.998727           2.56061          0.0118343                        0.165258           0.112657              0.882987         0.998634          0.997736             2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.02447403835984281\n",
       "synfuels-corporation-cutback.n                      0.9382486939430237     0.9382486939430237   0.022962734526633978\n",
       "physician-fee-freeze.n                              0.9353269934654236     0.9353269934654236   0.02289122871706922\n",
       "physician-fee-freeze.?                              0.9255664348602295     0.9255664348602295   0.022652348431352207\n",
       "adoption-of-the-budget-resolution.?                 0.9135778546333313     0.9135778546333313   0.02235893945899905\n",
       "superfund-right-to-sue.n                            0.9134546518325806     0.9134546518325806   0.022355924188927435\n",
       "religious-groups-in-schools.n                       0.9087585806846619     0.9087585806846619   0.02224099236351272\n",
       "handicapped-infants.y                               0.8998350501060486     0.8998350501060486   0.02202259753382651\n",
       "aid-to-nicaraguan-contras.y                         0.8997151255607605     0.8997151255607605   0.02201966249590484\n",
       "duty-free-exports.?                                 0.8950515985488892     0.8950515985488892   0.021905527156924138\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[100,100,100], nfolds=5, activation=\"rectifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f2ccf3f501b3ce",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [5,5,5], cross folds = 10, activation function = \"rectifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9e15f2313144817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:53:20.827853Z",
     "start_time": "2025-05-09T14:53:20.120469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_555\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-68.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-68 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-68 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-68 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-68 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-68 .h2o-table th,\n",
       "#h2o-table-68 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-68 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-68\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2696786</td>\n",
       "<td>0.4383750</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0065526</td>\n",
       "<td>0.1819432</td>\n",
       "<td>0.5640372</td>\n",
       "<td>0.0629817</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0086211</td>\n",
       "<td>0.0162925</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0663704</td>\n",
       "<td>0.4954164</td>\n",
       "<td>0.9437224</td>\n",
       "<td>0.0729509</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>5</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0052012</td>\n",
       "<td>0.0071499</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0624972</td>\n",
       "<td>0.4076147</td>\n",
       "<td>1.1628882</td>\n",
       "<td>0.6667528</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014566</td>\n",
       "<td>0.0003413</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6811175</td>\n",
       "<td>1.0931277</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.1634747</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02357065678931948\n",
       "RMSE: 0.15352738123644094\n",
       "LogLoss: 0.09121775368549542\n",
       "Mean Per-Class Error: 0.02213886437187408\n",
       "AUC: 0.9923323036187113\n",
       "AUCPR: 0.9789850679136286\n",
       "Gini: 0.9846646072374226</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-69.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-69 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-69 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-69 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-69 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-69 .h2o-table th,\n",
       "#h2o-table-69 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-69 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-69\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4651299332629031</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>200.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0291</td>\n",
       "<td> (6.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>202.0</td>\n",
       "<td>136.0</td>\n",
       "<td>0.0237</td>\n",
       "<td> (8.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-70.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-70 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-70 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-70 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-70 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-70 .h2o-table th,\n",
       "#h2o-table-70 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-70 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-70\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9701493</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9789157</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6108206</td>\n",
       "<td>0.9696970</td>\n",
       "<td>63.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6108206</td>\n",
       "<td>0.9763314</td>\n",
       "<td>63.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9134778</td>\n",
       "<td>0.9902913</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0551605</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.9951456</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9508393</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5368153</td>\n",
       "<td>0.9757282</td>\n",
       "<td>65.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4651299</td>\n",
       "<td>0.9778611</td>\n",
       "<td>67.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>205.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>87.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000026</td>\n",
       "<td>206.0</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0551605</td>\n",
       "<td>132.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.9951456</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.6590909</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000026</td>\n",
       "<td>1.0</td>\n",
       "<td>239.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0551605</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-71.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-71 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-71 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-71 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-71 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-71 .h2o-table th,\n",
       "#h2o-table-71 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-71 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-71\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.40 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.1360947</td>\n",
       "<td>0.9775661</td>\n",
       "<td>2.5049407</td>\n",
       "<td>2.5049407</td>\n",
       "<td>0.9782609</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.9782609</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.3409091</td>\n",
       "<td>0.3409091</td>\n",
       "<td>150.4940711</td>\n",
       "<td>150.4940711</td>\n",
       "<td>0.3360547</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.1568047</td>\n",
       "<td>0.9756318</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5122927</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9759588</td>\n",
       "<td>0.9811321</td>\n",
       "<td>0.9773538</td>\n",
       "<td>0.0530303</td>\n",
       "<td>0.3939394</td>\n",
       "<td>156.0606061</td>\n",
       "<td>151.2292739</td>\n",
       "<td>0.3890850</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.2218935</td>\n",
       "<td>0.9726074</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5264646</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9730034</td>\n",
       "<td>0.9866667</td>\n",
       "<td>0.9760777</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.5606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>152.6464646</td>\n",
       "<td>0.5557517</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9261521</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5355021</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9628542</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9725774</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.7651515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4783132</td>\n",
       "<td>2.1726354</td>\n",
       "<td>2.4468013</td>\n",
       "<td>0.8484848</td>\n",
       "<td>0.7811503</td>\n",
       "<td>0.9555556</td>\n",
       "<td>0.9257841</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.9772727</td>\n",
       "<td>117.2635445</td>\n",
       "<td>144.6801347</td>\n",
       "<td>0.9481465</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0221940</td>\n",
       "<td>0.2259358</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0882353</td>\n",
       "<td>0.1311074</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7659083</td>\n",
       "<td>0.0227273</td>\n",
       "<td>1.0</td>\n",
       "<td>-77.4064171</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0036235</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0077592</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6389277</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0008198</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0018242</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5498412</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0003127</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004849</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4806630</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001133</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002076</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4269278</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000026</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000536</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3839878</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.0313699851476705\n",
       "RMSE: 0.17711573941259567\n",
       "LogLoss: 0.11711592294593795\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.994535519125683\n",
       "AUCPR: 0.9918040042192442\n",
       "Gini: 0.9890710382513661</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-72.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-72 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-72 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-72 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-72 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-72 .h2o-table th,\n",
       "#h2o-table-72 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-72 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-72\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2668740561060711</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>59.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0328</td>\n",
       "<td> (2.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>60.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.0309</td>\n",
       "<td> (3.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-73.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-73 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-73 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-73 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-73 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-73 .h2o-table th,\n",
       "#h2o-table-73 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-73 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-73\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9589041</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9668508</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7220286</td>\n",
       "<td>0.9821429</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7220286</td>\n",
       "<td>0.9690722</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0131959</td>\n",
       "<td>1.0</td>\n",
       "<td>27.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7220286</td>\n",
       "<td>0.9347181</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9672131</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2668741</td>\n",
       "<td>0.9697177</td>\n",
       "<td>20.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9775661</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000094</td>\n",
       "<td>61.0</td>\n",
       "<td>78.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0131959</td>\n",
       "<td>36.0</td>\n",
       "<td>27.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.5277778</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000094</td>\n",
       "<td>1.0</td>\n",
       "<td>78.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0131959</td>\n",
       "<td>1.0</td>\n",
       "<td>27.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-74.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-74 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-74 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-74 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-74 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-74 .h2o-table th,\n",
       "#h2o-table-74 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-74 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-74\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.95 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.1752577</td>\n",
       "<td>0.9775661</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9775661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9775661</td>\n",
       "<td>0.4722222</td>\n",
       "<td>0.4722222</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4722222</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9750734</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9764260</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9773951</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.8444647</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9389353</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9654593</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0904979</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.5602224</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8615524</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0065238</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0245879</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.6907433</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0021160</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0036660</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5841279</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0005463</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0011275</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.4983925</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0004147</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004592</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4401925</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000880</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002519</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3896246</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000094</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000366</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3494609</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.040075001035739556\n",
       "RMSE: 0.2001874147786008\n",
       "LogLoss: 0.16448753718217035\n",
       "Mean Per-Class Error: 0.0469991173874669\n",
       "AUC: 0.9800492791997646\n",
       "AUCPR: 0.9720900769742027\n",
       "Gini: 0.9600985583995292</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-75.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-75 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-75 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-75 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-75 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-75 .h2o-table th,\n",
       "#h2o-table-75 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-75 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-75\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4712741083954024</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>196.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0485</td>\n",
       "<td> (10.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>6.0</td>\n",
       "<td>126.0</td>\n",
       "<td>0.0455</td>\n",
       "<td> (6.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>202.0</td>\n",
       "<td>136.0</td>\n",
       "<td>0.0473</td>\n",
       "<td> (16.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-76.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-76 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-76 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-76 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-76 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-76 .h2o-table th,\n",
       "#h2o-table-76 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-76 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-76\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.4712741</td>\n",
       "<td>0.9402985</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3290812</td>\n",
       "<td>0.9566517</td>\n",
       "<td>101.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6860431</td>\n",
       "<td>0.9453125</td>\n",
       "<td>87.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5245945</td>\n",
       "<td>0.9526627</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9807371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0000446</td>\n",
       "<td>1.0</td>\n",
       "<td>281.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9807371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4712741</td>\n",
       "<td>0.9013729</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4712741</td>\n",
       "<td>0.9514563</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3290812</td>\n",
       "<td>0.9532951</td>\n",
       "<td>101.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9807371</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9807371</td>\n",
       "<td>127.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000047</td>\n",
       "<td>206.0</td>\n",
       "<td>292.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0000446</td>\n",
       "<td>132.0</td>\n",
       "<td>281.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9807371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9807371</td>\n",
       "<td>0.9621212</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000047</td>\n",
       "<td>1.0</td>\n",
       "<td>292.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0000446</td>\n",
       "<td>1.0</td>\n",
       "<td>281.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-77.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-77 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-77 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-77 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-77 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-77 .h2o-table th,\n",
       "#h2o-table-77 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-77 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-77\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.28 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.9807371</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9807371</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0378788</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0378788</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9779873</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9802781</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9806060</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.9772431</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9772431</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9792048</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0909091</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0909091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9763309</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9767073</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9788480</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0621302</td>\n",
       "<td>0.9761694</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9761694</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9779551</td>\n",
       "<td>0.0530303</td>\n",
       "<td>0.1590909</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1590909</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9749152</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9754236</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9769872</td>\n",
       "<td>0.0984848</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9687549</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9728898</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9756214</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2100592</td>\n",
       "<td>0.9495503</td>\n",
       "<td>2.3045455</td>\n",
       "<td>2.4884763</td>\n",
       "<td>0.9</td>\n",
       "<td>0.9591785</td>\n",
       "<td>0.9718310</td>\n",
       "<td>0.9709896</td>\n",
       "<td>0.1363636</td>\n",
       "<td>0.5227273</td>\n",
       "<td>130.4545455</td>\n",
       "<td>148.8476312</td>\n",
       "<td>0.5130185</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3076923</td>\n",
       "<td>0.879433</td>\n",
       "<td>2.4830119</td>\n",
       "<td>2.4867424</td>\n",
       "<td>0.9696970</td>\n",
       "<td>0.9126433</td>\n",
       "<td>0.9711538</td>\n",
       "<td>0.9524759</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7651515</td>\n",
       "<td>148.3011938</td>\n",
       "<td>148.6742424</td>\n",
       "<td>0.7505884</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4739524</td>\n",
       "<td>1.9824047</td>\n",
       "<td>2.3709315</td>\n",
       "<td>0.7741935</td>\n",
       "<td>0.7469981</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.9052921</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.9469697</td>\n",
       "<td>98.2404692</td>\n",
       "<td>137.0931538</td>\n",
       "<td>0.8984260</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0414612</td>\n",
       "<td>0.3765597</td>\n",
       "<td>1.9696970</td>\n",
       "<td>0.1470588</td>\n",
       "<td>0.1872254</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.7608290</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.9848485</td>\n",
       "<td>-62.3440285</td>\n",
       "<td>96.9696970</td>\n",
       "<td>0.7955281</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0071360</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.6524108</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0174120</td>\n",
       "<td>0.6453202</td>\n",
       "<td>0.6363158</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>65.2410808</td>\n",
       "<td>0.6429097</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7011834</td>\n",
       "<td>0.0021870</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4153561</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0043729</td>\n",
       "<td>0.5527426</td>\n",
       "<td>0.5456573</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>41.5356093</td>\n",
       "<td>0.4778611</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0007051</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2423681</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0012588</td>\n",
       "<td>0.4851852</td>\n",
       "<td>0.4791197</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.2368126</td>\n",
       "<td>0.3176670</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001624</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1034191</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003699</td>\n",
       "<td>0.4309211</td>\n",
       "<td>0.4255753</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>10.3419059</td>\n",
       "<td>0.1526184</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>4.74e-06</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0000633</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3827723</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-78.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-78 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-78 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-78 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-78 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-78 .h2o-table th,\n",
       "#h2o-table-78 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-78 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-78\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th>\n",
       "<th>cv_6_valid</th>\n",
       "<th>cv_7_valid</th>\n",
       "<th>cv_8_valid</th>\n",
       "<th>cv_9_valid</th>\n",
       "<th>cv_10_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9692319</td>\n",
       "<td>0.0309954</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9591837</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9268293</td>\n",
       "<td>0.9285714</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.972973</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9864091</td>\n",
       "<td>0.0139217</td>\n",
       "<td>0.9699074</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.978836</td>\n",
       "<td>0.9791667</td>\n",
       "<td>0.9777778</td>\n",
       "<td>0.9941176</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0307681</td>\n",
       "<td>0.0309954</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0408163</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0731707</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.0666667</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.1</td>\n",
       "<td>1.1005049</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9513472</td>\n",
       "<td>0.0526375</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8783784</td>\n",
       "<td>0.8823530</td>\n",
       "<td>0.9036145</td>\n",
       "<td>0.9876543</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9620383</td>\n",
       "<td>0.0376535</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8965517</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.969697</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9737632</td>\n",
       "<td>0.0280932</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9154929</td>\n",
       "<td>0.9677419</td>\n",
       "<td>0.9740260</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.5712826</td>\n",
       "<td>0.4363864</td>\n",
       "<td>3.28125</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.6363637</td>\n",
       "<td>2.4166667</td>\n",
       "<td>2.9285715</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>3.2222223</td>\n",
       "<td>2.3846154</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9370362</td>\n",
       "<td>0.0620390</td>\n",
       "<td>0.9251849</td>\n",
       "<td>0.9166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8412485</td>\n",
       "<td>0.8660254</td>\n",
       "<td>0.8744746</td>\n",
       "<td>0.9467621</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9708485</td>\n",
       "<td>0.0299805</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9583333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9272487</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.9705882</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0291515</td>\n",
       "<td>0.0299805</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0727513</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.0666667</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0385868</td>\n",
       "<td>0.0229646</td>\n",
       "<td>0.0322261</td>\n",
       "<td>0.0499110</td>\n",
       "<td>0.0241836</td>\n",
       "<td>0.0201453</td>\n",
       "<td>0.0702685</td>\n",
       "<td>0.0593923</td>\n",
       "<td>0.0705280</td>\n",
       "<td>0.0324220</td>\n",
       "<td>0.0018609</td>\n",
       "<td>0.0249306</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9683530</td>\n",
       "<td>0.059137</td>\n",
       "<td>0.8048837</td>\n",
       "<td>0.9703948</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9651168</td>\n",
       "<td>0.9724552</td>\n",
       "<td>0.9770405</td>\n",
       "<td>0.9936392</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9447432</td>\n",
       "<td>0.0633394</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.8823530</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8348917</td>\n",
       "<td>0.0962824</td>\n",
       "<td>0.8172365</td>\n",
       "<td>0.7961966</td>\n",
       "<td>0.8972806</td>\n",
       "<td>0.9169502</td>\n",
       "<td>0.6875095</td>\n",
       "<td>0.7574815</td>\n",
       "<td>0.7178881</td>\n",
       "<td>0.8694539</td>\n",
       "<td>0.9913056</td>\n",
       "<td>0.8976142</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9822129</td>\n",
       "<td>0.0291852</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9411765</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1855820</td>\n",
       "<td>0.0678735</td>\n",
       "<td>0.1795162</td>\n",
       "<td>0.2234078</td>\n",
       "<td>0.1555109</td>\n",
       "<td>0.1419340</td>\n",
       "<td>0.2650822</td>\n",
       "<td>0.2437053</td>\n",
       "<td>0.2655710</td>\n",
       "<td>0.1800610</td>\n",
       "<td>0.0431378</td>\n",
       "<td>0.1578942</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9594841</td>\n",
       "<td>0.0528327</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.875</td>\n",
       "<td>0.8666667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 13 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-79.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-79 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-79 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-79 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-79 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-79 .h2o-table th,\n",
       "#h2o-table-79 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-79 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-79\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.630 sec</td>\n",
       "<td>169000 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.5934409</td>\n",
       "<td>1.2097308</td>\n",
       "<td>-0.4796095</td>\n",
       "<td>0.9613122</td>\n",
       "<td>0.9424013</td>\n",
       "<td>2.5212121</td>\n",
       "<td>0.0976331</td>\n",
       "<td>0.5805649</td>\n",
       "<td>1.1732796</td>\n",
       "<td>-0.4441512</td>\n",
       "<td>0.9704007</td>\n",
       "<td>0.9490134</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0824742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.649 sec</td>\n",
       "<td>48285 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.2637676</td>\n",
       "<td>0.2464865</td>\n",
       "<td>0.7076958</td>\n",
       "<td>0.9715909</td>\n",
       "<td>0.9423941</td>\n",
       "<td>2.4621212</td>\n",
       "<td>0.0710059</td>\n",
       "<td>0.2591862</td>\n",
       "<td>0.2349209</td>\n",
       "<td>0.7121708</td>\n",
       "<td>0.9744991</td>\n",
       "<td>0.9572636</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.667 sec</td>\n",
       "<td>39000 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.2227407</td>\n",
       "<td>0.1796701</td>\n",
       "<td>0.7915551</td>\n",
       "<td>0.9799941</td>\n",
       "<td>0.9558020</td>\n",
       "<td>2.4805871</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.2377195</td>\n",
       "<td>0.2000976</td>\n",
       "<td>0.7578744</td>\n",
       "<td>0.9785974</td>\n",
       "<td>0.9663337</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0515464</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.688 sec</td>\n",
       "<td>34666 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.2062927</td>\n",
       "<td>0.1531687</td>\n",
       "<td>0.8212030</td>\n",
       "<td>0.9846646</td>\n",
       "<td>0.9688582</td>\n",
       "<td>2.5234958</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.2191439</td>\n",
       "<td>0.1730541</td>\n",
       "<td>0.7942358</td>\n",
       "<td>0.9817851</td>\n",
       "<td>0.9715097</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.707 sec</td>\n",
       "<td>33137 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1923995</td>\n",
       "<td>0.1349478</td>\n",
       "<td>0.8444750</td>\n",
       "<td>0.9865953</td>\n",
       "<td>0.9676451</td>\n",
       "<td>2.4852941</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.2197891</td>\n",
       "<td>0.1737430</td>\n",
       "<td>0.7930224</td>\n",
       "<td>0.9831512</td>\n",
       "<td>0.9736716</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.727 sec</td>\n",
       "<td>31687 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1816193</td>\n",
       "<td>0.1221948</td>\n",
       "<td>0.8614149</td>\n",
       "<td>0.9886180</td>\n",
       "<td>0.9702942</td>\n",
       "<td>2.4752525</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.2092738</td>\n",
       "<td>0.1572064</td>\n",
       "<td>0.8123533</td>\n",
       "<td>0.9854281</td>\n",
       "<td>0.9770254</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.752 sec</td>\n",
       "<td>29209 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1734851</td>\n",
       "<td>0.1130596</td>\n",
       "<td>0.8735507</td>\n",
       "<td>0.9899419</td>\n",
       "<td>0.9748364</td>\n",
       "<td>2.5024105</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.1974501</td>\n",
       "<td>0.1391744</td>\n",
       "<td>0.8329579</td>\n",
       "<td>0.9895264</td>\n",
       "<td>0.9824451</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.783 sec</td>\n",
       "<td>27591 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1663014</td>\n",
       "<td>0.1051287</td>\n",
       "<td>0.8838058</td>\n",
       "<td>0.9909532</td>\n",
       "<td>0.9763613</td>\n",
       "<td>2.5010571</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1936989</td>\n",
       "<td>0.1350823</td>\n",
       "<td>0.8392446</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9847051</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.809 sec</td>\n",
       "<td>27160 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1635421</td>\n",
       "<td>0.1016475</td>\n",
       "<td>0.8876297</td>\n",
       "<td>0.9913761</td>\n",
       "<td>0.9747097</td>\n",
       "<td>2.4752525</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1925965</td>\n",
       "<td>0.1376056</td>\n",
       "<td>0.8410693</td>\n",
       "<td>0.9913479</td>\n",
       "<td>0.9867603</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.829 sec</td>\n",
       "<td>26825 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1576110</td>\n",
       "<td>0.0951942</td>\n",
       "<td>0.8956325</td>\n",
       "<td>0.9920197</td>\n",
       "<td>0.9791049</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1796379</td>\n",
       "<td>0.1169730</td>\n",
       "<td>0.8617367</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9909748</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:09</td>\n",
       "<td> 1.848 sec</td>\n",
       "<td>26748 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1535274</td>\n",
       "<td>0.0912178</td>\n",
       "<td>0.9009706</td>\n",
       "<td>0.9923323</td>\n",
       "<td>0.9789851</td>\n",
       "<td>2.5049407</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1771157</td>\n",
       "<td>0.1171159</td>\n",
       "<td>0.8655919</td>\n",
       "<td>0.9945355</td>\n",
       "<td>0.9918040</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-80.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-80 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-80 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-80 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-80 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-80 .h2o-table th,\n",
       "#h2o-table-80 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-80 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-80\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.n</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0458977</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.8481766</td>\n",
       "<td>0.8481766</td>\n",
       "<td>0.0389293</td></tr>\n",
       "<tr><td>el-salvador-aid.?</td>\n",
       "<td>0.6823165</td>\n",
       "<td>0.6823165</td>\n",
       "<td>0.0313168</td></tr>\n",
       "<tr><td>water-project-cost-sharing.y</td>\n",
       "<td>0.6660596</td>\n",
       "<td>0.6660596</td>\n",
       "<td>0.0305706</td></tr>\n",
       "<tr><td>physician-fee-freeze.y</td>\n",
       "<td>0.6104475</td>\n",
       "<td>0.6104475</td>\n",
       "<td>0.0280181</td></tr>\n",
       "<tr><td>crime.n</td>\n",
       "<td>0.6070755</td>\n",
       "<td>0.6070755</td>\n",
       "<td>0.0278634</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.5845112</td>\n",
       "<td>0.5845112</td>\n",
       "<td>0.0268277</td></tr>\n",
       "<tr><td>el-salvador-aid.n</td>\n",
       "<td>0.5741304</td>\n",
       "<td>0.5741304</td>\n",
       "<td>0.0263513</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.5629772</td>\n",
       "<td>0.5629772</td>\n",
       "<td>0.0258394</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.n</td>\n",
       "<td>0.5458343</td>\n",
       "<td>0.5458343</td>\n",
       "<td>0.0250525</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_555\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms                momentum    mean_weight            weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  ----------------------  ----------  ---------------------  -------------------  -----------------------  -------------------\n",
       "    1        64       Input      0.0\n",
       "    2        5        Rectifier  0.0        0.0   0.0   0.26967864367388755   0.43837499618530273     0.0         -0.006552608267702454  0.18194323778152466  0.5640372000500701       0.06298166513442993\n",
       "    3        5        Rectifier  0.0        0.0   0.0   0.008621125557110644  0.016292452812194824    0.0         -0.06637037634849548   0.49541640281677246  0.9437223901522694       0.07295086979866028\n",
       "    4        5        Rectifier  0.0        0.0   0.0   0.005201225398341194  0.007149899378418922    0.0         0.06249721698462963    0.40761470794677734  1.1628881981617805       0.666752815246582\n",
       "    5        2        Softmax               0.0   0.0   0.001456583570688963  0.00034134811721742153  0.0         1.681117482483387      1.093127727508545    -2.7755575615628914e-17  0.1634746789932251\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.02357065678931948\n",
       "RMSE: 0.15352738123644094\n",
       "LogLoss: 0.09121775368549542\n",
       "Mean Per-Class Error: 0.02213886437187408\n",
       "AUC: 0.9923323036187113\n",
       "AUCPR: 0.9789850679136286\n",
       "Gini: 0.9846646072374226\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4651299332629031\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    200         6             0.0291   (6.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       202         136           0.0237   (8.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.46513      0.970149  67\n",
       "max f2                       0.46513      0.978916  67\n",
       "max f0point5                 0.610821     0.969697  63\n",
       "max accuracy                 0.610821     0.976331  63\n",
       "max precision                0.913478     0.990291  36\n",
       "max recall                   0.0551605    1         91\n",
       "max specificity              0.977566     0.995146  0\n",
       "max absolute_mcc             0.46513      0.950839  67\n",
       "max min_per_class_accuracy   0.536815     0.975728  65\n",
       "max mean_per_class_accuracy  0.46513      0.977861  67\n",
       "max tns                      0.977566     205       0\n",
       "max fns                      0.977566     87        0\n",
       "max fps                      2.562e-06    206       239\n",
       "max tps                      0.0551605    132       91\n",
       "max tnr                      0.977566     0.995146  0\n",
       "max fnr                      0.977566     0.659091  0\n",
       "max fpr                      2.562e-06    1         239\n",
       "max tpr                      0.0551605    1         91\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.40 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.136095                    0.977566           2.50494   2.50494            0.978261         0.977566     0.978261                    0.977566            0.340909        0.340909                   150.494   150.494            0.336055\n",
       "2        0.156805                    0.975632           2.56061   2.51229            1                0.975959     0.981132                    0.977354            0.0530303       0.393939                   156.061   151.229            0.389085\n",
       "3        0.221893                    0.972607           2.56061   2.52646            1                0.973003     0.986667                    0.976078            0.166667        0.560606                   156.061   152.646            0.555752\n",
       "4        0.301775                    0.926152           2.56061   2.5355             1                0.962854     0.990196                    0.972577            0.204545        0.765152                   156.061   153.55             0.760297\n",
       "5        0.399408                    0.478313           2.17264   2.4468             0.848485         0.78115      0.955556                    0.925784            0.212121        0.977273                   117.264   144.68             0.948147\n",
       "6        0.5                         0.022194           0.225936  2                  0.0882353        0.131107     0.781065                    0.765908            0.0227273       1                          -77.4064  100                0.820388\n",
       "7        0.600592                    0.00362354         0         1.66502            0                0.00775922   0.650246                    0.638928            0               1                          -100      66.5025            0.65534\n",
       "8        0.698225                    0.000819781        0         1.4322             0                0.00182422   0.559322                    0.549841            0               1                          -100      43.2203            0.495146\n",
       "9        0.798817                    0.000312737        0         1.25185            0                0.000484883  0.488889                    0.480663            0               1                          -100      25.1852            0.330097\n",
       "10       0.899408                    0.00011333         0         1.11184            0                0.000207602  0.434211                    0.426928            0               1                          -100      11.1842            0.165049\n",
       "11       1                           2.562e-06          0         1                  0                5.36447e-05  0.390533                    0.383988            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.0313699851476705\n",
       "RMSE: 0.17711573941259567\n",
       "LogLoss: 0.11711592294593795\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.994535519125683\n",
       "AUCPR: 0.9918040042192442\n",
       "Gini: 0.9890710382513661\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2668740561060711\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    59          2             0.0328   (2.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       60          37            0.0309   (3.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.266874     0.958904  20\n",
       "max f2                       0.266874     0.966851  20\n",
       "max f0point5                 0.722029     0.982143  16\n",
       "max accuracy                 0.722029     0.969072  16\n",
       "max precision                0.977566     1         0\n",
       "max recall                   0.0131959    1         27\n",
       "max specificity              0.977566     1         0\n",
       "max absolute_mcc             0.722029     0.934718  16\n",
       "max min_per_class_accuracy   0.266874     0.967213  20\n",
       "max mean_per_class_accuracy  0.266874     0.969718  20\n",
       "max tns                      0.977566     61        0\n",
       "max fns                      0.977566     19        0\n",
       "max fps                      9.42667e-06  61        78\n",
       "max tps                      0.0131959    36        27\n",
       "max tnr                      0.977566     1         0\n",
       "max fnr                      0.977566     0.527778  0\n",
       "max fpr                      9.42667e-06  1         78\n",
       "max tpr                      0.0131959    1         27\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.95 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.175258                    0.977566           2.69444   2.69444            1                0.977566     1                           0.977566            0.472222        0.472222                   169.444   169.444            0.472222\n",
       "2        0.206186                    0.975073           2.69444   2.69444            1                0.976426     1                           0.977395            0.0833333       0.555556                   169.444   169.444            0.555556\n",
       "3        0.298969                    0.844465           2.69444   2.69444            1                0.938935     1                           0.965459            0.25            0.805556                   169.444   169.444            0.805556\n",
       "4        0.402062                    0.0904979          1.61667   2.41809            0.6              0.560222     0.897436                    0.861552            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "5        0.505155                    0.00652377         0.269444  1.97959            0.1              0.0245879    0.734694                    0.690743            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "6        0.597938                    0.00211604         0         1.67241            0                0.00366596   0.62069                     0.584128            0               1                          -100      67.2414            0.639344\n",
       "7        0.701031                    0.000546271        0         1.42647            0                0.0011275    0.529412                    0.498393            0               1                          -100      42.6471            0.47541\n",
       "8        0.793814                    0.0004147          0         1.25974            0                0.000459181  0.467532                    0.440193            0               1                          -100      25.974             0.327869\n",
       "9        0.896907                    8.79503e-05        0         1.11494            0                0.00025194   0.413793                    0.389625            0               1                          -100      11.4943            0.163934\n",
       "10       1                           9.42667e-06        0         1                  0                3.66146e-05  0.371134                    0.349461            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.040075001035739556\n",
       "RMSE: 0.2001874147786008\n",
       "LogLoss: 0.16448753718217035\n",
       "Mean Per-Class Error: 0.0469991173874669\n",
       "AUC: 0.9800492791997646\n",
       "AUCPR: 0.9720900769742027\n",
       "Gini: 0.9600985583995292\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4712741083954024\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    196         10            0.0485   (10.0/206.0)\n",
       "republican  6           126           0.0455   (6.0/132.0)\n",
       "Total       202         136           0.0473   (16.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.471274     0.940299  96\n",
       "max f2                       0.329081     0.956652  101\n",
       "max f0point5                 0.686043     0.945313  87\n",
       "max accuracy                 0.524595     0.952663  94\n",
       "max precision                0.980737     1         0\n",
       "max recall                   4.46172e-05  1         281\n",
       "max specificity              0.980737     1         0\n",
       "max absolute_mcc             0.471274     0.901373  96\n",
       "max min_per_class_accuracy   0.471274     0.951456  96\n",
       "max mean_per_class_accuracy  0.329081     0.953295  101\n",
       "max tns                      0.980737     206       0\n",
       "max fns                      0.980737     127       0\n",
       "max fps                      4.74175e-06  206       292\n",
       "max tps                      4.46172e-05  132       281\n",
       "max tnr                      0.980737     1         0\n",
       "max fnr                      0.980737     0.962121  0\n",
       "max fpr                      4.74175e-06  1         292\n",
       "max tpr                      4.46172e-05  1         281\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.28 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0147929                   0.980737           2.56061    2.56061            1                0.980737     1                           0.980737            0.0378788       0.0378788                  156.061   156.061            0.0378788\n",
       "2        0.0207101                   0.977987           2.56061    2.56061            1                0.980278     1                           0.980606            0.0151515       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.035503                    0.977243           2.56061    2.56061            1                0.977243     1                           0.979205            0.0378788       0.0909091                  156.061   156.061            0.0909091\n",
       "4        0.0414201                   0.976331           2.56061    2.56061            1                0.976707     1                           0.978848            0.0151515       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0621302                   0.976169           2.56061    2.56061            1                0.976169     1                           0.977955            0.0530303       0.159091                   156.061   156.061            0.159091\n",
       "6        0.100592                    0.974915           2.56061    2.56061            1                0.975424     1                           0.976987            0.0984848       0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.968755           2.56061    2.56061            1                0.97289      1                           0.975621            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.210059                    0.94955            2.30455    2.48848            0.9              0.959179     0.971831                    0.97099             0.136364        0.522727                   130.455   148.848            0.513019\n",
       "9        0.307692                    0.879433           2.48301    2.48674            0.969697         0.912643     0.971154                    0.952476            0.242424        0.765152                   148.301   148.674            0.750588\n",
       "10       0.399408                    0.473952           1.9824     2.37093            0.774194         0.746998     0.925926                    0.905292            0.181818        0.94697                    98.2405   137.093            0.898426\n",
       "11       0.5                         0.0414612          0.37656    1.9697             0.147059         0.187225     0.769231                    0.760829            0.0378788       0.984848                   -62.344   96.9697            0.795528\n",
       "12       0.600592                    0.00713601         0.0753119  1.65241            0.0294118        0.017412     0.64532                     0.636316            0.00757576      0.992424                   -92.4688  65.2411            0.64291\n",
       "13       0.701183                    0.00218696         0          1.41536            0                0.00437291   0.552743                    0.545657            0               0.992424                   -100      41.5356            0.477861\n",
       "14       0.798817                    0.000705082        0          1.24237            0                0.00125882   0.485185                    0.47912             0               0.992424                   -100      24.2368            0.317667\n",
       "15       0.899408                    0.000162374        0          1.10342            0                0.000369919  0.430921                    0.425575            0               0.992424                   -100      10.3419            0.152618\n",
       "16       1                           4.74e-06           0.0753119  1                  0.0294118        6.32868e-05  0.390533                    0.382772            0.00757576      1                          -92.4688  0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "accuracy                 0.9692319    0.03099544    0.9714286     0.9591837     1.0           1.0           0.9268293     0.9285714     0.93333334    0.972973      1.0           1.0\n",
       "aic                      nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan           nan           nan\n",
       "auc                      0.9864091    0.0139217125  0.9699074     0.96428573    1.0           1.0           0.978836      0.9791667     0.9777778     0.9941176     1.0           1.0\n",
       "err                      0.030768076  0.03099544    0.028571429   0.040816326   0.0           0.0           0.07317073    0.071428575   0.06666667    0.027027028   0.0           0.0\n",
       "err_count                1.1          1.1005049     1.0           2.0           0.0           0.0           3.0           2.0           2.0           1.0           0.0           0.0\n",
       "f0point5                 0.9513472    0.05263746    0.90909094    0.95238096    1.0           1.0           0.8783784     0.88235295    0.90361446    0.9876543     1.0           1.0\n",
       "f1                       0.9620383    0.037653547   0.9411765     0.95238096    1.0           1.0           0.8965517     0.9230769     0.9375        0.969697      1.0           1.0\n",
       "f2                       0.9737632    0.028093169   0.9756098     0.95238096    1.0           1.0           0.91549295    0.9677419     0.97402596    0.95238096    1.0           1.0\n",
       "lift_top_group           2.5712826    0.43638638    3.28125       2.3333333     2.6363637     2.4166667     2.9285715     2.3333333     2.0           2.1764705     3.2222223     2.3846154\n",
       "loglikelihood            nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan           nan           nan\n",
       "---                      ---          ---           ---           ---           ---           ---           ---           ---           ---           ---           ---           ---\n",
       "mcc                      0.9370362    0.062038954   0.9251849     0.9166667     1.0           1.0           0.8412485     0.8660254     0.87447464    0.94676214    1.0           1.0\n",
       "mean_per_class_accuracy  0.9708485    0.02998046    0.9814815     0.9583333     1.0           1.0           0.92724866    0.9375        0.93333334    0.9705882     1.0           1.0\n",
       "mean_per_class_error     0.029151494  0.02998046    0.018518519   0.041666668   0.0           0.0           0.07275132    0.0625        0.06666667    0.029411765   0.0           0.0\n",
       "mse                      0.03858682   0.022964632   0.032226056   0.04991104    0.024183638   0.02014527    0.07026854    0.05939228    0.07052797    0.03242197    0.0018608731  0.024930572\n",
       "pr_auc                   0.96835303   0.059137      0.8048837     0.9703948     1.0           1.0           0.9651168     0.9724552     0.97704047    0.9936392     1.0           1.0\n",
       "precision                0.9447432    0.063339405   0.8888889     0.95238096    1.0           1.0           0.8666667     0.85714287    0.88235295    1.0           1.0           1.0\n",
       "r2                       0.8348917    0.09628236    0.8172365     0.7961966     0.8972806     0.91695017    0.6875095     0.7574815     0.7178881     0.8694539     0.9913056     0.8976142\n",
       "recall                   0.9822129    0.029185247   1.0           0.95238096    1.0           1.0           0.9285714     1.0           1.0           0.9411765     1.0           1.0\n",
       "rmse                     0.18558204   0.06787347    0.17951617    0.22340779    0.1555109     0.14193404    0.26508215    0.24370532    0.26557103    0.18006101    0.043137837   0.15789418\n",
       "specificity              0.9594841    0.05283269    0.962963      0.96428573    1.0           1.0           0.9259259     0.875         0.8666667     1.0           1.0           1.0\n",
       "[22 rows x 13 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:09  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:09  1.630 sec   169000 obs/sec    1         1             338        0.593441         1.20973             -0.47961       0.961312        0.942401           2.52121          0.0976331                        0.580565           1.17328               -0.444151        0.970401          0.949013             2.69444            0.0824742\n",
       "    2025-05-26 14:48:09  1.649 sec   48285 obs/sec     2         2             676        0.263768         0.246487            0.707696       0.971591        0.942394           2.46212          0.0710059                        0.259186           0.234921              0.712171         0.974499          0.957264             2.69444            0.0618557\n",
       "    2025-05-26 14:48:09  1.667 sec   39000 obs/sec     3         3             1014       0.222741         0.17967             0.791555       0.979994        0.955802           2.48059          0.0502959                        0.237719           0.200098              0.757874         0.978597          0.966334             2.69444            0.0515464\n",
       "    2025-05-26 14:48:09  1.688 sec   34666 obs/sec     4         4             1352       0.206293         0.153169            0.821203       0.984665        0.968858           2.5235           0.0443787                        0.219144           0.173054              0.794236         0.981785          0.97151              2.69444            0.0412371\n",
       "    2025-05-26 14:48:09  1.707 sec   33137 obs/sec     5         5             1690       0.1924           0.134948            0.844475       0.986595        0.967645           2.48529          0.0414201                        0.219789           0.173743              0.793022         0.983151          0.973672             2.69444            0.0412371\n",
       "    2025-05-26 14:48:09  1.727 sec   31687 obs/sec     6         6             2028       0.181619         0.122195            0.861415       0.988618        0.970294           2.47525          0.035503                         0.209274           0.157206              0.812353         0.985428          0.977025             2.69444            0.0412371\n",
       "    2025-05-26 14:48:09  1.752 sec   29209 obs/sec     7         7             2366       0.173485         0.11306             0.873551       0.989942        0.974836           2.50241          0.0325444                        0.19745            0.139174              0.832958         0.989526          0.982445             2.69444            0.0412371\n",
       "    2025-05-26 14:48:09  1.783 sec   27591 obs/sec     8         8             2704       0.166301         0.105129            0.883806       0.990953        0.976361           2.50106          0.0266272                        0.193699           0.135082              0.839245         0.990437          0.984705             2.69444            0.0412371\n",
       "    2025-05-26 14:48:09  1.809 sec   27160 obs/sec     9         9             3042       0.163542         0.101648            0.88763        0.991376        0.97471            2.47525          0.0236686                        0.192596           0.137606              0.841069         0.991348          0.98676              2.69444            0.0412371\n",
       "    2025-05-26 14:48:09  1.829 sec   26825 obs/sec     10        10            3380       0.157611         0.0951942           0.895632       0.99202         0.979105           2.5104           0.0266272                        0.179638           0.116973              0.861737         0.99408           0.990975             2.69444            0.0309278\n",
       "    2025-05-26 14:48:09  1.848 sec   26748 obs/sec     11        11            3718       0.153527         0.0912178           0.900971       0.992332        0.978985           2.50494          0.0236686                        0.177116           0.117116              0.865592         0.994536          0.991804             2.69444            0.0309278\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.n                              1.0                    1.0                  0.04589768747785366\n",
       "synfuels-corporation-cutback.n                      0.8481765985488892     0.8481765985488892   0.03892934444622586\n",
       "el-salvador-aid.?                                   0.6823165416717529     0.6823165416717529   0.031316751390620026\n",
       "water-project-cost-sharing.y                        0.6660595536231995     0.6660595536231995   0.03057059323383632\n",
       "physician-fee-freeze.y                              0.6104474663734436     0.6104474663734436   0.028018127033255895\n",
       "crime.n                                             0.6070754528045654     0.6070754528045654   0.027863359408300443\n",
       "adoption-of-the-budget-resolution.y                 0.5845112204551697     0.5845112204551697   0.0268277133237502\n",
       "el-salvador-aid.n                                   0.5741303563117981     0.5741303563117981   0.026351255665547673\n",
       "aid-to-nicaraguan-contras.y                         0.5629771947860718     0.5629771947860718   0.025839351343449866\n",
       "adoption-of-the-budget-resolution.n                 0.5458343029022217     0.5458343029022217   0.02505253224929828\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[5,5,5], nfolds=10, activation=\"rectifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6159685384042",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [20,20,20], cross folds = 10, activation function = \"rectifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "303d5f3b0a2a00fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:53:30.089362Z",
     "start_time": "2025-05-09T14:53:29.161038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_829\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-81.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-81 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-81 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-81 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-81 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-81 .h2o-table th,\n",
       "#h2o-table-81 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-81 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-81\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2607449</td>\n",
       "<td>0.4345804</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005905</td>\n",
       "<td>0.1591191</td>\n",
       "<td>0.5065914</td>\n",
       "<td>0.0370423</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042765</td>\n",
       "<td>0.0121264</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042644</td>\n",
       "<td>0.2220984</td>\n",
       "<td>1.0005179</td>\n",
       "<td>0.0247876</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>20</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0525343</td>\n",
       "<td>0.2167396</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0093173</td>\n",
       "<td>0.2141045</td>\n",
       "<td>0.9965032</td>\n",
       "<td>0.0184232</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0536754</td>\n",
       "<td>0.2165301</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0369952</td>\n",
       "<td>1.1533446</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.0230692</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.012480409338631761\n",
       "RMSE: 0.1117157524193959\n",
       "LogLoss: 0.05231274762045036\n",
       "Mean Per-Class Error: 0.012135922330097087\n",
       "AUC: 0.9973153868784936\n",
       "AUCPR: 0.9946770169199727\n",
       "Gini: 0.9946307737569873</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-82.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-82 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-82 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-82 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-82 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-82 .h2o-table th,\n",
       "#h2o-table-82 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-82 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-82\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3643252864977982</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>201.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0243</td>\n",
       "<td> (5.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>0.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>201.0</td>\n",
       "<td>137.0</td>\n",
       "<td>0.0148</td>\n",
       "<td> (5.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-83.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-83 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-83 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-83 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-83 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-83 .h2o-table th,\n",
       "#h2o-table-83 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-83 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-83\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9814126</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9924812</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7518913</td>\n",
       "<td>0.9860248</td>\n",
       "<td>89.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6601833</td>\n",
       "<td>0.9852071</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9986951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3643253</td>\n",
       "<td>1.0</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9986951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9695966</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6601833</td>\n",
       "<td>0.9848485</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3643253</td>\n",
       "<td>0.9878641</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9986951</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9986951</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000001</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.3643253</td>\n",
       "<td>132.0</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9986951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9986951</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000001</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.3643253</td>\n",
       "<td>1.0</td>\n",
       "<td>98.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-84.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-84 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-84 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-84 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-84 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-84 .h2o-table th,\n",
       "#h2o-table-84 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-84 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-84\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.25 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.9986603</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986709</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986709</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0454545</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0454545</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9982512</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985914</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986596</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9978483</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979905</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984163</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9976263</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976796</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982198</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9973750</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974802</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981328</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9960824</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9968098</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974713</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9930050</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9949553</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966326</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2071006</td>\n",
       "<td>0.9911866</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920798</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9953969</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.5303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5303030</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9758081</td>\n",
       "<td>2.4805871</td>\n",
       "<td>2.5355021</td>\n",
       "<td>0.96875</td>\n",
       "<td>0.9839651</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9918104</td>\n",
       "<td>0.2348485</td>\n",
       "<td>0.7651515</td>\n",
       "<td>148.0587121</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4472810</td>\n",
       "<td>2.3278237</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.8555675</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9585066</td>\n",
       "<td>0.2272727</td>\n",
       "<td>0.9924242</td>\n",
       "<td>132.7823691</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0079393</td>\n",
       "<td>0.0753119</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0928559</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7843520</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0006303</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0027220</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6534386</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0001070</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003059</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5621107</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8076923</td>\n",
       "<td>0.0000244</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2380952</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000571</td>\n",
       "<td>0.4835165</td>\n",
       "<td>0.4859350</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>23.8095238</td>\n",
       "<td>0.3155340</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000064</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000151</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4363839</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000020</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3924875</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.02497777782325209\n",
       "RMSE: 0.15804359469226234\n",
       "LogLoss: 0.09661960962432892\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.9903601378148524\n",
       "Gini: 0.9881602914389798</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-85.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-85 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-85 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-85 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-85 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-85 .h2o-table th,\n",
       "#h2o-table-85 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-85 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-85\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.55041510917735</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0164</td>\n",
       "<td> (1.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-86.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-86 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-86 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-86 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-86 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-86 .h2o-table th,\n",
       "#h2o-table-86 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-86 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-86\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9793814</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0186975</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9558288</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5504151</td>\n",
       "<td>0.9779144</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9981316</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9981316</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000001</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0186975</td>\n",
       "<td>36.0</td>\n",
       "<td>39.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9981316</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000001</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0186975</td>\n",
       "<td>1.0</td>\n",
       "<td>39.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-87.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-87 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-87 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-87 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-87 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-87 .h2o-table th,\n",
       "#h2o-table-87 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-87 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-87\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.44 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9978607</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981316</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981316</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9978494</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978494</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979435</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9976531</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9979435</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0833333</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9972988</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976263</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978642</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9971110</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9972364</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9977386</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9965325</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9968606</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9972996</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9937892</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9953205</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966399</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9912272</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9923227</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9955606</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.8122057</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9466246</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9803735</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.1201933</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.5742891</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8762493</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0027337</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0181709</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7011313</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0009026</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016231</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5925869</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0001708</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0004711</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5055110</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0000564</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001082</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4464380</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000187</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000381</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3951277</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000029</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3543931</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.03196380751758517\n",
       "RMSE: 0.1787842485164316\n",
       "LogLoss: 0.11259326192740371\n",
       "Mean Per-Class Error: 0.03427478670197116\n",
       "AUC: 0.9909899970579583\n",
       "AUCPR: 0.9840426781959261\n",
       "Gini: 0.9819799941159166</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-88.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-88 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-88 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-88 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-88 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-88 .h2o-table th,\n",
       "#h2o-table-88 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-88 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-88\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.28813296823683565</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>195.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0534</td>\n",
       "<td> (11.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>197.0</td>\n",
       "<td>141.0</td>\n",
       "<td>0.0385</td>\n",
       "<td> (13.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-89.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-89 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-89 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-89 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-89 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-89 .h2o-table th,\n",
       "#h2o-table-89 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-89 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-89\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2881330</td>\n",
       "<td>0.9523810</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1993299</td>\n",
       "<td>0.9732541</td>\n",
       "<td>139.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8211303</td>\n",
       "<td>0.9583333</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3699366</td>\n",
       "<td>0.9615385</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9989466</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0065096</td>\n",
       "<td>1.0</td>\n",
       "<td>177.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9989466</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2881330</td>\n",
       "<td>0.9215898</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3919192</td>\n",
       "<td>0.9563107</td>\n",
       "<td>130.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2881330</td>\n",
       "<td>0.9657252</td>\n",
       "<td>135.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9989466</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9989466</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000011</td>\n",
       "<td>206.0</td>\n",
       "<td>326.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0065096</td>\n",
       "<td>132.0</td>\n",
       "<td>177.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9989466</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9989466</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000011</td>\n",
       "<td>1.0</td>\n",
       "<td>326.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0065096</td>\n",
       "<td>1.0</td>\n",
       "<td>177.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-90.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-90 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-90 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-90 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-90 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-90 .h2o-table th,\n",
       "#h2o-table-90 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-90 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-90\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.81 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9979736</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983593</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983593</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9975160</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9977302</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980897</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9972716</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973491</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978204</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9967253</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969954</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976436</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9966051</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9966841</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9974743</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9941404</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9955967</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9965355</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9905209</td>\n",
       "<td>2.4099822</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9926802</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9952504</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.3787879</td>\n",
       "<td>140.9982175</td>\n",
       "<td>151.0398099</td>\n",
       "<td>0.3739335</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9869051</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5229501</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9887219</td>\n",
       "<td>0.9852941</td>\n",
       "<td>0.9936183</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5075758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>152.2950089</td>\n",
       "<td>0.5027214</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9556547</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5355021</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9760927</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9877764</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7651515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4034427</td>\n",
       "<td>1.9398531</td>\n",
       "<td>2.3898990</td>\n",
       "<td>0.7575758</td>\n",
       "<td>0.7759017</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.9359848</td>\n",
       "<td>0.1893939</td>\n",
       "<td>0.9545455</td>\n",
       "<td>93.9853076</td>\n",
       "<td>138.9898990</td>\n",
       "<td>0.9108561</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0174742</td>\n",
       "<td>0.3765597</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.1470588</td>\n",
       "<td>0.1331619</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7744702</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-62.3440285</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0020947</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0068800</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6459083</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0004172</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010223</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5557335</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0001106</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002425</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4857828</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000264</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000516</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4314576</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>1.11e-06</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000101</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3880576</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-91.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-91 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-91 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-91 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-91 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-91 .h2o-table th,\n",
       "#h2o-table-91 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-91 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-91\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th>\n",
       "<th>cv_6_valid</th>\n",
       "<th>cv_7_valid</th>\n",
       "<th>cv_8_valid</th>\n",
       "<th>cv_9_valid</th>\n",
       "<th>cv_10_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9743692</td>\n",
       "<td>0.0310579</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.8979592</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9666666</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9677419</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9897450</td>\n",
       "<td>0.0145781</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.984127</td>\n",
       "<td>0.9947917</td>\n",
       "<td>0.9955556</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9957265</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0256308</td>\n",
       "<td>0.0310579</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.1020408</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0322581</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.0</td>\n",
       "<td>1.4907119</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9562836</td>\n",
       "<td>0.0525075</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.84</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9848485</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9493671</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.942029</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9688461</td>\n",
       "<td>0.0340848</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.8936170</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.96</td>\n",
       "<td>0.9677419</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9827482</td>\n",
       "<td>0.0203219</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9545454</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.942029</td>\n",
       "<td>0.9836066</td>\n",
       "<td>0.9868421</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9848485</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.2431576</td>\n",
       "<td>0.865684</td>\n",
       "<td>0.0</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.6363637</td>\n",
       "<td>2.4166667</td>\n",
       "<td>2.9285715</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>3.2222223</td>\n",
       "<td>2.3846154</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9488125</td>\n",
       "<td>0.0574966</td>\n",
       "<td>0.9251849</td>\n",
       "<td>0.8145315</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9462601</td>\n",
       "<td>0.9302605</td>\n",
       "<td>0.9354144</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9364743</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9764121</td>\n",
       "<td>0.0276601</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9107143</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.96875</td>\n",
       "<td>0.9666666</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0235880</td>\n",
       "<td>0.0276601</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.0892857</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0289660</td>\n",
       "<td>0.0224205</td>\n",
       "<td>0.0316839</td>\n",
       "<td>0.0811643</td>\n",
       "<td>0.0071556</td>\n",
       "<td>0.0127849</td>\n",
       "<td>0.0333361</td>\n",
       "<td>0.0346909</td>\n",
       "<td>0.0327316</td>\n",
       "<td>0.0143096</td>\n",
       "<td>0.0029626</td>\n",
       "<td>0.0388406</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9641623</td>\n",
       "<td>0.0851148</td>\n",
       "<td>0.7253469</td>\n",
       "<td>0.9549323</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9780172</td>\n",
       "<td>0.9933298</td>\n",
       "<td>0.9956974</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9942994</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9485729</td>\n",
       "<td>0.0648125</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.8076923</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.875399</td>\n",
       "<td>0.0935215</td>\n",
       "<td>0.8203113</td>\n",
       "<td>0.6685790</td>\n",
       "<td>0.9696066</td>\n",
       "<td>0.9472936</td>\n",
       "<td>0.8517513</td>\n",
       "<td>0.8583454</td>\n",
       "<td>0.8690735</td>\n",
       "<td>0.9423829</td>\n",
       "<td>0.9861583</td>\n",
       "<td>0.8404878</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9928572</td>\n",
       "<td>0.0225877</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1581442</td>\n",
       "<td>0.0663025</td>\n",
       "<td>0.1779997</td>\n",
       "<td>0.2848935</td>\n",
       "<td>0.0845910</td>\n",
       "<td>0.1130704</td>\n",
       "<td>0.1825818</td>\n",
       "<td>0.1862550</td>\n",
       "<td>0.1809188</td>\n",
       "<td>0.1196226</td>\n",
       "<td>0.0544294</td>\n",
       "<td>0.1970803</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9599670</td>\n",
       "<td>0.0564409</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.8214286</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9333333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9444444</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 13 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-92.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-92 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-92 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-92 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-92 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-92 .h2o-table th,\n",
       "#h2o-table-92 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-92 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-92\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 1.714 sec</td>\n",
       "<td>67600 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2442084</td>\n",
       "<td>0.1914721</td>\n",
       "<td>0.7494390</td>\n",
       "<td>0.9782657</td>\n",
       "<td>0.9632222</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0739645</td>\n",
       "<td>0.2653601</td>\n",
       "<td>0.2668435</td>\n",
       "<td>0.6982952</td>\n",
       "<td>0.9599271</td>\n",
       "<td>0.9498725</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0824742</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 1.737 sec</td>\n",
       "<td>32190 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1991910</td>\n",
       "<td>0.1337020</td>\n",
       "<td>0.8333015</td>\n",
       "<td>0.9878641</td>\n",
       "<td>0.9776065</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0473373</td>\n",
       "<td>0.2442234</td>\n",
       "<td>0.2079910</td>\n",
       "<td>0.7444442</td>\n",
       "<td>0.9763206</td>\n",
       "<td>0.9681289</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0721649</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 1.760 sec</td>\n",
       "<td>26684 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1667623</td>\n",
       "<td>0.1023519</td>\n",
       "<td>0.8831609</td>\n",
       "<td>0.9911739</td>\n",
       "<td>0.9799595</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.2209233</td>\n",
       "<td>0.1727135</td>\n",
       "<td>0.7908807</td>\n",
       "<td>0.9840619</td>\n",
       "<td>0.9771650</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 1.784 sec</td>\n",
       "<td>25037 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1548635</td>\n",
       "<td>0.0900348</td>\n",
       "<td>0.8992394</td>\n",
       "<td>0.9926817</td>\n",
       "<td>0.9842176</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.2063223</td>\n",
       "<td>0.1460797</td>\n",
       "<td>0.8176089</td>\n",
       "<td>0.9867942</td>\n",
       "<td>0.9804180</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0515464</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 1.807 sec</td>\n",
       "<td>24142 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1457774</td>\n",
       "<td>0.0807554</td>\n",
       "<td>0.9107162</td>\n",
       "<td>0.9939688</td>\n",
       "<td>0.9873278</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1937603</td>\n",
       "<td>0.1326955</td>\n",
       "<td>0.8391427</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9854463</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 1.832 sec</td>\n",
       "<td>23310 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1469839</td>\n",
       "<td>0.0811612</td>\n",
       "<td>0.9092322</td>\n",
       "<td>0.9949250</td>\n",
       "<td>0.9889383</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.2147133</td>\n",
       "<td>0.1613537</td>\n",
       "<td>0.8024719</td>\n",
       "<td>0.9904372</td>\n",
       "<td>0.9849707</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:13</td>\n",
       "<td> 1.856 sec</td>\n",
       "<td>22970 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1302942</td>\n",
       "<td>0.0669045</td>\n",
       "<td>0.9286749</td>\n",
       "<td>0.9964695</td>\n",
       "<td>0.9930110</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1734686</td>\n",
       "<td>0.1102418</td>\n",
       "<td>0.8710703</td>\n",
       "<td>0.9931694</td>\n",
       "<td>0.9888850</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:14</td>\n",
       "<td> 1.880 sec</td>\n",
       "<td>22722 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1257635</td>\n",
       "<td>0.0626863</td>\n",
       "<td>0.9335490</td>\n",
       "<td>0.9968005</td>\n",
       "<td>0.9936383</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1701342</td>\n",
       "<td>0.1075819</td>\n",
       "<td>0.8759793</td>\n",
       "<td>0.9931694</td>\n",
       "<td>0.9884437</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:14</td>\n",
       "<td> 1.904 sec</td>\n",
       "<td>22367 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1352762</td>\n",
       "<td>0.0704332</td>\n",
       "<td>0.9231161</td>\n",
       "<td>0.9964328</td>\n",
       "<td>0.9920966</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.2001105</td>\n",
       "<td>0.1420475</td>\n",
       "<td>0.8284263</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:14</td>\n",
       "<td> 1.929 sec</td>\n",
       "<td>21948 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1204756</td>\n",
       "<td>0.0587115</td>\n",
       "<td>0.9390196</td>\n",
       "<td>0.9970947</td>\n",
       "<td>0.9939040</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1596359</td>\n",
       "<td>0.0953582</td>\n",
       "<td>0.8908127</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:14</td>\n",
       "<td> 1.966 sec</td>\n",
       "<td>20655 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1117158</td>\n",
       "<td>0.0523127</td>\n",
       "<td>0.9475650</td>\n",
       "<td>0.9973154</td>\n",
       "<td>0.9946770</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1580436</td>\n",
       "<td>0.0966196</td>\n",
       "<td>0.8929800</td>\n",
       "<td>0.9940801</td>\n",
       "<td>0.9903601</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-93.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-93 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-93 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-93 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-93 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-93 .h2o-table th,\n",
       "#h2o-table-93 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-93 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-93\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>el-salvador-aid.?</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0269998</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.9803649</td>\n",
       "<td>0.9803649</td>\n",
       "<td>0.0264697</td></tr>\n",
       "<tr><td>crime.?</td>\n",
       "<td>0.9715016</td>\n",
       "<td>0.9715016</td>\n",
       "<td>0.0262304</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9657401</td>\n",
       "<td>0.9657401</td>\n",
       "<td>0.0260748</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.9546074</td>\n",
       "<td>0.9546074</td>\n",
       "<td>0.0257742</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9333184</td>\n",
       "<td>0.9333184</td>\n",
       "<td>0.0251994</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.?</td>\n",
       "<td>0.9329675</td>\n",
       "<td>0.9329675</td>\n",
       "<td>0.0251900</td></tr>\n",
       "<tr><td>superfund-right-to-sue.y</td>\n",
       "<td>0.9286214</td>\n",
       "<td>0.9286214</td>\n",
       "<td>0.0250726</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.y</td>\n",
       "<td>0.8797601</td>\n",
       "<td>0.8797601</td>\n",
       "<td>0.0237534</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.8578669</td>\n",
       "<td>0.8578669</td>\n",
       "<td>0.0231623</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_829\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms             momentum    mean_weight            weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  -------------------  ----------  ---------------------  -------------------  -----------------------  --------------------\n",
       "    1        64       Input      0.0\n",
       "    2        20       Rectifier  0.0        0.0   0.0   0.26074486959576004   0.4345804452896118   0.0         0.0005905363869032953  0.15911906957626343  0.506591416448452        0.03704230487346649\n",
       "    3        20       Rectifier  0.0        0.0   0.0   0.004276484863075893  0.0121263787150383   0.0         0.004264391815522686   0.22209841012954712  1.0005178812546662       0.02478756010532379\n",
       "    4        20       Rectifier  0.0        0.0   0.0   0.05253426652980124   0.21673959493637085  0.0         0.00931727505492745    0.2141045331954956   0.9965031925472785       0.018423162400722504\n",
       "    5        2        Softmax               0.0   0.0   0.05367538485006662   0.21653014421463013  0.0         0.036995189543813464   1.1533446311950684   -1.0408340855860843e-17  0.023069165647029877\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.012480409338631761\n",
       "RMSE: 0.1117157524193959\n",
       "LogLoss: 0.05231274762045036\n",
       "Mean Per-Class Error: 0.012135922330097087\n",
       "AUC: 0.9973153868784936\n",
       "AUCPR: 0.9946770169199727\n",
       "Gini: 0.9946307737569873\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3643252864977982\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    201         5             0.0243   (5.0/206.0)\n",
       "republican  0           132           0        (0.0/132.0)\n",
       "Total       201         137           0.0148   (5.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.364325     0.981413  98\n",
       "max f2                       0.364325     0.992481  98\n",
       "max f0point5                 0.751891     0.986025  89\n",
       "max accuracy                 0.660183     0.985207  94\n",
       "max precision                0.998695     1         0\n",
       "max recall                   0.364325     1         98\n",
       "max specificity              0.998695     1         0\n",
       "max absolute_mcc             0.364325     0.969597  98\n",
       "max min_per_class_accuracy   0.660183     0.984848  94\n",
       "max mean_per_class_accuracy  0.364325     0.987864  98\n",
       "max tns                      0.998695     206       0\n",
       "max fns                      0.998695     131       0\n",
       "max fps                      9.94648e-08  206       269\n",
       "max tps                      0.364325     132       98\n",
       "max tnr                      0.998695     1         0\n",
       "max fnr                      0.998695     0.992424  0\n",
       "max fpr                      9.94648e-08  1         269\n",
       "max tpr                      0.364325     1         98\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.25 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0177515                   0.99866            2.56061    2.56061            1                0.998671     1                           0.998671            0.0454545       0.0454545                  156.061   156.061            0.0454545\n",
       "2        0.0207101                   0.998251           2.56061    2.56061            1                0.998591     1                           0.99866             0.00757576      0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.997848           2.56061    2.56061            1                0.997991     1                           0.998416            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0443787                   0.997626           2.56061    2.56061            1                0.99768      1                           0.99822             0.030303        0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.997375           2.56061    2.56061            1                0.99748      1                           0.998133            0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.996082           2.56061    2.56061            1                0.99681      1                           0.997471            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.993005           2.56061    2.56061            1                0.994955     1                           0.996633            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.207101                    0.991187           2.56061    2.56061            1                0.99208      1                           0.995397            0.143939        0.530303                   156.061   156.061            0.530303\n",
       "9        0.301775                    0.975808           2.48059    2.5355             0.96875          0.983965     0.990196                    0.99181             0.234848        0.765152                   148.059   153.55             0.760297\n",
       "10       0.399408                    0.447281           2.32782    2.48474            0.909091         0.855567     0.97037                     0.958507            0.227273        0.992424                   132.782   148.474            0.973007\n",
       "11       0.5                         0.00793931         0.0753119  2                  0.0294118        0.0928559    0.781065                    0.784352            0.00757576      1                          -92.4688  100                0.820388\n",
       "12       0.600592                    0.000630331        0          1.66502            0                0.00272203   0.650246                    0.653439            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.00010698         0          1.4322             0                0.000305936  0.559322                    0.562111            0               1                          -100      43.2203            0.495146\n",
       "14       0.807692                    2.44045e-05        0          1.2381             0                5.70641e-05  0.483516                    0.485935            0               1                          -100      23.8095            0.315534\n",
       "15       0.899408                    6.4403e-06         0          1.11184            0                1.51499e-05  0.434211                    0.436384            0               1                          -100      11.1842            0.165049\n",
       "16       1                           9.94648e-08        0          1                  0                2.0128e-06   0.390533                    0.392488            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.02497777782325209\n",
       "RMSE: 0.15804359469226234\n",
       "LogLoss: 0.09661960962432892\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9940801457194899\n",
       "AUCPR: 0.9903601378148524\n",
       "Gini: 0.9881602914389798\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.55041510917735\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    60          1             0.0164   (1.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       61          36            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.550415     0.972222  32\n",
       "max f2                       0.550415     0.972222  32\n",
       "max f0point5                 0.550415     0.972222  32\n",
       "max accuracy                 0.550415     0.979381  32\n",
       "max precision                0.998132     1         0\n",
       "max recall                   0.0186975    1         39\n",
       "max specificity              0.998132     1         0\n",
       "max absolute_mcc             0.550415     0.955829  32\n",
       "max min_per_class_accuracy   0.550415     0.972222  32\n",
       "max mean_per_class_accuracy  0.550415     0.977914  32\n",
       "max tns                      0.998132     61        0\n",
       "max fns                      0.998132     35        0\n",
       "max fps                      9.94648e-08  61        91\n",
       "max tps                      0.0186975    36        39\n",
       "max tnr                      0.998132     1         0\n",
       "max fnr                      0.998132     0.972222  0\n",
       "max fpr                      9.94648e-08  1         91\n",
       "max tpr                      0.0186975    1         39\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.44 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0103093                   0.997861           2.69444   2.69444            1                0.998132     1                           0.998132            0.0277778       0.0277778                  169.444   169.444            0.0277778\n",
       "2        0.0309278                   0.997849           2.69444   2.69444            1                0.997849     1                           0.997943            0.0555556       0.0833333                  169.444   169.444            0.0833333\n",
       "3        0.0309278                   0.997653           0         2.69444            0                0            1                           0.997943            0               0.0833333                  -100      169.444            0.0833333\n",
       "4        0.0412371                   0.997299           2.69444   2.69444            1                0.997626     1                           0.997864            0.0277778       0.111111                   169.444   169.444            0.111111\n",
       "5        0.0515464                   0.997111           2.69444   2.69444            1                0.997236     1                           0.997739            0.0277778       0.138889                   169.444   169.444            0.138889\n",
       "6        0.103093                    0.996533           2.69444   2.69444            1                0.996861     1                           0.9973              0.138889        0.277778                   169.444   169.444            0.277778\n",
       "7        0.154639                    0.993789           2.69444   2.69444            1                0.995321     1                           0.99664             0.138889        0.416667                   169.444   169.444            0.416667\n",
       "8        0.206186                    0.991227           2.69444   2.69444            1                0.992323     1                           0.995561            0.138889        0.555556                   169.444   169.444            0.555556\n",
       "9        0.298969                    0.812206           2.69444   2.69444            1                0.946625     1                           0.980374            0.25            0.805556                   169.444   169.444            0.805556\n",
       "10       0.402062                    0.120193           1.61667   2.41809            0.6              0.574289     0.897436                    0.876249            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "11       0.505155                    0.00273365         0.269444  1.97959            0.1              0.0181709    0.734694                    0.701131            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "12       0.597938                    0.000902566        0         1.67241            0                0.00162306   0.62069                     0.592587            0               1                          -100      67.2414            0.639344\n",
       "13       0.701031                    0.00017083         0         1.42647            0                0.000471052  0.529412                    0.505511            0               1                          -100      42.6471            0.47541\n",
       "14       0.793814                    5.64032e-05        0         1.25974            0                0.000108226  0.467532                    0.446438            0               1                          -100      25.974             0.327869\n",
       "15       0.896907                    1.87338e-05        0         1.11494            0                3.81128e-05  0.413793                    0.395128            0               1                          -100      11.4943            0.163934\n",
       "16       1                           9.94648e-08        0         1                  0                2.92246e-06  0.371134                    0.354393            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.03196380751758517\n",
       "RMSE: 0.1787842485164316\n",
       "LogLoss: 0.11259326192740371\n",
       "Mean Per-Class Error: 0.03427478670197116\n",
       "AUC: 0.9909899970579583\n",
       "AUCPR: 0.9840426781959261\n",
       "Gini: 0.9819799941159166\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.28813296823683565\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    195         11            0.0534   (11.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       197         141           0.0385   (13.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.288133     0.952381  135\n",
       "max f2                       0.19933      0.973254  139\n",
       "max f0point5                 0.82113      0.958333  111\n",
       "max accuracy                 0.369937     0.961538  131\n",
       "max precision                0.998947     1         0\n",
       "max recall                   0.00650964   1         177\n",
       "max specificity              0.998947     1         0\n",
       "max absolute_mcc             0.288133     0.92159   135\n",
       "max min_per_class_accuracy   0.391919     0.956311  130\n",
       "max mean_per_class_accuracy  0.288133     0.965725  135\n",
       "max tns                      0.998947     206       0\n",
       "max fns                      0.998947     131       0\n",
       "max fps                      1.11214e-06  206       326\n",
       "max tps                      0.00650964   132       177\n",
       "max tnr                      0.998947     1         0\n",
       "max fnr                      0.998947     0.992424  0\n",
       "max fpr                      1.11214e-06  1         326\n",
       "max tpr                      0.00650964   1         177\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.81 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.997974           2.56061    2.56061            1                0.998359     1                           0.998359            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.997516           2.56061    2.56061            1                0.99773      1                           0.99809             0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.997272           2.56061    2.56061            1                0.997349     1                           0.99782             0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.996725           2.56061    2.56061            1                0.996995     1                           0.997644            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.996605           2.56061    2.56061            1                0.996684     1                           0.997474            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.99414            2.56061    2.56061            1                0.995597     1                           0.996535            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.990521           2.40998    2.5104             0.941176         0.99268      0.980392                    0.99525             0.121212        0.378788                   140.998   151.04             0.373934\n",
       "8        0.201183                    0.986905           2.56061    2.52295            1                0.988722     0.985294                    0.993618            0.128788        0.507576                   156.061   152.295            0.502721\n",
       "9        0.301775                    0.955655           2.56061    2.5355             1                0.976093     0.990196                    0.987776            0.257576        0.765152                   156.061   153.55             0.760297\n",
       "10       0.399408                    0.403443           1.93985    2.3899             0.757576         0.775902     0.933333                    0.935985            0.189394        0.954545                   93.9853   138.99             0.910856\n",
       "11       0.5                         0.0174742          0.37656    1.98485            0.147059         0.133162     0.775148                    0.77447             0.0378788       0.992424                   -62.344   98.4848            0.807958\n",
       "12       0.600592                    0.00209474         0.0753119  1.66502            0.0294118        0.00688004   0.650246                    0.645908            0.00757576      1                          -92.4688  66.5025            0.65534\n",
       "13       0.698225                    0.000417189        0          1.4322             0                0.00102225   0.559322                    0.555734            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    0.000110606        0          1.25185            0                0.000242549  0.488889                    0.485783            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    2.6378e-05         0          1.11184            0                5.16021e-05  0.434211                    0.431458            0               1                          -100      11.1842            0.165049\n",
       "16       1                           1.11e-06           0          1                  0                1.00824e-05  0.390533                    0.388058            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "accuracy                 0.97436917   0.03105793    0.9714286     0.8979592     1.0           1.0           0.9756098     0.96428573    0.96666664    1.0           1.0           0.9677419\n",
       "aic                      nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan           nan           nan\n",
       "auc                      0.98974496   0.0145780835  0.962963      0.96428573    1.0           1.0           0.984127      0.9947917     0.9955556     1.0           1.0           0.99572647\n",
       "err                      0.025630817  0.03105793    0.028571429   0.10204082    0.0           0.0           0.024390243   0.035714287   0.033333335   0.0           0.0           0.032258064\n",
       "err_count                1.0          1.4907119     1.0           5.0           0.0           0.0           1.0           1.0           1.0           0.0           0.0           1.0\n",
       "f0point5                 0.95628357   0.05250749    0.90909094    0.84          1.0           1.0           0.9848485     0.9375        0.9493671     1.0           1.0           0.942029\n",
       "f1                       0.96884614   0.03408483    0.9411765     0.89361703    1.0           1.0           0.962963      0.96          0.9677419     1.0           1.0           0.962963\n",
       "f2                       0.98274815   0.02032189    0.9756098     0.95454544    1.0           1.0           0.942029      0.9836066     0.9868421     1.0           1.0           0.9848485\n",
       "lift_top_group           2.2431576    0.865684      0.0           2.3333333     2.6363637     2.4166667     2.9285715     2.3333333     2.0           2.1764705     3.2222223     2.3846154\n",
       "loglikelihood            nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan           nan           nan\n",
       "---                      ---          ---           ---           ---           ---           ---           ---           ---           ---           ---           ---           ---\n",
       "mcc                      0.94881254   0.057496596   0.9251849     0.8145315     1.0           1.0           0.9462601     0.93026054    0.9354144     1.0           1.0           0.9364743\n",
       "mean_per_class_accuracy  0.97641206   0.027660126   0.9814815     0.91071427    1.0           1.0           0.96428573    0.96875       0.96666664    1.0           1.0           0.9722222\n",
       "mean_per_class_error     0.023587963  0.027660126   0.018518519   0.08928572    0.0           0.0           0.035714287   0.03125       0.033333335   0.0           0.0           0.027777778\n",
       "mse                      0.028966017  0.022420531   0.031683892   0.08116432    0.0071556447  0.012784908   0.033336125   0.0346909     0.03273162    0.014309565   0.0029625592  0.03884064\n",
       "pr_auc                   0.9641623    0.08511479    0.7253469     0.9549323     1.0           1.0           0.97801715    0.99332976    0.99569744    1.0           1.0           0.9942994\n",
       "precision                0.94857293   0.064812526   0.8888889     0.8076923     1.0           1.0           1.0           0.9230769     0.9375        1.0           1.0           0.9285714\n",
       "r2                       0.875399     0.09352146    0.82031125    0.66857904    0.9696066     0.9472936     0.85175127    0.85834545    0.8690735     0.94238293    0.98615825    0.8404878\n",
       "recall                   0.99285716   0.022587698   1.0           1.0           1.0           1.0           0.9285714     1.0           1.0           1.0           1.0           1.0\n",
       "rmse                     0.15814425   0.066302456   0.17799969    0.2848935     0.084591046   0.11307036    0.18258184    0.18625495    0.18091881    0.119622596   0.054429397   0.19708028\n",
       "specificity              0.95996696   0.056440867   0.962963      0.8214286     1.0           1.0           1.0           0.9375        0.93333334    1.0           1.0           0.9444444\n",
       "[22 rows x 13 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:13  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:13  1.714 sec   67600 obs/sec     1         1             338        0.244208         0.191472            0.749439       0.978266        0.963222           2.56061          0.0739645                        0.26536            0.266844              0.698295         0.959927          0.949872             2.69444            0.0824742\n",
       "    2025-05-26 14:48:13  1.737 sec   32190 obs/sec     2         2             676        0.199191         0.133702            0.833301       0.987864        0.977607           2.56061          0.0473373                        0.244223           0.207991              0.744444         0.976321          0.968129             2.69444            0.0721649\n",
       "    2025-05-26 14:48:13  1.760 sec   26684 obs/sec     3         3             1014       0.166762         0.102352            0.883161       0.991174        0.97996            2.56061          0.0266272                        0.220923           0.172713              0.790881         0.984062          0.977165             2.69444            0.0618557\n",
       "    2025-05-26 14:48:13  1.784 sec   25037 obs/sec     4         4             1352       0.154864         0.0900348           0.899239       0.992682        0.984218           2.56061          0.0236686                        0.206322           0.14608               0.817609         0.986794          0.980418             2.69444            0.0515464\n",
       "    2025-05-26 14:48:13  1.807 sec   24142 obs/sec     5         5             1690       0.145777         0.0807554           0.910716       0.993969        0.987328           2.56061          0.0207101                        0.19376            0.132695              0.839143         0.990437          0.985446             2.69444            0.0412371\n",
       "    2025-05-26 14:48:13  1.832 sec   23310 obs/sec     6         6             2028       0.146984         0.0811612           0.909232       0.994925        0.988938           2.56061          0.0207101                        0.214713           0.161354              0.802472         0.990437          0.984971             2.69444            0.0412371\n",
       "    2025-05-26 14:48:13  1.856 sec   22970 obs/sec     7         7             2366       0.130294         0.0669045           0.928675       0.99647         0.993011           2.56061          0.0177515                        0.173469           0.110242              0.87107          0.993169          0.988885             2.69444            0.0206186\n",
       "    2025-05-26 14:48:14  1.880 sec   22722 obs/sec     8         8             2704       0.125763         0.0626863           0.933549       0.996801        0.993638           2.56061          0.0177515                        0.170134           0.107582              0.875979         0.993169          0.988444             2.69444            0.0206186\n",
       "    2025-05-26 14:48:14  1.904 sec   22367 obs/sec     9         9             3042       0.135276         0.0704332           0.923116       0.996433        0.992097           2.56061          0.0147929                        0.20011            0.142048              0.828426         0.99408           0.99036              2.69444            0.0206186\n",
       "    2025-05-26 14:48:14  1.929 sec   21948 obs/sec     10        10            3380       0.120476         0.0587115           0.93902        0.997095        0.993904           2.56061          0.0118343                        0.159636           0.0953582             0.890813         0.99408           0.99036              2.69444            0.0206186\n",
       "    2025-05-26 14:48:14  1.966 sec   20655 obs/sec     11        11            3718       0.111716         0.0523127           0.947565       0.997315        0.994677           2.56061          0.0147929                        0.158044           0.0966196             0.89298          0.99408           0.99036              2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "el-salvador-aid.?                                   1.0                    1.0                  0.026999829121300226\n",
       "duty-free-exports.?                                 0.9803648591041565     0.9803648591041565   0.026469683672339796\n",
       "crime.?                                             0.9715016484260559     0.9715016484260559   0.026230378498564997\n",
       "synfuels-corporation-cutback.n                      0.9657400846481323     0.9657400846481323   0.026074817261089588\n",
       "adoption-of-the-budget-resolution.y                 0.9546074271202087     0.9546074271202087   0.025774237410169695\n",
       "physician-fee-freeze.n                              0.9333184361457825     0.9333184361457825   0.02519943829169528\n",
       "synfuels-corporation-cutback.?                      0.9329675436019897     0.9329675436019897   0.02518996425297294\n",
       "superfund-right-to-sue.y                            0.9286213517189026     0.9286213517189026   0.025072617814801204\n",
       "export-administration-act-south-africa.y            0.8797601461410522     0.8797601461410522   0.023753373613538523\n",
       "mx-missile.n                                        0.8578668832778931     0.8578668832778931   0.02316225925732552\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[20,20,20], nfolds=10, activation=\"rectifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b830af814e1031",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [100,100,100], cross folds = 10, activation function = \"rectifier\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a055322afee89ad1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:53:50.901721Z",
     "start_time": "2025-05-09T14:53:47.914749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1105\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-94.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-94 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-94 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-94 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-94 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-94 .h2o-table th,\n",
       "#h2o-table-94 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-94 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-94\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2533059</td>\n",
       "<td>0.4307226</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014378</td>\n",
       "<td>0.1101845</td>\n",
       "<td>0.4852396</td>\n",
       "<td>0.0241633</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0072749</td>\n",
       "<td>0.0107178</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0054778</td>\n",
       "<td>0.1015074</td>\n",
       "<td>0.9864373</td>\n",
       "<td>0.0121145</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>100</td>\n",
       "<td>Rectifier</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0722639</td>\n",
       "<td>0.2158356</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0004306</td>\n",
       "<td>0.1007069</td>\n",
       "<td>0.9982090</td>\n",
       "<td>0.0034842</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0679671</td>\n",
       "<td>0.2363142</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0074745</td>\n",
       "<td>0.5510728</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0001631</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.010393406739185063\n",
       "RMSE: 0.10194805902607985\n",
       "LogLoss: 0.03078602815911163\n",
       "Mean Per-Class Error: 0.008642247719917623\n",
       "AUC: 0.9993380406001766\n",
       "AUCPR: 0.9989627086845767\n",
       "Gini: 0.9986760812003532</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-95.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-95 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-95 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-95 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-95 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-95 .h2o-table th,\n",
       "#h2o-table-95 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-95 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-95\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35701591035352204</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>204.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0097</td>\n",
       "<td> (2.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>205.0</td>\n",
       "<td>133.0</td>\n",
       "<td>0.0089</td>\n",
       "<td> (3.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-96.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-96 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-96 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-96 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-96 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-96 .h2o-table th,\n",
       "#h2o-table-96 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-96 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-96\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3570159</td>\n",
       "<td>0.9886792</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1666489</td>\n",
       "<td>0.9924812</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7941172</td>\n",
       "<td>0.9872611</td>\n",
       "<td>85.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3570159</td>\n",
       "<td>0.9911243</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1666489</td>\n",
       "<td>1.0</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3570159</td>\n",
       "<td>0.9813990</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3570159</td>\n",
       "<td>0.9902913</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3570159</td>\n",
       "<td>0.9913578</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1666489</td>\n",
       "<td>132.0</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1666489</td>\n",
       "<td>1.0</td>\n",
       "<td>98.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-97.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-97 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-97 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-97 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-97 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-97 .h2o-table th,\n",
       "#h2o-table-97 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-97 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-97\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.42 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0266272</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0681818</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0681818</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0562130</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.1439394</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1439394</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9999996</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.1136364</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9999939</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999981</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999993</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9998992</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999663</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999910</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9994233</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997318</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999046</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.2157270</td>\n",
       "<td>2.2502296</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.8787879</td>\n",
       "<td>0.8196293</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9558373</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9924242</td>\n",
       "<td>125.0229568</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0001151</td>\n",
       "<td>0.0753119</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0245557</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7684789</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6035503</td>\n",
       "<td>0.0000041</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6568627</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000359</td>\n",
       "<td>0.6470588</td>\n",
       "<td>0.6366382</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>65.6862745</td>\n",
       "<td>0.6504854</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0000004</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000016</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5503146</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4810157</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4272179</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3842433</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.011114612614220745\n",
       "RMSE: 0.10542586311821565\n",
       "LogLoss: 0.04856863091725578\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-98.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-98 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-98 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-98 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-98 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-98 .h2o-table th,\n",
       "#h2o-table-98 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-98 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-98\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.81124600114364</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>62.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (1.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-99.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-99 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-99 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-99 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-99 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-99 .h2o-table th,\n",
       "#h2o-table-99 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-99 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-99\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.8112460</td>\n",
       "<td>0.9859155</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0203235</td>\n",
       "<td>0.9890110</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8112460</td>\n",
       "<td>0.9943182</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8112460</td>\n",
       "<td>0.9896907</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0203235</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8112460</td>\n",
       "<td>0.9780293</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.8112460</td>\n",
       "<td>0.9722222</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.8112460</td>\n",
       "<td>0.9861111</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0203235</td>\n",
       "<td>36.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0203235</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-100.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-100 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-100 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-100 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-100 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-100 .h2o-table th,\n",
       "#h2o-table-100 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-100 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-100\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.06 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1388889</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9999998</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9999986</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9999923</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999961</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9881718</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991579</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997378</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0122867</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.5967570</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.8964094</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0001013</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014648</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7137677</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0000122</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000313</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6030155</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000044</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5143374</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000003</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4542201</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4020109</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3605664</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.030805097823323052\n",
       "RMSE: 0.1755138109190358\n",
       "LogLoss: 0.12080609928754477\n",
       "Mean Per-Class Error: 0.03320829655781112\n",
       "AUC: 0.9942997940570756\n",
       "AUCPR: 0.9917218455947896\n",
       "Gini: 0.9885995881141512</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-101.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-101 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-101 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-101 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-101 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-101 .h2o-table th,\n",
       "#h2o-table-101 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-101 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-101\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2315598519990075</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>197.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0437</td>\n",
       "<td> (9.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>3.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.0227</td>\n",
       "<td> (3.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>200.0</td>\n",
       "<td>138.0</td>\n",
       "<td>0.0355</td>\n",
       "<td> (12.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-102.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-102 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-102 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-102 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-102 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-102 .h2o-table th,\n",
       "#h2o-table-102 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-102 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-102\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2315599</td>\n",
       "<td>0.9555556</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1804759</td>\n",
       "<td>0.9715994</td>\n",
       "<td>128.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9793827</td>\n",
       "<td>0.9647651</td>\n",
       "<td>103.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8248765</td>\n",
       "<td>0.9644970</td>\n",
       "<td>115.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0005895</td>\n",
       "<td>1.0</td>\n",
       "<td>160.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2315599</td>\n",
       "<td>0.9266573</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3313415</td>\n",
       "<td>0.9563107</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2315599</td>\n",
       "<td>0.9667917</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>319.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0005895</td>\n",
       "<td>132.0</td>\n",
       "<td>160.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>319.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0005895</td>\n",
       "<td>1.0</td>\n",
       "<td>160.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-103.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-103 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-103 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-103 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-103 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-103 .h2o-table th,\n",
       "#h2o-table-103 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-103 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-103\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.26 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9999997</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9999995</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9999990</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9999988</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999994</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9999985</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999987</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999993</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9999925</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999959</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999976</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9999655</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999817</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999923</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9998480</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999001</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999693</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9976329</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992324</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997237</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.3378503</td>\n",
       "<td>1.8622590</td>\n",
       "<td>2.3898990</td>\n",
       "<td>0.7272727</td>\n",
       "<td>0.8679488</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.9675120</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.9545455</td>\n",
       "<td>86.2258953</td>\n",
       "<td>138.9898990</td>\n",
       "<td>0.9108561</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0013811</td>\n",
       "<td>0.3765597</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.1470588</td>\n",
       "<td>0.0605520</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7850467</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-62.3440285</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0000537</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0002680</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6536059</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0000124</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000291</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5622160</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0000017</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000064</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4914192</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000006</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4364579</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3925539</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-104.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-104 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-104 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-104 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-104 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-104 .h2o-table th,\n",
       "#h2o-table-104 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-104 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-104\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th>\n",
       "<th>cv_6_valid</th>\n",
       "<th>cv_7_valid</th>\n",
       "<th>cv_8_valid</th>\n",
       "<th>cv_9_valid</th>\n",
       "<th>cv_10_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9813859</td>\n",
       "<td>0.0203117</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9591837</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9512195</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9677419</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9952725</td>\n",
       "<td>0.0059337</td>\n",
       "<td>0.9907407</td>\n",
       "<td>0.9846939</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9867725</td>\n",
       "<td>0.9947917</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9957265</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0186141</td>\n",
       "<td>0.0203117</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0408163</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0487805</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0322581</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.7</td>\n",
       "<td>0.8232726</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9735743</td>\n",
       "<td>0.0333565</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9793814</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9677419</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.942029</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9737216</td>\n",
       "<td>0.0297089</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.95</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.96</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9748748</td>\n",
       "<td>0.0403511</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9223301</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8823530</td>\n",
       "<td>0.9836066</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9848485</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6806576</td>\n",
       "<td>0.6947111</td>\n",
       "<td>4.375</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.6363637</td>\n",
       "<td>2.4166667</td>\n",
       "<td>2.9285715</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>3.2222223</td>\n",
       "<td>2.3846154</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9604181</td>\n",
       "<td>0.0431792</td>\n",
       "<td>0.9251849</td>\n",
       "<td>0.9189366</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.893325</td>\n",
       "<td>0.9302605</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9364743</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9803406</td>\n",
       "<td>0.0249350</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td>\n",
       "<td>0.96875</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0196594</td>\n",
       "<td>0.0249350</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.0476191</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0278743</td>\n",
       "<td>0.0266697</td>\n",
       "<td>0.0429294</td>\n",
       "<td>0.0696531</td>\n",
       "<td>0.0018239</td>\n",
       "<td>0.0065732</td>\n",
       "<td>0.0560841</td>\n",
       "<td>0.0569312</td>\n",
       "<td>0.0273058</td>\n",
       "<td>0.0000037</td>\n",
       "<td>0.0001770</td>\n",
       "<td>0.0172616</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9916815</td>\n",
       "<td>0.0113913</td>\n",
       "<td>0.9685857</td>\n",
       "<td>0.9834470</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9771529</td>\n",
       "<td>0.9933298</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9942994</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9740537</td>\n",
       "<td>0.0429894</td>\n",
       "<td>0.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8774437</td>\n",
       "<td>0.1173625</td>\n",
       "<td>0.7565347</td>\n",
       "<td>0.7155831</td>\n",
       "<td>0.9922531</td>\n",
       "<td>0.9729015</td>\n",
       "<td>0.7505891</td>\n",
       "<td>0.7675308</td>\n",
       "<td>0.8907768</td>\n",
       "<td>0.9999852</td>\n",
       "<td>0.9991731</td>\n",
       "<td>0.9291092</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9761905</td>\n",
       "<td>0.0514344</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9047619</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8571429</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1382172</td>\n",
       "<td>0.0987158</td>\n",
       "<td>0.2071941</td>\n",
       "<td>0.2639188</td>\n",
       "<td>0.0427068</td>\n",
       "<td>0.0810756</td>\n",
       "<td>0.2368208</td>\n",
       "<td>0.2386027</td>\n",
       "<td>0.1652446</td>\n",
       "<td>0.0019214</td>\n",
       "<td>0.0133033</td>\n",
       "<td>0.1313836</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9844907</td>\n",
       "<td>0.0257316</td>\n",
       "<td>0.962963</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9444444</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 13 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-105.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-105 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-105 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-105 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-105 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-105 .h2o-table th,\n",
       "#h2o-table-105 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-105 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-105\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:19</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:19</td>\n",
       "<td> 2.121 sec</td>\n",
       "<td>5929 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2341813</td>\n",
       "<td>0.2406872</td>\n",
       "<td>0.7695925</td>\n",
       "<td>0.9933436</td>\n",
       "<td>0.9898243</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.2176876</td>\n",
       "<td>0.1812659</td>\n",
       "<td>0.7969615</td>\n",
       "<td>0.9936248</td>\n",
       "<td>0.9903706</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.209 sec</td>\n",
       "<td>5160 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.2074964</td>\n",
       "<td>0.1892519</td>\n",
       "<td>0.8191105</td>\n",
       "<td>0.9966167</td>\n",
       "<td>0.9949132</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0295858</td>\n",
       "<td>0.1914497</td>\n",
       "<td>0.1444949</td>\n",
       "<td>0.8429563</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9956647</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.307 sec</td>\n",
       "<td>5121 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1456830</td>\n",
       "<td>0.0788892</td>\n",
       "<td>0.9108318</td>\n",
       "<td>0.9974993</td>\n",
       "<td>0.9959878</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1320338</td>\n",
       "<td>0.0512462</td>\n",
       "<td>0.9253067</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.386 sec</td>\n",
       "<td>5101 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1538868</td>\n",
       "<td>0.0799338</td>\n",
       "<td>0.9005064</td>\n",
       "<td>0.9980509</td>\n",
       "<td>0.9968213</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1727893</td>\n",
       "<td>0.1198918</td>\n",
       "<td>0.8720782</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.463 sec</td>\n",
       "<td>5136 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1438360</td>\n",
       "<td>0.0870605</td>\n",
       "<td>0.9130785</td>\n",
       "<td>0.9977935</td>\n",
       "<td>0.9965341</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1370946</td>\n",
       "<td>0.0689280</td>\n",
       "<td>0.9194711</td>\n",
       "<td>0.9977231</td>\n",
       "<td>0.9964044</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.540 sec</td>\n",
       "<td>5147 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1238290</td>\n",
       "<td>0.0488185</td>\n",
       "<td>0.9355776</td>\n",
       "<td>0.9988600</td>\n",
       "<td>0.9982412</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1389756</td>\n",
       "<td>0.0677223</td>\n",
       "<td>0.9172462</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9984564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.618 sec</td>\n",
       "<td>5154 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1429047</td>\n",
       "<td>0.0739717</td>\n",
       "<td>0.9142004</td>\n",
       "<td>0.9989703</td>\n",
       "<td>0.9984075</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1270877</td>\n",
       "<td>0.0523032</td>\n",
       "<td>0.9307981</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.695 sec</td>\n",
       "<td>5170 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1352205</td>\n",
       "<td>0.0645180</td>\n",
       "<td>0.9231794</td>\n",
       "<td>0.9991542</td>\n",
       "<td>0.9987009</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1838890</td>\n",
       "<td>0.1442605</td>\n",
       "<td>0.8551152</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9976512</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.772 sec</td>\n",
       "<td>5182 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1413051</td>\n",
       "<td>0.0767080</td>\n",
       "<td>0.9161104</td>\n",
       "<td>0.9990438</td>\n",
       "<td>0.9985396</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1823697</td>\n",
       "<td>0.1993980</td>\n",
       "<td>0.8574995</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9955992</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.850 sec</td>\n",
       "<td>5184 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1939040</td>\n",
       "<td>0.1496363</td>\n",
       "<td>0.8420333</td>\n",
       "<td>0.9991909</td>\n",
       "<td>0.9987274</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1652579</td>\n",
       "<td>0.1126568</td>\n",
       "<td>0.8829866</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:20</td>\n",
       "<td> 2.927 sec</td>\n",
       "<td>5185 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1019481</td>\n",
       "<td>0.0307860</td>\n",
       "<td>0.9563333</td>\n",
       "<td>0.9993380</td>\n",
       "<td>0.9989627</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0088757</td>\n",
       "<td>0.1054259</td>\n",
       "<td>0.0485686</td>\n",
       "<td>0.9523782</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-106.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-106 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-106 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-106 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-106 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-106 .h2o-table th,\n",
       "#h2o-table-106 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-106 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-106\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0243999</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9429157</td>\n",
       "<td>0.9429157</td>\n",
       "<td>0.0230070</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9360318</td>\n",
       "<td>0.9360318</td>\n",
       "<td>0.0228390</td></tr>\n",
       "<tr><td>physician-fee-freeze.?</td>\n",
       "<td>0.9289333</td>\n",
       "<td>0.9289333</td>\n",
       "<td>0.0226658</td></tr>\n",
       "<tr><td>superfund-right-to-sue.n</td>\n",
       "<td>0.9169230</td>\n",
       "<td>0.9169230</td>\n",
       "<td>0.0223728</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.?</td>\n",
       "<td>0.9168223</td>\n",
       "<td>0.9168223</td>\n",
       "<td>0.0223703</td></tr>\n",
       "<tr><td>religious-groups-in-schools.n</td>\n",
       "<td>0.9119287</td>\n",
       "<td>0.9119287</td>\n",
       "<td>0.0222509</td></tr>\n",
       "<tr><td>handicapped-infants.y</td>\n",
       "<td>0.9032876</td>\n",
       "<td>0.9032876</td>\n",
       "<td>0.0220401</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.9012909</td>\n",
       "<td>0.9012909</td>\n",
       "<td>0.0219914</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.y</td>\n",
       "<td>0.8972496</td>\n",
       "<td>0.8972496</td>\n",
       "<td>0.0218928</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1105\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type       dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight             weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  ---------  ---------  ----  ----  --------------------  --------------------  ----------  ----------------------  -------------------  ---------------------  ----------------------\n",
       "    1        64       Input      0.0\n",
       "    2        100      Rectifier  0.0        0.0   0.0   0.25330591148541315   0.43072259426116943   0.0         0.0014377941788416137   0.11018452048301697  0.4852396061028154     0.024163298308849335\n",
       "    3        100      Rectifier  0.0        0.0   0.0   0.007274869144178228  0.010717805474996567  0.0         -0.005477823818532374   0.10150739550590515  0.9864373116969942     0.01211453229188919\n",
       "    4        100      Rectifier  0.0        0.0   0.0   0.07226387432205957   0.21583563089370728   0.0         -0.0004305749288701918  0.10070693492889404  0.9982090311574716     0.0034842360764741898\n",
       "    5        2        Softmax               0.0   0.0   0.06796705719374586   0.23631423711776733   0.0         -0.007474514635978266   0.5510728359222412   2.778268066994105e-18  0.00016308255726471543\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.010393406739185063\n",
       "RMSE: 0.10194805902607985\n",
       "LogLoss: 0.03078602815911163\n",
       "Mean Per-Class Error: 0.008642247719917623\n",
       "AUC: 0.9993380406001766\n",
       "AUCPR: 0.9989627086845767\n",
       "Gini: 0.9986760812003532\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.35701591035352204\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    204         2             0.0097   (2.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       205         133           0.0089   (3.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.357016     0.988679  94\n",
       "max f2                       0.166649     0.992481  98\n",
       "max f0point5                 0.794117     0.987261  85\n",
       "max accuracy                 0.357016     0.991124  94\n",
       "max precision                1            1         0\n",
       "max recall                   0.166649     1         98\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.357016     0.981399  94\n",
       "max min_per_class_accuracy   0.357016     0.990291  94\n",
       "max mean_per_class_accuracy  0.357016     0.991358  94\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      7.90727e-12  206       269\n",
       "max tps                      0.166649     132       98\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      7.90727e-12  1         269\n",
       "max tpr                      0.166649     1         98\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.42 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   1                  2.56061    2.56061            1                1            1                           1                   0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0266272                   1                  2.56061    2.56061            1                1            1                           1                   0.0378788       0.0681818                  156.061   156.061            0.0681818\n",
       "3        0.0325444                   1                  2.56061    2.56061            1                1            1                           1                   0.0151515       0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   1                  2.56061    2.56061            1                1            1                           1                   0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.056213                    1                  2.56061    2.56061            1                1            1                           1                   0.0378788       0.143939                   156.061   156.061            0.143939\n",
       "6        0.100592                    1                  2.56061    2.56061            1                1            1                           1                   0.113636        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.999994           2.56061    2.56061            1                0.999998     1                           0.999999            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.201183                    0.999899           2.56061    2.56061            1                0.999966     1                           0.999991            0.128788        0.515152                   156.061   156.061            0.515152\n",
       "9        0.301775                    0.999423           2.56061    2.56061            1                0.999732     1                           0.999905            0.257576        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.215727           2.25023    2.48474            0.878788         0.819629     0.97037                     0.955837            0.219697        0.992424                   125.023   148.474            0.973007\n",
       "11       0.5                         0.00011511         0.0753119  2                  0.0294118        0.0245557    0.781065                    0.768479            0.00757576      1                          -92.4688  100                0.820388\n",
       "12       0.60355                     4.13351e-06        0          1.65686            0                3.59226e-05  0.647059                    0.636638            0               1                          -100      65.6863            0.650485\n",
       "13       0.698225                    4.00196e-07        0          1.4322             0                1.58718e-06  0.559322                    0.550315            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    1.09027e-07        0          1.25185            0                2.62256e-07  0.488889                    0.481016            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    4.63394e-09        0          1.11184            0                4.02303e-08  0.434211                    0.427218            0               1                          -100      11.1842            0.165049\n",
       "16       1                           7.90727e-12        0          1                  0                1.09742e-09  0.390533                    0.384243            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.011114612614220745\n",
       "RMSE: 0.10542586311821565\n",
       "LogLoss: 0.04856863091725578\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.81124600114364\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    61          0             0        (0.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       62          35            0.0103   (1.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.811246     0.985915  31\n",
       "max f2                       0.0203235    0.989011  34\n",
       "max f0point5                 0.811246     0.994318  31\n",
       "max accuracy                 0.811246     0.989691  31\n",
       "max precision                1            1         0\n",
       "max recall                   0.0203235    1         34\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.811246     0.978029  31\n",
       "max min_per_class_accuracy   0.811246     0.972222  31\n",
       "max mean_per_class_accuracy  0.811246     0.986111  31\n",
       "max tns                      1            61        0\n",
       "max fns                      1            35        0\n",
       "max fps                      5.02886e-11  61        91\n",
       "max tps                      0.0203235    36        34\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.972222  0\n",
       "max fpr                      5.02886e-11  1         91\n",
       "max tpr                      0.0203235    1         34\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.06 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0515464                   1                  2.69444  2.69444            1                1            1                           1                   0.0833333       0.138889                   169.444  169.444            0.138889\n",
       "4        0.0515464                   1                  0        2.69444            0                0            1                           1                   0               0.138889                   -100     169.444            0.138889\n",
       "5        0.103093                    1                  2.69444  2.69444            1                1            1                           1                   0.138889        0.277778                   169.444  169.444            0.277778\n",
       "6        0.154639                    0.999999           2.69444  2.69444            1                0.999999     1                           1                   0.138889        0.416667                   169.444  169.444            0.416667\n",
       "7        0.206186                    0.999992           2.69444  2.69444            1                0.999996     1                           0.999999            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "8        0.298969                    0.988172           2.69444  2.69444            1                0.999158     1                           0.999738            0.25            0.805556                   169.444  169.444            0.805556\n",
       "9        0.402062                    0.0122867          1.88611  2.48718            0.7              0.596757     0.923077                    0.896409            0.194444        1                          88.6111  148.718            0.95082\n",
       "10       0.505155                    0.000101335        0        1.97959            0                0.00146476   0.734694                    0.713768            0               1                          -100     97.9592            0.786885\n",
       "11       0.597938                    1.22419e-05        0        1.67241            0                3.13217e-05  0.62069                     0.603015            0               1                          -100     67.2414            0.639344\n",
       "12       0.701031                    4.86643e-07        0        1.42647            0                4.38972e-06  0.529412                    0.514337            0               1                          -100     42.6471            0.47541\n",
       "13       0.793814                    1.3452e-07         0        1.25974            0                2.9198e-07   0.467532                    0.45422             0               1                          -100     25.974             0.327869\n",
       "14       0.896907                    1.59958e-08        0        1.11494            0                6.38794e-08  0.413793                    0.402011            0               1                          -100     11.4943            0.163934\n",
       "15       1                           5.02886e-11        0        1                  0                1.43828e-09  0.371134                    0.360566            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.030805097823323052\n",
       "RMSE: 0.1755138109190358\n",
       "LogLoss: 0.12080609928754477\n",
       "Mean Per-Class Error: 0.03320829655781112\n",
       "AUC: 0.9942997940570756\n",
       "AUCPR: 0.9917218455947896\n",
       "Gini: 0.9885995881141512\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2315598519990075\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    197         9             0.0437   (9.0/206.0)\n",
       "republican  3           129           0.0227   (3.0/132.0)\n",
       "Total       200         138           0.0355   (12.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.23156      0.955556  125\n",
       "max f2                       0.180476     0.971599  128\n",
       "max f0point5                 0.979383     0.964765  103\n",
       "max accuracy                 0.824876     0.964497  115\n",
       "max precision                1            1         0\n",
       "max recall                   0.000589481  1         160\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.23156      0.926657  125\n",
       "max min_per_class_accuracy   0.331342     0.956311  123\n",
       "max mean_per_class_accuracy  0.23156      0.966792  125\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      1.66346e-11  206       319\n",
       "max tps                      0.000589481  132       160\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      1.66346e-11  1         319\n",
       "max tpr                      0.000589481  1         160\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.26 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   1                  2.56061    2.56061            1                1            1                           1                   0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.999999           2.56061    2.56061            1                1            1                           1                   0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.999999           2.56061    2.56061            1                0.999999     1                           1                   0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0443787                   0.999999           2.56061    2.56061            1                0.999999     1                           0.999999            0.030303        0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.999999           2.56061    2.56061            1                0.999999     1                           0.999999            0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.999993           2.56061    2.56061            1                0.999996     1                           0.999998            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.999966           2.56061    2.56061            1                0.999982     1                           0.999992            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.201183                    0.999848           2.56061    2.56061            1                0.9999       1                           0.999969            0.128788        0.515152                   156.061   156.061            0.515152\n",
       "9        0.301775                    0.997633           2.56061    2.56061            1                0.999232     1                           0.999724            0.257576        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.33785            1.86226    2.3899             0.727273         0.867949     0.933333                    0.967512            0.181818        0.954545                   86.2259   138.99             0.910856\n",
       "11       0.5                         0.00138112         0.37656    1.98485            0.147059         0.060552     0.775148                    0.785047            0.0378788       0.992424                   -62.344   98.4848            0.807958\n",
       "12       0.600592                    5.3734e-05         0.0753119  1.66502            0.0294118        0.000267991  0.650246                    0.653606            0.00757576      1                          -92.4688  66.5025            0.65534\n",
       "13       0.698225                    1.238e-05          0          1.4322             0                2.90885e-05  0.559322                    0.562216            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    1.672e-06          0          1.25185            0                6.41529e-06  0.488889                    0.491419            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    8.7e-08            0          1.11184            0                5.57353e-07  0.434211                    0.436458            0               1                          -100      11.1842            0.165049\n",
       "16       1                           0                  0          1                  0                2e-08        0.390533                    0.392554            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid     cv_9_valid     cv_10_valid\n",
       "-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------  -------------  -------------\n",
       "accuracy                 0.98138595   0.020311726   0.9714286     0.9591837     1.0           1.0           0.9512195     0.96428573    1.0           1.0            1.0            0.9677419\n",
       "aic                      nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan            nan            nan\n",
       "auc                      0.9952725    0.0059336885  0.9907407     0.9846939     1.0           1.0           0.9867725     0.9947917     1.0           1.0            1.0            0.99572647\n",
       "err                      0.01861406   0.020311726   0.028571429   0.040816326   0.0           0.0           0.048780486   0.035714287   0.0           0.0            0.0            0.032258064\n",
       "err_count                0.7          0.8232726     1.0           2.0           0.0           0.0           2.0           1.0           0.0           0.0            0.0            1.0\n",
       "f0point5                 0.97357434   0.033356488   0.90909094    0.97938144    1.0           1.0           0.9677419     0.9375        1.0           1.0            1.0            0.942029\n",
       "f1                       0.9737216    0.029708931   0.9411765     0.95          1.0           1.0           0.9230769     0.96          1.0           1.0            1.0            0.962963\n",
       "f2                       0.9748748    0.040351067   0.9756098     0.9223301     1.0           1.0           0.88235295    0.9836066     1.0           1.0            1.0            0.9848485\n",
       "lift_top_group           2.6806576    0.6947111     4.375         2.3333333     2.6363637     2.4166667     2.9285715     2.3333333     2.0           2.1764705      3.2222223      2.3846154\n",
       "loglikelihood            nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan            nan            nan\n",
       "---                      ---          ---           ---           ---           ---           ---           ---           ---           ---           ---            ---            ---\n",
       "mcc                      0.9604181    0.04317921    0.9251849     0.9189366     1.0           1.0           0.893325      0.93026054    1.0           1.0            1.0            0.9364743\n",
       "mean_per_class_accuracy  0.9803406    0.024935028   0.9814815     0.95238096    1.0           1.0           0.9285714     0.96875       1.0           1.0            1.0            0.9722222\n",
       "mean_per_class_error     0.01965939   0.024935028   0.018518519   0.04761905    0.0           0.0           0.071428575   0.03125       0.0           0.0            0.0            0.027777778\n",
       "mse                      0.027874304  0.026669677   0.04292939    0.06965311    0.0018238745  0.0065732496  0.056084074   0.05693124    0.027305793   3.6917643e-06  0.00017697741  0.01726165\n",
       "pr_auc                   0.99168146   0.01139133    0.96858567    0.98344696    1.0           1.0           0.9771529     0.99332976    1.0           1.0            1.0            0.9942994\n",
       "precision                0.97405374   0.042989388   0.8888889     1.0           1.0           1.0           1.0           0.9230769     1.0           1.0            1.0            0.9285714\n",
       "r2                       0.8774437    0.11736255    0.7565347     0.71558315    0.9922531     0.97290146    0.7505891     0.7675308     0.8907768     0.99998516     0.9991731      0.9291092\n",
       "recall                   0.97619045   0.05143445    1.0           0.9047619     1.0           1.0           0.85714287    1.0           1.0           1.0            1.0            1.0\n",
       "rmse                     0.13821717   0.09871575    0.20719409    0.26391876    0.042706843   0.08107558    0.23682076    0.23860268    0.16524465    0.0019213965   0.013303285    0.1313836\n",
       "specificity              0.98449075   0.025731608   0.962963      1.0           1.0           1.0           1.0           0.9375        1.0           1.0            1.0            0.9444444\n",
       "[22 rows x 13 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:19  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:19  2.121 sec   5929 obs/sec      1         1             338        0.234181         0.240687            0.769593       0.993344        0.989824           2.56061          0.035503                         0.217688           0.181266              0.796962         0.993625          0.990371             2.69444            0.0309278\n",
       "    2025-05-26 14:48:20  2.209 sec   5160 obs/sec      2         2             676        0.207496         0.189252            0.81911        0.996617        0.994913           2.56061          0.0295858                        0.19145            0.144495              0.842956         0.997268          0.995665             2.69444            0.0206186\n",
       "    2025-05-26 14:48:20  2.307 sec   5121 obs/sec      3         3             1014       0.145683         0.0788892           0.910832       0.997499        0.995988           2.56061          0.0207101                        0.132034           0.0512462             0.925307         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:20  2.386 sec   5101 obs/sec      4         4             1352       0.153887         0.0799338           0.900506       0.998051        0.996821           2.56061          0.0207101                        0.172789           0.119892              0.872078         0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:48:20  2.463 sec   5136 obs/sec      5         5             1690       0.143836         0.0870605           0.913078       0.997793        0.996534           2.56061          0.0207101                        0.137095           0.068928              0.919471         0.997723          0.996404             2.69444            0.0206186\n",
       "    2025-05-26 14:48:20  2.540 sec   5147 obs/sec      6         6             2028       0.123829         0.0488185           0.935578       0.99886         0.998241           2.56061          0.0177515                        0.138976           0.0677223             0.917246         0.999089          0.998456             2.69444            0.0103093\n",
       "    2025-05-26 14:48:20  2.618 sec   5154 obs/sec      7         7             2366       0.142905         0.0739717           0.9142         0.99897         0.998408           2.56061          0.0147929                        0.127088           0.0523032             0.930798         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:20  2.695 sec   5170 obs/sec      8         8             2704       0.135221         0.064518            0.923179       0.999154        0.998701           2.56061          0.0118343                        0.183889           0.14426               0.855115         0.998634          0.997651             2.69444            0.0103093\n",
       "    2025-05-26 14:48:20  2.772 sec   5182 obs/sec      9         9             3042       0.141305         0.076708            0.91611        0.999044        0.99854            2.56061          0.0118343                        0.18237            0.199398              0.857499         0.997268          0.995599             2.69444            0.0206186\n",
       "    2025-05-26 14:48:20  2.850 sec   5184 obs/sec      10        10            3380       0.193904         0.149636            0.842033       0.999191        0.998727           2.56061          0.0118343                        0.165258           0.112657              0.882987         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:20  2.927 sec   5185 obs/sec      11        11            3718       0.101948         0.030786            0.956333       0.999338        0.998963           2.56061          0.00887574                       0.105426           0.0485686             0.952378         0.999089          0.998518             2.69444            0.0103093\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.024399857866876762\n",
       "synfuels-corporation-cutback.n                      0.9429157376289368     0.9429157376289368   0.023007009978587317\n",
       "physician-fee-freeze.n                              0.9360318183898926     0.9360318183898926   0.022839043327587582\n",
       "physician-fee-freeze.?                              0.9289332628250122     0.9289332628250122   0.022665839580744373\n",
       "superfund-right-to-sue.n                            0.9169229865074158     0.9169229865074158   0.022372790545653103\n",
       "adoption-of-the-budget-resolution.?                 0.9168223142623901     0.9168223142623901   0.022370334157183338\n",
       "religious-groups-in-schools.n                       0.9119287133216858     0.9119287133216858   0.02225093098977294\n",
       "handicapped-infants.y                               0.9032875895500183     0.9032875895500183   0.022040088797934163\n",
       "aid-to-nicaraguan-contras.y                         0.9012908935546875     0.9012908935546875   0.021991369699444728\n",
       "export-administration-act-south-africa.y            0.8972495794296265     0.8972495794296265   0.021892762209197836\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[100,100,100], nfolds=10, activation=\"rectifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03aae76db56e66",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [5,5,5], cross folds = 0, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be327175baf9ee33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T14:54:29.486606Z",
     "start_time": "2025-05-09T14:54:29.095245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1385\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-107.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-107 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-107 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-107 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-107 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-107 .h2o-table th,\n",
       "#h2o-table-107 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-107 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-107\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2524469</td>\n",
       "<td>0.4311426</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0148989</td>\n",
       "<td>0.1780187</td>\n",
       "<td>-0.0000309</td>\n",
       "<td>0.1196337</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0020506</td>\n",
       "<td>0.0007596</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0609113</td>\n",
       "<td>0.4876398</td>\n",
       "<td>0.0641635</td>\n",
       "<td>0.0305209</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0129818</td>\n",
       "<td>0.0155707</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1696949</td>\n",
       "<td>0.3945540</td>\n",
       "<td>0.0566816</td>\n",
       "<td>0.0278130</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0033279</td>\n",
       "<td>0.0006054</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6811199</td>\n",
       "<td>1.0460100</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0911278</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01548889297470334\n",
       "RMSE: 0.12445438109887229\n",
       "LogLoss: 0.0691635521869766\n",
       "Mean Per-Class Error: 0.014857310973815829\n",
       "AUC: 0.995660488378935\n",
       "AUCPR: 0.9940360901404862\n",
       "Gini: 0.9913209767578699</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-108.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-108 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-108 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-108 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-108 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-108 .h2o-table th,\n",
       "#h2o-table-108 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-108 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-108\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5700888974598675</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>203.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0146</td>\n",
       "<td> (3.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>205.0</td>\n",
       "<td>133.0</td>\n",
       "<td>0.0148</td>\n",
       "<td> (5.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-109.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-109 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-109 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-109 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-109 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-109 .h2o-table th,\n",
       "#h2o-table-109 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-109 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-109\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9811321</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4686205</td>\n",
       "<td>0.9864458</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6803106</td>\n",
       "<td>0.9815951</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9852071</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9946734</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0058288</td>\n",
       "<td>1.0</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9946734</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9689856</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9848485</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9851427</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9946734</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9946734</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0025129</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0058288</td>\n",
       "<td>132.0</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9946734</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9946734</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0025129</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0058288</td>\n",
       "<td>1.0</td>\n",
       "<td>158.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-110.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-110 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-110 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-110 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-110 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-110 .h2o-table th,\n",
       "#h2o-table-110 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-110 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-110\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.13 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9937615</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9940582</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9940582</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9934070</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936405</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9938792</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9928607</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930847</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935903</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9928374</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928374</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933895</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9925453</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927170</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933104</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9913286</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919030</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9926067</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9882660</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9901207</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9917780</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9848219</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9865003</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9904586</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3047337</td>\n",
       "<td>0.9691212</td>\n",
       "<td>2.4874459</td>\n",
       "<td>2.5357458</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9801877</td>\n",
       "<td>0.9902913</td>\n",
       "<td>0.9869685</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>148.7445887</td>\n",
       "<td>153.5745808</td>\n",
       "<td>0.7678729</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4749243</td>\n",
       "<td>2.2405303</td>\n",
       "<td>2.4657688</td>\n",
       "<td>0.875</td>\n",
       "<td>0.8410500</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9523804</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.9848485</td>\n",
       "<td>124.0530303</td>\n",
       "<td>146.5768799</td>\n",
       "<td>0.9605766</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0096958</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0870462</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7782895</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0053393</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0069045</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6490920</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0044140</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0048011</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5590005</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8047337</td>\n",
       "<td>0.0035295</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2426471</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0038870</td>\n",
       "<td>0.4852941</td>\n",
       "<td>0.4855296</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.2647059</td>\n",
       "<td>0.3203883</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0032011</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0033878</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4347778</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0025129</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029399</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3913385</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.013890928797000693\n",
       "RMSE: 0.11785978447715188\n",
       "LogLoss: 0.052391018270660734\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-111.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-111 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-111 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-111 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-111 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-111 .h2o-table th,\n",
       "#h2o-table-111 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-111 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-111\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6952516404269884</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>62.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (1.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-112.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-112 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-112 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-112 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-112 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-112 .h2o-table th,\n",
       "#h2o-table-112 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-112 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-112\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9859155</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1287646</td>\n",
       "<td>0.9890110</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9943182</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9896907</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1287646</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9780293</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9722222</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9861111</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9943072</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9943072</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0026870</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1287646</td>\n",
       "<td>36.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9943072</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0026870</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1287646</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-113.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-113 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-113 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-113 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-113 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-113 .h2o-table th,\n",
       "#h2o-table-113 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-113 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-113\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.06 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9930321</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943072</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9928063</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929790</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936431</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9924882</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933591</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9922148</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924469</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931311</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9921208</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9921706</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929390</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9917159</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919522</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924456</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9907624</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9914307</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9921073</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9881609</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9892030</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9913812</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9269438</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9811918</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9882190</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0819447</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.5897882</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.8860573</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0083615</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0206481</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7094432</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0056579</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0065111</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6003675</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0045818</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051605</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5128371</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0036732</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0041021</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4533745</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0032940</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0034820</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4016627</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0026870</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0028974</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3605529</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-114.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-114 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-114 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-114 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-114 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-114 .h2o-table th,\n",
       "#h2o-table-114 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-114 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-114\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:33</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.016 sec</td>\n",
       "<td>84500 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2109433</td>\n",
       "<td>0.1634058</td>\n",
       "<td>0.8130508</td>\n",
       "<td>0.9817961</td>\n",
       "<td>0.9628444</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0532544</td>\n",
       "<td>0.2219103</td>\n",
       "<td>0.1685375</td>\n",
       "<td>0.7890079</td>\n",
       "<td>0.9886157</td>\n",
       "<td>0.9810854</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.038 sec</td>\n",
       "<td>35578 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1843473</td>\n",
       "<td>0.1296516</td>\n",
       "<td>0.8572205</td>\n",
       "<td>0.9881951</td>\n",
       "<td>0.9785739</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.1915001</td>\n",
       "<td>0.1243378</td>\n",
       "<td>0.8428735</td>\n",
       "<td>0.9927140</td>\n",
       "<td>0.9875940</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.060 sec</td>\n",
       "<td>29823 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1658221</td>\n",
       "<td>0.1089020</td>\n",
       "<td>0.8844747</td>\n",
       "<td>0.9906222</td>\n",
       "<td>0.9831777</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.1757758</td>\n",
       "<td>0.1026639</td>\n",
       "<td>0.8676179</td>\n",
       "<td>0.9949909</td>\n",
       "<td>0.9914792</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.080 sec</td>\n",
       "<td>28166 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1570520</td>\n",
       "<td>0.0992638</td>\n",
       "<td>0.8963715</td>\n",
       "<td>0.9918358</td>\n",
       "<td>0.9857957</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1555667</td>\n",
       "<td>0.0836351</td>\n",
       "<td>0.8963082</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9930641</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.101 sec</td>\n",
       "<td>26825 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1464146</td>\n",
       "<td>0.0894230</td>\n",
       "<td>0.9099340</td>\n",
       "<td>0.9931230</td>\n",
       "<td>0.9884188</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1453706</td>\n",
       "<td>0.0763246</td>\n",
       "<td>0.9094551</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.122 sec</td>\n",
       "<td>26000 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1393621</td>\n",
       "<td>0.0830717</td>\n",
       "<td>0.9184016</td>\n",
       "<td>0.9938217</td>\n",
       "<td>0.9899479</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1360821</td>\n",
       "<td>0.0686306</td>\n",
       "<td>0.9206562</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.143 sec</td>\n",
       "<td>25440 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1376766</td>\n",
       "<td>0.0800181</td>\n",
       "<td>0.9203634</td>\n",
       "<td>0.9942630</td>\n",
       "<td>0.9909781</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1258424</td>\n",
       "<td>0.0590951</td>\n",
       "<td>0.9321477</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.165 sec</td>\n",
       "<td>25037 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1322235</td>\n",
       "<td>0.0754169</td>\n",
       "<td>0.9265470</td>\n",
       "<td>0.9948147</td>\n",
       "<td>0.9922661</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1217894</td>\n",
       "<td>0.0557746</td>\n",
       "<td>0.9364478</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.206 sec</td>\n",
       "<td>22701 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1265907</td>\n",
       "<td>0.0716402</td>\n",
       "<td>0.9326720</td>\n",
       "<td>0.9950353</td>\n",
       "<td>0.9927280</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1226970</td>\n",
       "<td>0.0578272</td>\n",
       "<td>0.9354971</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:34</td>\n",
       "<td> 0.228 sec</td>\n",
       "<td>22837 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1244544</td>\n",
       "<td>0.0691636</td>\n",
       "<td>0.9349252</td>\n",
       "<td>0.9956605</td>\n",
       "<td>0.9940361</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1178598</td>\n",
       "<td>0.0523910</td>\n",
       "<td>0.9404828</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-115.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-115 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-115 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-115 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-115 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-115 .h2o-table th,\n",
       "#h2o-table-115 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-115 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-115\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0481745</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.7166771</td>\n",
       "<td>0.7166771</td>\n",
       "<td>0.0345255</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.6974205</td>\n",
       "<td>0.6974205</td>\n",
       "<td>0.0335979</td></tr>\n",
       "<tr><td>el-salvador-aid.?</td>\n",
       "<td>0.6335801</td>\n",
       "<td>0.6335801</td>\n",
       "<td>0.0305224</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.6160795</td>\n",
       "<td>0.6160795</td>\n",
       "<td>0.0296793</td></tr>\n",
       "<tr><td>water-project-cost-sharing.y</td>\n",
       "<td>0.5971928</td>\n",
       "<td>0.5971928</td>\n",
       "<td>0.0287694</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.n</td>\n",
       "<td>0.5896254</td>\n",
       "<td>0.5896254</td>\n",
       "<td>0.0284049</td></tr>\n",
       "<tr><td>crime.n</td>\n",
       "<td>0.5706848</td>\n",
       "<td>0.5706848</td>\n",
       "<td>0.0274924</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.5699778</td>\n",
       "<td>0.5699778</td>\n",
       "<td>0.0274584</td></tr>\n",
       "<tr><td>education-spending.?</td>\n",
       "<td>0.5143144</td>\n",
       "<td>0.5143144</td>\n",
       "<td>0.0247768</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1385\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  --------------------\n",
       "    1        64       Input    0.0\n",
       "    2        5        Tanh     0.0        0.0   0.0   0.25244694898956366    0.43114256858825684    0.0         -0.014898876845973064  0.1780187487602234   -3.0877236202137e-05    0.1196337342262268\n",
       "    3        5        Tanh     0.0        0.0   0.0   0.0020506446668878196  0.0007595927454531193  0.0         -0.06091129034757614   0.48763978481292725  0.064163481603456       0.030520908534526825\n",
       "    4        5        Tanh     0.0        0.0   0.0   0.012981761889532208   0.01557065173983574    0.0         0.16969490901799872    0.3945540189743042   0.056681598694319955    0.027812950313091278\n",
       "    5        2        Softmax             0.0   0.0   0.003327851835638285   0.0006053755059838295  0.0         1.6811198571696877     1.0460100173950195   1.1102230246251565e-16  0.09112781286239624\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01548889297470334\n",
       "RMSE: 0.12445438109887229\n",
       "LogLoss: 0.0691635521869766\n",
       "Mean Per-Class Error: 0.014857310973815829\n",
       "AUC: 0.995660488378935\n",
       "AUCPR: 0.9940360901404862\n",
       "Gini: 0.9913209767578699\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5700888974598675\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    203         3             0.0146   (3.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       205         133           0.0148   (5.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.570089     0.981132  94\n",
       "max f2                       0.46862      0.986446  97\n",
       "max f0point5                 0.680311     0.981595  91\n",
       "max accuracy                 0.570089     0.985207  94\n",
       "max precision                0.994673     1         0\n",
       "max recall                   0.00582885   1         158\n",
       "max specificity              0.994673     1         0\n",
       "max absolute_mcc             0.570089     0.968986  94\n",
       "max min_per_class_accuracy   0.570089     0.984848  94\n",
       "max mean_per_class_accuracy  0.570089     0.985143  94\n",
       "max tns                      0.994673     206       0\n",
       "max fns                      0.994673     131       0\n",
       "max fps                      0.00251287   206       269\n",
       "max tps                      0.00582885   132       158\n",
       "max tnr                      0.994673     1         0\n",
       "max fnr                      0.994673     0.992424  0\n",
       "max fpr                      0.00251287   1         269\n",
       "max tpr                      0.00582885   1         158\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.13 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.993762           2.56061    2.56061            1                0.994058    1                           0.994058            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.993407           2.56061    2.56061            1                0.99364     1                           0.993879            0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.992861           2.56061    2.56061            1                0.993085    1                           0.99359             0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0443787                   0.992837           2.56061    2.56061            1                0.992837    1                           0.99339             0.030303        0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.992545           2.56061    2.56061            1                0.992717    1                           0.99331             0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.991329           2.56061    2.56061            1                0.991903    1                           0.992607            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.988266           2.56061    2.56061            1                0.990121    1                           0.991778            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.201183                    0.984822           2.56061    2.56061            1                0.9865      1                           0.990459            0.128788        0.515152                   156.061   156.061            0.515152\n",
       "9        0.304734                    0.969121           2.48745    2.53575            0.971429         0.980188    0.990291                    0.986968            0.257576        0.772727                   148.745   153.575            0.767873\n",
       "10       0.399408                    0.474924           2.24053    2.46577            0.875            0.84105     0.962963                    0.95238             0.212121        0.984848                   124.053   146.577            0.960577\n",
       "11       0.5                         0.0096958          0.0753119  1.98485            0.0294118        0.0870462   0.775148                    0.778289            0.00757576      0.992424                   -92.4688  98.4848            0.807958\n",
       "12       0.600592                    0.00533935         0.0753119  1.66502            0.0294118        0.00690448  0.650246                    0.649092            0.00757576      1                          -92.4688  66.5025            0.65534\n",
       "13       0.698225                    0.00441405         0          1.4322             0                0.00480107  0.559322                    0.559               0               1                          -100      43.2203            0.495146\n",
       "14       0.804734                    0.00352954         0          1.24265            0                0.00388701  0.485294                    0.48553             0               1                          -100      24.2647            0.320388\n",
       "15       0.899408                    0.00320113         0          1.11184            0                0.00338781  0.434211                    0.434778            0               1                          -100      11.1842            0.165049\n",
       "16       1                           0.00251287         0          1                  0                0.00293989  0.390533                    0.391338            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.013890928797000693\n",
       "RMSE: 0.11785978447715188\n",
       "LogLoss: 0.052391018270660734\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6952516404269884\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    61          0             0        (0.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       62          35            0.0103   (1.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.695252     0.985915  31\n",
       "max f2                       0.128765     0.989011  34\n",
       "max f0point5                 0.695252     0.994318  31\n",
       "max accuracy                 0.695252     0.989691  31\n",
       "max precision                0.994307     1         0\n",
       "max recall                   0.128765     1         34\n",
       "max specificity              0.994307     1         0\n",
       "max absolute_mcc             0.695252     0.978029  31\n",
       "max min_per_class_accuracy   0.695252     0.972222  31\n",
       "max mean_per_class_accuracy  0.695252     0.986111  31\n",
       "max tns                      0.994307     61        0\n",
       "max fns                      0.994307     35        0\n",
       "max fps                      0.00268697   61        91\n",
       "max tps                      0.128765     36        34\n",
       "max tnr                      0.994307     1         0\n",
       "max fnr                      0.994307     0.972222  0\n",
       "max fpr                      0.00268697   1         91\n",
       "max tpr                      0.128765     1         34\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.06 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   0.993032           2.69444  2.69444            1                0.994307    1                           0.994307            0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   0.992806           2.69444  2.69444            1                0.992979    1                           0.993643            0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0309278                   0.992488           2.69444  2.69444            1                0.992791    1                           0.993359            0.0277778       0.0833333                  169.444  169.444            0.0833333\n",
       "4        0.0412371                   0.992215           2.69444  2.69444            1                0.992447    1                           0.993131            0.0277778       0.111111                   169.444  169.444            0.111111\n",
       "5        0.0515464                   0.992121           2.69444  2.69444            1                0.992171    1                           0.992939            0.0277778       0.138889                   169.444  169.444            0.138889\n",
       "6        0.103093                    0.991716           2.69444  2.69444            1                0.991952    1                           0.992446            0.138889        0.277778                   169.444  169.444            0.277778\n",
       "7        0.154639                    0.990762           2.69444  2.69444            1                0.991431    1                           0.992107            0.138889        0.416667                   169.444  169.444            0.416667\n",
       "8        0.206186                    0.988161           2.69444  2.69444            1                0.989203    1                           0.991381            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "9        0.298969                    0.926944           2.69444  2.69444            1                0.981192    1                           0.988219            0.25            0.805556                   169.444  169.444            0.805556\n",
       "10       0.402062                    0.0819447          1.88611  2.48718            0.7              0.589788    0.923077                    0.886057            0.194444        1                          88.6111  148.718            0.95082\n",
       "11       0.505155                    0.00836154         0        1.97959            0                0.0206481   0.734694                    0.709443            0               1                          -100     97.9592            0.786885\n",
       "12       0.597938                    0.0056579          0        1.67241            0                0.00651115  0.62069                     0.600367            0               1                          -100     67.2414            0.639344\n",
       "13       0.701031                    0.00458185         0        1.42647            0                0.00516046  0.529412                    0.512837            0               1                          -100     42.6471            0.47541\n",
       "14       0.793814                    0.00367319         0        1.25974            0                0.0041021   0.467532                    0.453375            0               1                          -100     25.974             0.327869\n",
       "15       0.896907                    0.00329398         0        1.11494            0                0.00348204  0.413793                    0.401663            0               1                          -100     11.4943            0.163934\n",
       "16       1                           0.00268697         0        1                  0                0.00289736  0.371134                    0.360553            0               1                          -100     0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:33  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:34  0.016 sec   84500 obs/sec     1         1             338        0.210943         0.163406            0.813051       0.981796        0.962844           2.56061          0.0532544                        0.22191            0.168537              0.789008         0.988616          0.981085             2.69444            0.0412371\n",
       "    2025-05-26 14:48:34  0.038 sec   35578 obs/sec     2         2             676        0.184347         0.129652            0.857221       0.988195        0.978574           2.56061          0.0414201                        0.1915             0.124338              0.842874         0.992714          0.987594             2.69444            0.0309278\n",
       "    2025-05-26 14:48:34  0.060 sec   29823 obs/sec     3         3             1014       0.165822         0.108902            0.884475       0.990622        0.983178           2.56061          0.0325444                        0.175776           0.102664              0.867618         0.994991          0.991479             2.69444            0.0309278\n",
       "    2025-05-26 14:48:34  0.080 sec   28166 obs/sec     4         4             1352       0.157052         0.0992638           0.896371       0.991836        0.985796           2.56061          0.0236686                        0.155567           0.0836351             0.896308         0.995902          0.993064             2.69444            0.0309278\n",
       "    2025-05-26 14:48:34  0.101 sec   26825 obs/sec     5         5             1690       0.146415         0.089423            0.909934       0.993123        0.988419           2.56061          0.0207101                        0.145371           0.0763246             0.909455         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:34  0.122 sec   26000 obs/sec     6         6             2028       0.139362         0.0830717           0.918402       0.993822        0.989948           2.56061          0.0207101                        0.136082           0.0686306             0.920656         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:34  0.143 sec   25440 obs/sec     7         7             2366       0.137677         0.0800181           0.920363       0.994263        0.990978           2.56061          0.0177515                        0.125842           0.0590951             0.932148         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:34  0.165 sec   25037 obs/sec     8         8             2704       0.132223         0.0754169           0.926547       0.994815        0.992266           2.56061          0.0177515                        0.121789           0.0557746             0.936448         0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:48:34  0.206 sec   22701 obs/sec     9         9             3042       0.126591         0.0716402           0.932672       0.995035        0.992728           2.56061          0.0177515                        0.122697           0.0578272             0.935497         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:34  0.228 sec   22837 obs/sec     10        10            3380       0.124454         0.0691636           0.934925       0.99566         0.994036           2.56061          0.0147929                        0.11786            0.052391              0.940483         0.999089          0.998518             2.69444            0.0103093\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.0481744599251922\n",
       "physician-fee-freeze.n                              0.7166770696640015     0.7166770696640015   0.03452553077183262\n",
       "synfuels-corporation-cutback.n                      0.6974204778671265     0.6974204778671265   0.03359785486201828\n",
       "el-salvador-aid.?                                   0.6335800886154175     0.6335800886154175   0.030522378588403155\n",
       "adoption-of-the-budget-resolution.y                 0.6160795092582703     0.6160795092582703   0.02967929762949462\n",
       "water-project-cost-sharing.y                        0.5971928238868713     0.5971928238868713   0.028769441761950447\n",
       "anti-satellite-test-ban.n                           0.5896254181861877     0.5896254181861877   0.028404886079285197\n",
       "crime.n                                             0.5706847906112671     0.5706847906112671   0.02749243157521919\n",
       "mx-missile.n                                        0.5699778199195862     0.5699778199195862   0.027458373643964522\n",
       "education-spending.?                                0.5143143534660339     0.5143143534660339   0.02477681621000059\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[5,5,5], nfolds=0, activation=\"tanh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb25a1ff9c21ee6",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [5,5,5], cross folds = 0, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d07e8ca48556a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1406\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-116.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-116 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-116 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-116 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-116 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-116 .h2o-table th,\n",
       "#h2o-table-116 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-116 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-116\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2524469</td>\n",
       "<td>0.4311426</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0148989</td>\n",
       "<td>0.1780187</td>\n",
       "<td>-0.0000309</td>\n",
       "<td>0.1196337</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0020506</td>\n",
       "<td>0.0007596</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0609113</td>\n",
       "<td>0.4876398</td>\n",
       "<td>0.0641635</td>\n",
       "<td>0.0305209</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0129818</td>\n",
       "<td>0.0155707</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1696949</td>\n",
       "<td>0.3945540</td>\n",
       "<td>0.0566816</td>\n",
       "<td>0.0278130</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0033279</td>\n",
       "<td>0.0006054</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6811199</td>\n",
       "<td>1.0460100</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0911278</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01548889297470334\n",
       "RMSE: 0.12445438109887229\n",
       "LogLoss: 0.0691635521869766\n",
       "Mean Per-Class Error: 0.014857310973815829\n",
       "AUC: 0.995660488378935\n",
       "AUCPR: 0.9940360901404862\n",
       "Gini: 0.9913209767578699</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-117.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-117 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-117 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-117 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-117 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-117 .h2o-table th,\n",
       "#h2o-table-117 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-117 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-117\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5700888974598675</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>203.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0146</td>\n",
       "<td> (3.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>205.0</td>\n",
       "<td>133.0</td>\n",
       "<td>0.0148</td>\n",
       "<td> (5.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-118.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-118 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-118 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-118 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-118 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-118 .h2o-table th,\n",
       "#h2o-table-118 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-118 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-118\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9811321</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4686205</td>\n",
       "<td>0.9864458</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6803106</td>\n",
       "<td>0.9815951</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9852071</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9946734</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0058288</td>\n",
       "<td>1.0</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9946734</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9689856</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9848485</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5700889</td>\n",
       "<td>0.9851427</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9946734</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9946734</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0025129</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0058288</td>\n",
       "<td>132.0</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9946734</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9946734</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0025129</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0058288</td>\n",
       "<td>1.0</td>\n",
       "<td>158.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-119.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-119 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-119 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-119 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-119 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-119 .h2o-table th,\n",
       "#h2o-table-119 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-119 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-119\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.13 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9937615</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9940582</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9940582</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9934070</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936405</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9938792</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9928607</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930847</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935903</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9928374</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928374</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933895</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9925453</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927170</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933104</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9913286</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919030</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9926067</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9882660</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9901207</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9917780</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9848219</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9865003</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9904586</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3047337</td>\n",
       "<td>0.9691212</td>\n",
       "<td>2.4874459</td>\n",
       "<td>2.5357458</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9801877</td>\n",
       "<td>0.9902913</td>\n",
       "<td>0.9869685</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>148.7445887</td>\n",
       "<td>153.5745808</td>\n",
       "<td>0.7678729</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4749243</td>\n",
       "<td>2.2405303</td>\n",
       "<td>2.4657688</td>\n",
       "<td>0.875</td>\n",
       "<td>0.8410500</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9523804</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.9848485</td>\n",
       "<td>124.0530303</td>\n",
       "<td>146.5768799</td>\n",
       "<td>0.9605766</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0096958</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0870462</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7782895</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0053393</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0069045</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6490920</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0044140</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0048011</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5590005</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8047337</td>\n",
       "<td>0.0035295</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2426471</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0038870</td>\n",
       "<td>0.4852941</td>\n",
       "<td>0.4855296</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.2647059</td>\n",
       "<td>0.3203883</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0032011</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0033878</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4347778</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0025129</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029399</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3913385</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.013890928797000693\n",
       "RMSE: 0.11785978447715188\n",
       "LogLoss: 0.052391018270660734\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-120.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-120 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-120 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-120 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-120 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-120 .h2o-table th,\n",
       "#h2o-table-120 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-120 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-120\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6952516404269884</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>62.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (1.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-121.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-121 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-121 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-121 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-121 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-121 .h2o-table th,\n",
       "#h2o-table-121 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-121 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-121\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9859155</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1287646</td>\n",
       "<td>0.9890110</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9943182</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9896907</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1287646</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9780293</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9722222</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6952516</td>\n",
       "<td>0.9861111</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9943072</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9943072</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0026870</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1287646</td>\n",
       "<td>36.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9943072</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0026870</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1287646</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-122.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-122 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-122 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-122 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-122 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-122 .h2o-table th,\n",
       "#h2o-table-122 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-122 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-122\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.06 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9930321</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943072</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943072</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9928063</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929790</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936431</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9924882</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933591</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9922148</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924469</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931311</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9921208</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9921706</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929390</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9917159</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919522</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924456</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9907624</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9914307</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9921073</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9881609</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9892030</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9913812</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9269438</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9811918</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9882190</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0819447</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.5897882</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.8860573</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0083615</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0206481</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7094432</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0056579</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0065111</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6003675</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0045818</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051605</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5128371</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0036732</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0041021</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4533745</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0032940</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0034820</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4016627</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0026870</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0028974</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3605529</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-123.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-123 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-123 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-123 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-123 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-123 .h2o-table th,\n",
       "#h2o-table-123 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-123 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-123\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.012 sec</td>\n",
       "<td>112666 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2109433</td>\n",
       "<td>0.1634058</td>\n",
       "<td>0.8130508</td>\n",
       "<td>0.9817961</td>\n",
       "<td>0.9628444</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0532544</td>\n",
       "<td>0.2219103</td>\n",
       "<td>0.1685375</td>\n",
       "<td>0.7890079</td>\n",
       "<td>0.9886157</td>\n",
       "<td>0.9810854</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.032 sec</td>\n",
       "<td>39764 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1843473</td>\n",
       "<td>0.1296516</td>\n",
       "<td>0.8572205</td>\n",
       "<td>0.9881951</td>\n",
       "<td>0.9785739</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.1915001</td>\n",
       "<td>0.1243378</td>\n",
       "<td>0.8428735</td>\n",
       "<td>0.9927140</td>\n",
       "<td>0.9875940</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.051 sec</td>\n",
       "<td>33800 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1658221</td>\n",
       "<td>0.1089020</td>\n",
       "<td>0.8844747</td>\n",
       "<td>0.9906222</td>\n",
       "<td>0.9831777</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.1757758</td>\n",
       "<td>0.1026639</td>\n",
       "<td>0.8676179</td>\n",
       "<td>0.9949909</td>\n",
       "<td>0.9914792</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.072 sec</td>\n",
       "<td>30727 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1570520</td>\n",
       "<td>0.0992638</td>\n",
       "<td>0.8963715</td>\n",
       "<td>0.9918358</td>\n",
       "<td>0.9857957</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1555667</td>\n",
       "<td>0.0836351</td>\n",
       "<td>0.8963082</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9930641</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.100 sec</td>\n",
       "<td>29137 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1464146</td>\n",
       "<td>0.0894230</td>\n",
       "<td>0.9099340</td>\n",
       "<td>0.9931230</td>\n",
       "<td>0.9884188</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1453706</td>\n",
       "<td>0.0763246</td>\n",
       "<td>0.9094551</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.131 sec</td>\n",
       "<td>24433 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1393621</td>\n",
       "<td>0.0830717</td>\n",
       "<td>0.9184016</td>\n",
       "<td>0.9938217</td>\n",
       "<td>0.9899479</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1360821</td>\n",
       "<td>0.0686306</td>\n",
       "<td>0.9206562</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.150 sec</td>\n",
       "<td>24645 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1376766</td>\n",
       "<td>0.0800181</td>\n",
       "<td>0.9203634</td>\n",
       "<td>0.9942630</td>\n",
       "<td>0.9909781</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1258424</td>\n",
       "<td>0.0590951</td>\n",
       "<td>0.9321477</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.171 sec</td>\n",
       "<td>24360 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1322235</td>\n",
       "<td>0.0754169</td>\n",
       "<td>0.9265470</td>\n",
       "<td>0.9948147</td>\n",
       "<td>0.9922661</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1217894</td>\n",
       "<td>0.0557746</td>\n",
       "<td>0.9364478</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.191 sec</td>\n",
       "<td>24336 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1265907</td>\n",
       "<td>0.0716402</td>\n",
       "<td>0.9326720</td>\n",
       "<td>0.9950353</td>\n",
       "<td>0.9927280</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1226970</td>\n",
       "<td>0.0578272</td>\n",
       "<td>0.9354971</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:38</td>\n",
       "<td> 0.211 sec</td>\n",
       "<td>24492 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1244544</td>\n",
       "<td>0.0691636</td>\n",
       "<td>0.9349252</td>\n",
       "<td>0.9956605</td>\n",
       "<td>0.9940361</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1178598</td>\n",
       "<td>0.0523910</td>\n",
       "<td>0.9404828</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-124.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-124 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-124 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-124 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-124 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-124 .h2o-table th,\n",
       "#h2o-table-124 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-124 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-124\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0481745</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.7166771</td>\n",
       "<td>0.7166771</td>\n",
       "<td>0.0345255</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.6974205</td>\n",
       "<td>0.6974205</td>\n",
       "<td>0.0335979</td></tr>\n",
       "<tr><td>el-salvador-aid.?</td>\n",
       "<td>0.6335801</td>\n",
       "<td>0.6335801</td>\n",
       "<td>0.0305224</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.6160795</td>\n",
       "<td>0.6160795</td>\n",
       "<td>0.0296793</td></tr>\n",
       "<tr><td>water-project-cost-sharing.y</td>\n",
       "<td>0.5971928</td>\n",
       "<td>0.5971928</td>\n",
       "<td>0.0287694</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.n</td>\n",
       "<td>0.5896254</td>\n",
       "<td>0.5896254</td>\n",
       "<td>0.0284049</td></tr>\n",
       "<tr><td>crime.n</td>\n",
       "<td>0.5706848</td>\n",
       "<td>0.5706848</td>\n",
       "<td>0.0274924</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.5699778</td>\n",
       "<td>0.5699778</td>\n",
       "<td>0.0274584</td></tr>\n",
       "<tr><td>education-spending.?</td>\n",
       "<td>0.5143144</td>\n",
       "<td>0.5143144</td>\n",
       "<td>0.0247768</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1406\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight            weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  ---------------------  ---------------------  ----------  ---------------------  -------------------  ----------------------  --------------------\n",
       "    1        64       Input    0.0\n",
       "    2        5        Tanh     0.0        0.0   0.0   0.25244694898956366    0.43114256858825684    0.0         -0.014898876845973064  0.1780187487602234   -3.0877236202137e-05    0.1196337342262268\n",
       "    3        5        Tanh     0.0        0.0   0.0   0.0020506446668878196  0.0007595927454531193  0.0         -0.06091129034757614   0.48763978481292725  0.064163481603456       0.030520908534526825\n",
       "    4        5        Tanh     0.0        0.0   0.0   0.012981761889532208   0.01557065173983574    0.0         0.16969490901799872    0.3945540189743042   0.056681598694319955    0.027812950313091278\n",
       "    5        2        Softmax             0.0   0.0   0.003327851835638285   0.0006053755059838295  0.0         1.6811198571696877     1.0460100173950195   1.1102230246251565e-16  0.09112781286239624\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01548889297470334\n",
       "RMSE: 0.12445438109887229\n",
       "LogLoss: 0.0691635521869766\n",
       "Mean Per-Class Error: 0.014857310973815829\n",
       "AUC: 0.995660488378935\n",
       "AUCPR: 0.9940360901404862\n",
       "Gini: 0.9913209767578699\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5700888974598675\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    203         3             0.0146   (3.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       205         133           0.0148   (5.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.570089     0.981132  94\n",
       "max f2                       0.46862      0.986446  97\n",
       "max f0point5                 0.680311     0.981595  91\n",
       "max accuracy                 0.570089     0.985207  94\n",
       "max precision                0.994673     1         0\n",
       "max recall                   0.00582885   1         158\n",
       "max specificity              0.994673     1         0\n",
       "max absolute_mcc             0.570089     0.968986  94\n",
       "max min_per_class_accuracy   0.570089     0.984848  94\n",
       "max mean_per_class_accuracy  0.570089     0.985143  94\n",
       "max tns                      0.994673     206       0\n",
       "max fns                      0.994673     131       0\n",
       "max fps                      0.00251287   206       269\n",
       "max tps                      0.00582885   132       158\n",
       "max tnr                      0.994673     1         0\n",
       "max fnr                      0.994673     0.992424  0\n",
       "max fpr                      0.00251287   1         269\n",
       "max tpr                      0.00582885   1         158\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.13 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.993762           2.56061    2.56061            1                0.994058    1                           0.994058            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.993407           2.56061    2.56061            1                0.99364     1                           0.993879            0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.992861           2.56061    2.56061            1                0.993085    1                           0.99359             0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0443787                   0.992837           2.56061    2.56061            1                0.992837    1                           0.99339             0.030303        0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.992545           2.56061    2.56061            1                0.992717    1                           0.99331             0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.991329           2.56061    2.56061            1                0.991903    1                           0.992607            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.988266           2.56061    2.56061            1                0.990121    1                           0.991778            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.201183                    0.984822           2.56061    2.56061            1                0.9865      1                           0.990459            0.128788        0.515152                   156.061   156.061            0.515152\n",
       "9        0.304734                    0.969121           2.48745    2.53575            0.971429         0.980188    0.990291                    0.986968            0.257576        0.772727                   148.745   153.575            0.767873\n",
       "10       0.399408                    0.474924           2.24053    2.46577            0.875            0.84105     0.962963                    0.95238             0.212121        0.984848                   124.053   146.577            0.960577\n",
       "11       0.5                         0.0096958          0.0753119  1.98485            0.0294118        0.0870462   0.775148                    0.778289            0.00757576      0.992424                   -92.4688  98.4848            0.807958\n",
       "12       0.600592                    0.00533935         0.0753119  1.66502            0.0294118        0.00690448  0.650246                    0.649092            0.00757576      1                          -92.4688  66.5025            0.65534\n",
       "13       0.698225                    0.00441405         0          1.4322             0                0.00480107  0.559322                    0.559               0               1                          -100      43.2203            0.495146\n",
       "14       0.804734                    0.00352954         0          1.24265            0                0.00388701  0.485294                    0.48553             0               1                          -100      24.2647            0.320388\n",
       "15       0.899408                    0.00320113         0          1.11184            0                0.00338781  0.434211                    0.434778            0               1                          -100      11.1842            0.165049\n",
       "16       1                           0.00251287         0          1                  0                0.00293989  0.390533                    0.391338            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.013890928797000693\n",
       "RMSE: 0.11785978447715188\n",
       "LogLoss: 0.052391018270660734\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6952516404269884\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    61          0             0        (0.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       62          35            0.0103   (1.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.695252     0.985915  31\n",
       "max f2                       0.128765     0.989011  34\n",
       "max f0point5                 0.695252     0.994318  31\n",
       "max accuracy                 0.695252     0.989691  31\n",
       "max precision                0.994307     1         0\n",
       "max recall                   0.128765     1         34\n",
       "max specificity              0.994307     1         0\n",
       "max absolute_mcc             0.695252     0.978029  31\n",
       "max min_per_class_accuracy   0.695252     0.972222  31\n",
       "max mean_per_class_accuracy  0.695252     0.986111  31\n",
       "max tns                      0.994307     61        0\n",
       "max fns                      0.994307     35        0\n",
       "max fps                      0.00268697   61        91\n",
       "max tps                      0.128765     36        34\n",
       "max tnr                      0.994307     1         0\n",
       "max fnr                      0.994307     0.972222  0\n",
       "max fpr                      0.00268697   1         91\n",
       "max tpr                      0.128765     1         34\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.06 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   0.993032           2.69444  2.69444            1                0.994307    1                           0.994307            0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   0.992806           2.69444  2.69444            1                0.992979    1                           0.993643            0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0309278                   0.992488           2.69444  2.69444            1                0.992791    1                           0.993359            0.0277778       0.0833333                  169.444  169.444            0.0833333\n",
       "4        0.0412371                   0.992215           2.69444  2.69444            1                0.992447    1                           0.993131            0.0277778       0.111111                   169.444  169.444            0.111111\n",
       "5        0.0515464                   0.992121           2.69444  2.69444            1                0.992171    1                           0.992939            0.0277778       0.138889                   169.444  169.444            0.138889\n",
       "6        0.103093                    0.991716           2.69444  2.69444            1                0.991952    1                           0.992446            0.138889        0.277778                   169.444  169.444            0.277778\n",
       "7        0.154639                    0.990762           2.69444  2.69444            1                0.991431    1                           0.992107            0.138889        0.416667                   169.444  169.444            0.416667\n",
       "8        0.206186                    0.988161           2.69444  2.69444            1                0.989203    1                           0.991381            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "9        0.298969                    0.926944           2.69444  2.69444            1                0.981192    1                           0.988219            0.25            0.805556                   169.444  169.444            0.805556\n",
       "10       0.402062                    0.0819447          1.88611  2.48718            0.7              0.589788    0.923077                    0.886057            0.194444        1                          88.6111  148.718            0.95082\n",
       "11       0.505155                    0.00836154         0        1.97959            0                0.0206481   0.734694                    0.709443            0               1                          -100     97.9592            0.786885\n",
       "12       0.597938                    0.0056579          0        1.67241            0                0.00651115  0.62069                     0.600367            0               1                          -100     67.2414            0.639344\n",
       "13       0.701031                    0.00458185         0        1.42647            0                0.00516046  0.529412                    0.512837            0               1                          -100     42.6471            0.47541\n",
       "14       0.793814                    0.00367319         0        1.25974            0                0.0041021   0.467532                    0.453375            0               1                          -100     25.974             0.327869\n",
       "15       0.896907                    0.00329398         0        1.11494            0                0.00348204  0.413793                    0.401663            0               1                          -100     11.4943            0.163934\n",
       "16       1                           0.00268697         0        1                  0                0.00289736  0.371134                    0.360553            0               1                          -100     0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:38  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:38  0.012 sec   112666 obs/sec    1         1             338        0.210943         0.163406            0.813051       0.981796        0.962844           2.56061          0.0532544                        0.22191            0.168537              0.789008         0.988616          0.981085             2.69444            0.0412371\n",
       "    2025-05-26 14:48:38  0.032 sec   39764 obs/sec     2         2             676        0.184347         0.129652            0.857221       0.988195        0.978574           2.56061          0.0414201                        0.1915             0.124338              0.842874         0.992714          0.987594             2.69444            0.0309278\n",
       "    2025-05-26 14:48:38  0.051 sec   33800 obs/sec     3         3             1014       0.165822         0.108902            0.884475       0.990622        0.983178           2.56061          0.0325444                        0.175776           0.102664              0.867618         0.994991          0.991479             2.69444            0.0309278\n",
       "    2025-05-26 14:48:38  0.072 sec   30727 obs/sec     4         4             1352       0.157052         0.0992638           0.896371       0.991836        0.985796           2.56061          0.0236686                        0.155567           0.0836351             0.896308         0.995902          0.993064             2.69444            0.0309278\n",
       "    2025-05-26 14:48:38  0.100 sec   29137 obs/sec     5         5             1690       0.146415         0.089423            0.909934       0.993123        0.988419           2.56061          0.0207101                        0.145371           0.0763246             0.909455         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:38  0.131 sec   24433 obs/sec     6         6             2028       0.139362         0.0830717           0.918402       0.993822        0.989948           2.56061          0.0207101                        0.136082           0.0686306             0.920656         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:38  0.150 sec   24645 obs/sec     7         7             2366       0.137677         0.0800181           0.920363       0.994263        0.990978           2.56061          0.0177515                        0.125842           0.0590951             0.932148         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:38  0.171 sec   24360 obs/sec     8         8             2704       0.132223         0.0754169           0.926547       0.994815        0.992266           2.56061          0.0177515                        0.121789           0.0557746             0.936448         0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:48:38  0.191 sec   24336 obs/sec     9         9             3042       0.126591         0.0716402           0.932672       0.995035        0.992728           2.56061          0.0177515                        0.122697           0.0578272             0.935497         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:38  0.211 sec   24492 obs/sec     10        10            3380       0.124454         0.0691636           0.934925       0.99566         0.994036           2.56061          0.0147929                        0.11786            0.052391              0.940483         0.999089          0.998518             2.69444            0.0103093\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.0481744599251922\n",
       "physician-fee-freeze.n                              0.7166770696640015     0.7166770696640015   0.03452553077183262\n",
       "synfuels-corporation-cutback.n                      0.6974204778671265     0.6974204778671265   0.03359785486201828\n",
       "el-salvador-aid.?                                   0.6335800886154175     0.6335800886154175   0.030522378588403155\n",
       "adoption-of-the-budget-resolution.y                 0.6160795092582703     0.6160795092582703   0.02967929762949462\n",
       "water-project-cost-sharing.y                        0.5971928238868713     0.5971928238868713   0.028769441761950447\n",
       "anti-satellite-test-ban.n                           0.5896254181861877     0.5896254181861877   0.028404886079285197\n",
       "crime.n                                             0.5706847906112671     0.5706847906112671   0.02749243157521919\n",
       "mx-missile.n                                        0.5699778199195862     0.5699778199195862   0.027458373643964522\n",
       "education-spending.?                                0.5143143534660339     0.5143143534660339   0.02477681621000059\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[5,5,5], nfolds=0, activation=\"tanh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d70fead4b570fcb",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [20,20,20], cross folds = 0, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79319cba032d5e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1427\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-125.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-125 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-125 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-125 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-125 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-125 .h2o-table th,\n",
       "#h2o-table-125 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-125 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-125\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2528838</td>\n",
       "<td>0.4309276</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0006293</td>\n",
       "<td>0.1580461</td>\n",
       "<td>-0.0032269</td>\n",
       "<td>0.0284487</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0039108</td>\n",
       "<td>0.0033601</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0051196</td>\n",
       "<td>0.2218475</td>\n",
       "<td>0.0079488</td>\n",
       "<td>0.0237799</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0044414</td>\n",
       "<td>0.0035357</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0155494</td>\n",
       "<td>0.2137624</td>\n",
       "<td>0.0035175</td>\n",
       "<td>0.0117155</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0047410</td>\n",
       "<td>0.0014152</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0369950</td>\n",
       "<td>1.1523738</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.0069570</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.015894808045215335\n",
       "RMSE: 0.12607461300839012\n",
       "LogLoss: 0.05654426607172878\n",
       "Mean Per-Class Error: 0.018645189761694617\n",
       "AUC: 0.9979773462783172\n",
       "AUCPR: 0.9967656423884548\n",
       "Gini: 0.9959546925566345</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-126.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-126 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-126 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-126 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-126 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-126 .h2o-table th,\n",
       "#h2o-table-126 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-126 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-126\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6693947349504704</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>203.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0146</td>\n",
       "<td> (3.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>3.0</td>\n",
       "<td>129.0</td>\n",
       "<td>0.0227</td>\n",
       "<td> (3.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>206.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.0178</td>\n",
       "<td> (6.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-127.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-127 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-127 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-127 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-127 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-127 .h2o-table th,\n",
       "#h2o-table-127 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-127 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-127\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6693947</td>\n",
       "<td>0.9772727</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2642081</td>\n",
       "<td>0.9836066</td>\n",
       "<td>104.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8610331</td>\n",
       "<td>0.9792994</td>\n",
       "<td>85.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6693947</td>\n",
       "<td>0.9822485</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999437</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2642081</td>\n",
       "<td>1.0</td>\n",
       "<td>104.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999437</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6693947</td>\n",
       "<td>0.9627096</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6693947</td>\n",
       "<td>0.9772727</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6693947</td>\n",
       "<td>0.9813548</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999437</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999437</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000195</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.2642081</td>\n",
       "<td>132.0</td>\n",
       "<td>104.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999437</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999437</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000195</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.2642081</td>\n",
       "<td>1.0</td>\n",
       "<td>104.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-128.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-128 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-128 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-128 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-128 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-128 .h2o-table th,\n",
       "#h2o-table-128 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-128 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-128\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.65 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.9998606</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998772</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998772</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0378788</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0378788</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9996704</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997564</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998427</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9995963</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996421</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997698</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9995673</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995722</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997274</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9994133</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995122</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996895</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9987499</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993904</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1597633</td>\n",
       "<td>0.9969074</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978347</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988142</td>\n",
       "<td>0.1515152</td>\n",
       "<td>0.4090909</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.4090909</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2071006</td>\n",
       "<td>0.9936811</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9947481</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978848</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.5303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5303030</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9769091</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9881889</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9948430</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.3944761</td>\n",
       "<td>2.0950413</td>\n",
       "<td>2.4468013</td>\n",
       "<td>0.8181818</td>\n",
       "<td>0.8504072</td>\n",
       "<td>0.9555556</td>\n",
       "<td>0.9595364</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.9772727</td>\n",
       "<td>109.5041322</td>\n",
       "<td>144.6801347</td>\n",
       "<td>0.9481465</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0124314</td>\n",
       "<td>0.2259358</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0882353</td>\n",
       "<td>0.1242946</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7914996</td>\n",
       "<td>0.0227273</td>\n",
       "<td>1.0</td>\n",
       "<td>-77.4064171</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0025045</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0053262</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6598253</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0008064</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015058</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5677721</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0003635</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005253</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4963410</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001256</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002272</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4408546</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000195</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000678</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3965151</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.023670272857108543\n",
       "RMSE: 0.15385146361705027\n",
       "LogLoss: 0.07986644976045372\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.9959016393442623\n",
       "AUCPR: 0.9936563668132266\n",
       "Gini: 0.9918032786885247</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-129.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-129 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-129 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-129 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-129 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-129 .h2o-table th,\n",
       "#h2o-table-129 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-129 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-129\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2640113037066277</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>59.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0328</td>\n",
       "<td> (2.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>60.0</td>\n",
       "<td>37.0</td>\n",
       "<td>0.0309</td>\n",
       "<td> (3.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-130.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-130 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-130 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-130 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-130 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-130 .h2o-table th,\n",
       "#h2o-table-130 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-130 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-130\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2640113</td>\n",
       "<td>0.9589041</td>\n",
       "<td>33.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0519275</td>\n",
       "<td>0.9677419</td>\n",
       "<td>38.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7065223</td>\n",
       "<td>0.9821429</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7065223</td>\n",
       "<td>0.9690722</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9997587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0519275</td>\n",
       "<td>1.0</td>\n",
       "<td>38.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9997587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7065223</td>\n",
       "<td>0.9347181</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2640113</td>\n",
       "<td>0.9672131</td>\n",
       "<td>33.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2640113</td>\n",
       "<td>0.9697177</td>\n",
       "<td>33.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9997587</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9997587</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000102</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0519275</td>\n",
       "<td>36.0</td>\n",
       "<td>38.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9997587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9997587</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000102</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0519275</td>\n",
       "<td>1.0</td>\n",
       "<td>38.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-131.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-131 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-131 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-131 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-131 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-131 .h2o-table th,\n",
       "#h2o-table-131 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-131 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-131\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.73 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9996694</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997587</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9995706</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996657</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997122</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9995623</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996223</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9994429</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996223</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1388889</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9990261</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992914</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994569</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9979303</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984298</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991145</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9972837</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9976114</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987387</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9213569</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9819206</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935193</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.1152110</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.5442435</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8783204</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0069422</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0335803</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7059245</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0021954</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0047764</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5971256</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0009846</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014285</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5095231</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0003913</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006809</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4500480</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0001422</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002577</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3983480</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000102</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000688</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3572883</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-132.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-132 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-132 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-132 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-132 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-132 .h2o-table th,\n",
       "#h2o-table-132 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-132 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-132\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.020 sec</td>\n",
       "<td>56333 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2207238</td>\n",
       "<td>0.1613350</td>\n",
       "<td>0.7953129</td>\n",
       "<td>0.9839291</td>\n",
       "<td>0.9748325</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0591716</td>\n",
       "<td>0.2616883</td>\n",
       "<td>0.2390545</td>\n",
       "<td>0.7065868</td>\n",
       "<td>0.9685792</td>\n",
       "<td>0.9593676</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0927835</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.051 sec</td>\n",
       "<td>23310 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1836335</td>\n",
       "<td>0.1144381</td>\n",
       "<td>0.8583240</td>\n",
       "<td>0.9930127</td>\n",
       "<td>0.9892854</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.2193056</td>\n",
       "<td>0.1600240</td>\n",
       "<td>0.7939319</td>\n",
       "<td>0.9840619</td>\n",
       "<td>0.9765677</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.080 sec</td>\n",
       "<td>20693 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1605320</td>\n",
       "<td>0.0894164</td>\n",
       "<td>0.8917281</td>\n",
       "<td>0.9956605</td>\n",
       "<td>0.9932067</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1877236</td>\n",
       "<td>0.1206921</td>\n",
       "<td>0.8490098</td>\n",
       "<td>0.9922587</td>\n",
       "<td>0.9889741</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.110 sec</td>\n",
       "<td>19042 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1506416</td>\n",
       "<td>0.0786731</td>\n",
       "<td>0.9046584</td>\n",
       "<td>0.9969109</td>\n",
       "<td>0.9950810</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1751166</td>\n",
       "<td>0.1041747</td>\n",
       "<td>0.8686090</td>\n",
       "<td>0.9936248</td>\n",
       "<td>0.9906904</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.142 sec</td>\n",
       "<td>17422 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1404111</td>\n",
       "<td>0.0679485</td>\n",
       "<td>0.9171686</td>\n",
       "<td>0.9972786</td>\n",
       "<td>0.9957266</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1673279</td>\n",
       "<td>0.0976448</td>\n",
       "<td>0.8800369</td>\n",
       "<td>0.9945355</td>\n",
       "<td>0.9917333</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.167 sec</td>\n",
       "<td>17634 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1364133</td>\n",
       "<td>0.0656268</td>\n",
       "<td>0.9218183</td>\n",
       "<td>0.9978670</td>\n",
       "<td>0.9965925</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1773899</td>\n",
       "<td>0.1100505</td>\n",
       "<td>0.8651755</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:41</td>\n",
       "<td> 0.192 sec</td>\n",
       "<td>17789 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1260746</td>\n",
       "<td>0.0565443</td>\n",
       "<td>0.9332198</td>\n",
       "<td>0.9979773</td>\n",
       "<td>0.9967656</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1538515</td>\n",
       "<td>0.0798664</td>\n",
       "<td>0.8985822</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:42</td>\n",
       "<td> 0.217 sec</td>\n",
       "<td>18026 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1254440</td>\n",
       "<td>0.0540615</td>\n",
       "<td>0.9338862</td>\n",
       "<td>0.9981980</td>\n",
       "<td>0.9971564</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1674418</td>\n",
       "<td>0.0949686</td>\n",
       "<td>0.8798735</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:42</td>\n",
       "<td> 0.241 sec</td>\n",
       "<td>18107 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1282885</td>\n",
       "<td>0.0560890</td>\n",
       "<td>0.9308539</td>\n",
       "<td>0.9984187</td>\n",
       "<td>0.9975124</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1761549</td>\n",
       "<td>0.1148253</td>\n",
       "<td>0.8670463</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:42</td>\n",
       "<td> 0.269 sec</td>\n",
       "<td>17789 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1149926</td>\n",
       "<td>0.0473662</td>\n",
       "<td>0.9444439</td>\n",
       "<td>0.9987864</td>\n",
       "<td>0.9980953</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1552790</td>\n",
       "<td>0.0833018</td>\n",
       "<td>0.8966914</td>\n",
       "<td>0.9963570</td>\n",
       "<td>0.9943960</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:42</td>\n",
       "<td> 0.278 sec</td>\n",
       "<td>17604 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1260746</td>\n",
       "<td>0.0565443</td>\n",
       "<td>0.9332198</td>\n",
       "<td>0.9979773</td>\n",
       "<td>0.9967656</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1538515</td>\n",
       "<td>0.0798664</td>\n",
       "<td>0.8985822</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-133.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-133 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-133 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-133 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-133 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-133 .h2o-table th,\n",
       "#h2o-table-133 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-133 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-133\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>el-salvador-aid.?</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0269549</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.9851332</td>\n",
       "<td>0.9851332</td>\n",
       "<td>0.0265541</td></tr>\n",
       "<tr><td>crime.?</td>\n",
       "<td>0.9807437</td>\n",
       "<td>0.9807437</td>\n",
       "<td>0.0264358</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9541820</td>\n",
       "<td>0.9541820</td>\n",
       "<td>0.0257198</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.?</td>\n",
       "<td>0.9509653</td>\n",
       "<td>0.9509653</td>\n",
       "<td>0.0256331</td></tr>\n",
       "<tr><td>superfund-right-to-sue.y</td>\n",
       "<td>0.9181176</td>\n",
       "<td>0.9181176</td>\n",
       "<td>0.0247477</td></tr>\n",
       "<tr><td>physician-fee-freeze.y</td>\n",
       "<td>0.8970591</td>\n",
       "<td>0.8970591</td>\n",
       "<td>0.0241801</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.8966131</td>\n",
       "<td>0.8966131</td>\n",
       "<td>0.0241681</td></tr>\n",
       "<tr><td>mx-missile.y</td>\n",
       "<td>0.8662047</td>\n",
       "<td>0.8662047</td>\n",
       "<td>0.0233484</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.8598179</td>\n",
       "<td>0.8598179</td>\n",
       "<td>0.0231763</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1427\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate             rate_rms               momentum    mean_weight             weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  --------------------  ---------------------  ----------  ----------------------  -------------------  ----------------------  --------------------\n",
       "    1        64       Input    0.0\n",
       "    2        20       Tanh     0.0        0.0   0.0   0.25288375200802876   0.4309276342391968     0.0         -0.0006292716017185285  0.15804606676101685  -0.0032268937639498814  0.02844873070716858\n",
       "    3        20       Tanh     0.0        0.0   0.0   0.003910838651281665  0.0033601103350520134  0.0         0.00511955373629462     0.2218475341796875   0.007948761646788038    0.023779861629009247\n",
       "    4        20       Tanh     0.0        0.0   0.0   0.004441358810872771  0.003535749390721321   0.0         0.01554943269395153     0.21376240253448486  0.0035175324453470395   0.011715516448020935\n",
       "    5        2        Softmax             0.0   0.0   0.00474102896405384   0.0014152303338050842  0.0         0.03699496034532786     1.1523737907409668   -5.204170427930421e-18  0.006956985220313072\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.015894808045215335\n",
       "RMSE: 0.12607461300839012\n",
       "LogLoss: 0.05654426607172878\n",
       "Mean Per-Class Error: 0.018645189761694617\n",
       "AUC: 0.9979773462783172\n",
       "AUCPR: 0.9967656423884548\n",
       "Gini: 0.9959546925566345\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6693947349504704\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    203         3             0.0146   (3.0/206.0)\n",
       "republican  3           129           0.0227   (3.0/132.0)\n",
       "Total       206         132           0.0178   (6.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.669395     0.977273  93\n",
       "max f2                       0.264208     0.983607  104\n",
       "max f0point5                 0.861033     0.979299  85\n",
       "max accuracy                 0.669395     0.982249  93\n",
       "max precision                0.999944     1         0\n",
       "max recall                   0.264208     1         104\n",
       "max specificity              0.999944     1         0\n",
       "max absolute_mcc             0.669395     0.96271   93\n",
       "max min_per_class_accuracy   0.669395     0.977273  93\n",
       "max mean_per_class_accuracy  0.669395     0.981355  93\n",
       "max tns                      0.999944     206       0\n",
       "max fns                      0.999944     131       0\n",
       "max fps                      1.95182e-05  206       269\n",
       "max tps                      0.264208     132       104\n",
       "max tnr                      0.999944     1         0\n",
       "max fnr                      0.999944     0.992424  0\n",
       "max fpr                      1.95182e-05  1         269\n",
       "max tpr                      0.264208     1         104\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.65 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0147929                   0.999861           2.56061   2.56061            1                0.999877     1                           0.999877            0.0378788       0.0378788                  156.061   156.061            0.0378788\n",
       "2        0.0207101                   0.99967            2.56061   2.56061            1                0.999756     1                           0.999843            0.0151515       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.999596           2.56061   2.56061            1                0.999642     1                           0.99977             0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.999567           2.56061   2.56061            1                0.999572     1                           0.999727            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.999413           2.56061   2.56061            1                0.999512     1                           0.999689            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.99875            2.56061   2.56061            1                0.999091     1                           0.99939             0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.159763                    0.996907           2.56061   2.56061            1                0.997835     1                           0.998814            0.151515        0.409091                   156.061   156.061            0.409091\n",
       "8        0.207101                    0.993681           2.56061   2.56061            1                0.994748     1                           0.997885            0.121212        0.530303                   156.061   156.061            0.530303\n",
       "9        0.301775                    0.976909           2.56061   2.56061            1                0.988189     1                           0.994843            0.242424        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.394476           2.09504   2.4468             0.818182         0.850407     0.955556                    0.959536            0.204545        0.977273                   109.504   144.68             0.948147\n",
       "11       0.5                         0.0124314          0.225936  2                  0.0882353        0.124295     0.781065                    0.7915              0.0227273       1                          -77.4064  100                0.820388\n",
       "12       0.600592                    0.00250455         0         1.66502            0                0.00532618   0.650246                    0.659825            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.000806434        0         1.4322             0                0.00150577   0.559322                    0.567772            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    0.000363454        0         1.25185            0                0.000525265  0.488889                    0.496341            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    0.000125562        0         1.11184            0                0.000227152  0.434211                    0.440855            0               1                          -100      11.1842            0.165049\n",
       "16       1                           1.95182e-05        0         1                  0                6.78041e-05  0.390533                    0.396515            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.023670272857108543\n",
       "RMSE: 0.15385146361705027\n",
       "LogLoss: 0.07986644976045372\n",
       "Mean Per-Class Error: 0.03028233151183971\n",
       "AUC: 0.9959016393442623\n",
       "AUCPR: 0.9936563668132266\n",
       "Gini: 0.9918032786885247\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2640113037066277\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    59          2             0.0328   (2.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       60          37            0.0309   (3.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.264011     0.958904  33\n",
       "max f2                       0.0519275    0.967742  38\n",
       "max f0point5                 0.706522     0.982143  29\n",
       "max accuracy                 0.706522     0.969072  29\n",
       "max precision                0.999759     1         0\n",
       "max recall                   0.0519275    1         38\n",
       "max specificity              0.999759     1         0\n",
       "max absolute_mcc             0.706522     0.934718  29\n",
       "max min_per_class_accuracy   0.264011     0.967213  33\n",
       "max mean_per_class_accuracy  0.264011     0.969718  33\n",
       "max tns                      0.999759     61        0\n",
       "max fns                      0.999759     35        0\n",
       "max fps                      1.02157e-05  61        91\n",
       "max tps                      0.0519275    36        38\n",
       "max tnr                      0.999759     1         0\n",
       "max fnr                      0.999759     0.972222  0\n",
       "max fpr                      1.02157e-05  1         91\n",
       "max tpr                      0.0519275    1         38\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.73 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0103093                   0.999669           2.69444   2.69444            1                0.999759     1                           0.999759            0.0277778       0.0277778                  169.444   169.444            0.0277778\n",
       "2        0.0206186                   0.999571           2.69444   2.69444            1                0.999666     1                           0.999712            0.0277778       0.0555556                  169.444   169.444            0.0555556\n",
       "3        0.0515464                   0.999562           2.69444   2.69444            1                0.999562     1                           0.999622            0.0833333       0.138889                   169.444   169.444            0.138889\n",
       "4        0.0515464                   0.999443           0         2.69444            0                0            1                           0.999622            0               0.138889                   -100      169.444            0.138889\n",
       "5        0.103093                    0.999026           2.69444   2.69444            1                0.999291     1                           0.999457            0.138889        0.277778                   169.444   169.444            0.277778\n",
       "6        0.154639                    0.99793            2.69444   2.69444            1                0.99843      1                           0.999114            0.138889        0.416667                   169.444   169.444            0.416667\n",
       "7        0.206186                    0.997284           2.69444   2.69444            1                0.997611     1                           0.998739            0.138889        0.555556                   169.444   169.444            0.555556\n",
       "8        0.298969                    0.921357           2.69444   2.69444            1                0.981921     1                           0.993519            0.25            0.805556                   169.444   169.444            0.805556\n",
       "9        0.402062                    0.115211           1.61667   2.41809            0.6              0.544244     0.897436                    0.87832             0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "10       0.505155                    0.00694218         0.269444  1.97959            0.1              0.0335803    0.734694                    0.705924            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "11       0.597938                    0.0021954          0         1.67241            0                0.00477642   0.62069                     0.597126            0               1                          -100      67.2414            0.639344\n",
       "12       0.701031                    0.000984594        0         1.42647            0                0.00142853   0.529412                    0.509523            0               1                          -100      42.6471            0.47541\n",
       "13       0.793814                    0.000391281        0         1.25974            0                0.000680862  0.467532                    0.450048            0               1                          -100      25.974             0.327869\n",
       "14       0.896907                    0.000142213        0         1.11494            0                0.000257715  0.413793                    0.398348            0               1                          -100      11.4943            0.163934\n",
       "15       1                           1.02157e-05        0         1                  0                6.88014e-05  0.371134                    0.357288            0               1                          -100      0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:41  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:41  0.020 sec   56333 obs/sec     1         1             338        0.220724         0.161335            0.795313       0.983929        0.974833           2.56061          0.0591716                        0.261688           0.239055              0.706587         0.968579          0.959368             2.69444            0.0927835\n",
       "    2025-05-26 14:48:41  0.051 sec   23310 obs/sec     2         2             676        0.183634         0.114438            0.858324       0.993013        0.989285           2.56061          0.0384615                        0.219306           0.160024              0.793932         0.984062          0.976568             2.69444            0.0618557\n",
       "    2025-05-26 14:48:41  0.080 sec   20693 obs/sec     3         3             1014       0.160532         0.0894164           0.891728       0.99566         0.993207           2.56061          0.0266272                        0.187724           0.120692              0.84901          0.992259          0.988974             2.69444            0.0309278\n",
       "    2025-05-26 14:48:41  0.110 sec   19042 obs/sec     4         4             1352       0.150642         0.0786731           0.904658       0.996911        0.995081           2.56061          0.0236686                        0.175117           0.104175              0.868609         0.993625          0.99069              2.69444            0.0309278\n",
       "    2025-05-26 14:48:41  0.142 sec   17422 obs/sec     5         5             1690       0.140411         0.0679485           0.917169       0.997279        0.995727           2.56061          0.0207101                        0.167328           0.0976448             0.880037         0.994536          0.991733             2.69444            0.0309278\n",
       "    2025-05-26 14:48:41  0.167 sec   17634 obs/sec     6         6             2028       0.136413         0.0656268           0.921818       0.997867        0.996593           2.56061          0.0177515                        0.17739            0.11005               0.865176         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:41  0.192 sec   17789 obs/sec     7         7             2366       0.126075         0.0565443           0.93322        0.997977        0.996766           2.56061          0.0177515                        0.153851           0.0798664             0.898582         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:42  0.217 sec   18026 obs/sec     8         8             2704       0.125444         0.0540615           0.933886       0.998198        0.997156           2.56061          0.0177515                        0.167442           0.0949686             0.879873         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:42  0.241 sec   18107 obs/sec     9         9             3042       0.128288         0.056089            0.930854       0.998419        0.997512           2.56061          0.0177515                        0.176155           0.114825              0.867046         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:42  0.269 sec   17789 obs/sec     10        10            3380       0.114993         0.0473662           0.944444       0.998786        0.998095           2.56061          0.0147929                        0.155279           0.0833018             0.896691         0.996357          0.994396             2.69444            0.0206186\n",
       "    2025-05-26 14:48:42  0.278 sec   17604 obs/sec     10        10            3380       0.126075         0.0565443           0.93322        0.997977        0.996766           2.56061          0.0177515                        0.153851           0.0798664             0.898582         0.995902          0.993656             2.69444            0.0309278\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "el-salvador-aid.?                                   1.0                    1.0                  0.026954850111618748\n",
       "duty-free-exports.?                                 0.985133171081543      0.985133171081543    0.026554116966486657\n",
       "crime.?                                             0.9807437062263489     0.9807437062263489   0.026435799599244685\n",
       "synfuels-corporation-cutback.n                      0.9541820287704468     0.9541820287704468   0.02571983356470768\n",
       "synfuels-corporation-cutback.?                      0.9509652853012085     0.9509652853012085   0.025633126726646832\n",
       "superfund-right-to-sue.y                            0.9181176424026489     0.9181176424026489   0.024747723435796183\n",
       "physician-fee-freeze.y                              0.8970591425895691     0.8970591425895691   0.024180094729759065\n",
       "adoption-of-the-budget-resolution.y                 0.8966130614280701     0.8966130614280701   0.02416807067891324\n",
       "mx-missile.y                                        0.8662047386169434     0.8662047386169434   0.023348418895393602\n",
       "mx-missile.n                                        0.8598179221153259     0.8598179221153259   0.023176263213902093\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[20,20,20], nfolds=0, activation=\"tanh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667fd79eade9b6ad",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [100,100,100], cross folds = 0, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "214bfe43859221c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1450\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-134.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-134 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-134 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-134 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-134 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-134 .h2o-table th,\n",
       "#h2o-table-134 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-134 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-134\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2547061</td>\n",
       "<td>0.4300272</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029735</td>\n",
       "<td>0.1094336</td>\n",
       "<td>-0.0006238</td>\n",
       "<td>0.0061659</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0118620</td>\n",
       "<td>0.0123872</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005504</td>\n",
       "<td>0.1009844</td>\n",
       "<td>-0.0004767</td>\n",
       "<td>0.0048597</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0275780</td>\n",
       "<td>0.0531094</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010803</td>\n",
       "<td>0.1005702</td>\n",
       "<td>0.0002810</td>\n",
       "<td>0.0018700</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0044754</td>\n",
       "<td>0.0016040</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0074745</td>\n",
       "<td>0.5535500</td>\n",
       "<td>-0.0000000</td>\n",
       "<td>0.0008556</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.022487782171216938\n",
       "RMSE: 0.14995926837383855\n",
       "LogLoss: 0.07514393643645458\n",
       "Mean Per-Class Error: 0.02486025301559282\n",
       "AUC: 0.9970947337452192\n",
       "AUCPR: 0.9955915684327467\n",
       "Gini: 0.9941894674904383</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-135.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-135 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-135 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-135 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-135 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-135 .h2o-table th,\n",
       "#h2o-table-135 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-135 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-135\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6304233638481587</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>202.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0194</td>\n",
       "<td> (4.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>4.0</td>\n",
       "<td>128.0</td>\n",
       "<td>0.0303</td>\n",
       "<td> (4.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>206.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.0237</td>\n",
       "<td> (8.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-136.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-136 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-136 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-136 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-136 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-136 .h2o-table th,\n",
       "#h2o-table-136 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-136 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-136\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6304234</td>\n",
       "<td>0.9696970</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4040919</td>\n",
       "<td>0.9759760</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9092972</td>\n",
       "<td>0.9758065</td>\n",
       "<td>83.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6304234</td>\n",
       "<td>0.9763314</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998508</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1098580</td>\n",
       "<td>1.0</td>\n",
       "<td>110.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998508</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6304234</td>\n",
       "<td>0.9502795</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4512282</td>\n",
       "<td>0.9708738</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6304234</td>\n",
       "<td>0.9751397</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9998508</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9998508</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000234</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1098580</td>\n",
       "<td>132.0</td>\n",
       "<td>110.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9998508</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9998508</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000234</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1098580</td>\n",
       "<td>1.0</td>\n",
       "<td>110.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-137.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-137 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-137 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-137 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-137 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-137 .h2o-table th,\n",
       "#h2o-table-137 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-137 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-137\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 40.10 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.9996112</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996566</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996566</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0454545</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0454545</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9995227</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995779</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996454</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9994656</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994887</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995884</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9992807</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993554</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995385</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0562130</td>\n",
       "<td>0.9991532</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991833</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994450</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.1439394</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1439394</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1094675</td>\n",
       "<td>0.9986999</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988495</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991553</td>\n",
       "<td>0.1363636</td>\n",
       "<td>0.2803030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2803030</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9970880</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9978407</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987944</td>\n",
       "<td>0.1060606</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2071006</td>\n",
       "<td>0.9953207</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9962067</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9980921</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.5303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5303030</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9784488</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9891395</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9952834</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4444115</td>\n",
       "<td>2.0950413</td>\n",
       "<td>2.4468013</td>\n",
       "<td>0.8181818</td>\n",
       "<td>0.8708755</td>\n",
       "<td>0.9555556</td>\n",
       "<td>0.9648726</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.9772727</td>\n",
       "<td>109.5041322</td>\n",
       "<td>144.6801347</td>\n",
       "<td>0.9481465</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0143764</td>\n",
       "<td>0.2259358</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0882353</td>\n",
       "<td>0.1425472</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7994343</td>\n",
       "<td>0.0227273</td>\n",
       "<td>1.0</td>\n",
       "<td>-77.4064171</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0046140</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0076924</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6668273</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0018768</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029398</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5739956</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0009893</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014369</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.5018956</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0002639</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005321</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4458221</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000234</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001300</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.4009891</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.017322386518148526\n",
       "RMSE: 0.13161453763983874\n",
       "LogLoss: 0.05888400335760787\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9986338797814207\n",
       "AUCPR: 0.9978353761330616\n",
       "Gini: 0.9972677595628414</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-138.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-138 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-138 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-138 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-138 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-138 .h2o-table th,\n",
       "#h2o-table-138 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-138 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-138\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6765892901996935</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>62.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (1.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-139.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-139 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-139 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-139 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-139 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-139 .h2o-table th,\n",
       "#h2o-table-139 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-139 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-139\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.6765893</td>\n",
       "<td>0.9859155</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1318260</td>\n",
       "<td>0.9836066</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6765893</td>\n",
       "<td>0.9943182</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6765893</td>\n",
       "<td>0.9896907</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9992283</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1318260</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9992283</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6765893</td>\n",
       "<td>0.9780293</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.6765893</td>\n",
       "<td>0.9722222</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6765893</td>\n",
       "<td>0.9861111</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9992283</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9992283</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000725</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1318260</td>\n",
       "<td>36.0</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9992283</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9992283</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000725</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1318260</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-140.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-140 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-140 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-140 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-140 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-140 .h2o-table th,\n",
       "#h2o-table-140 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-140 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-140\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.88 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9991562</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992283</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992283</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9990664</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991532</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991908</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9990588</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990588</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991248</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9990483</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991248</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1111111</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9990463</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990463</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991091</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9988332</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9989645</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990368</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9979581</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985654</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988797</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9950839</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9964939</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982832</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9370358</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9754294</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9911906</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.1235612</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.6592370</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9060743</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0092352</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0347463</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7282523</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0037041</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0049837</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6160209</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0020876</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0027979</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5258411</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0009721</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014566</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4645494</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0002615</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005349</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4112144</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000725</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001269</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3688342</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-141.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-141 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-141 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-141 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-141 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-141 .h2o-table th,\n",
       "#h2o-table-141 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-141 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-141\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:45</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:45</td>\n",
       "<td> 0.089 sec</td>\n",
       "<td>4694 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.1499593</td>\n",
       "<td>0.0751439</td>\n",
       "<td>0.9055202</td>\n",
       "<td>0.9970947</td>\n",
       "<td>0.9955916</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1316145</td>\n",
       "<td>0.0588840</td>\n",
       "<td>0.9257804</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:45</td>\n",
       "<td> 0.184 sec</td>\n",
       "<td>4418 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1413837</td>\n",
       "<td>0.0718852</td>\n",
       "<td>0.9160171</td>\n",
       "<td>0.9969476</td>\n",
       "<td>0.9951138</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1409968</td>\n",
       "<td>0.0648132</td>\n",
       "<td>0.9148216</td>\n",
       "<td>0.9981785</td>\n",
       "<td>0.9970529</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.277 sec</td>\n",
       "<td>4351 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1324967</td>\n",
       "<td>0.0600974</td>\n",
       "<td>0.9262432</td>\n",
       "<td>0.9980877</td>\n",
       "<td>0.9968429</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1386852</td>\n",
       "<td>0.0597066</td>\n",
       "<td>0.9175916</td>\n",
       "<td>0.9977231</td>\n",
       "<td>0.9961014</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.376 sec</td>\n",
       "<td>4305 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1257899</td>\n",
       "<td>0.0544589</td>\n",
       "<td>0.9335211</td>\n",
       "<td>0.9979038</td>\n",
       "<td>0.9965739</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1592843</td>\n",
       "<td>0.0947178</td>\n",
       "<td>0.8912932</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9932987</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.476 sec</td>\n",
       "<td>4225 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1372659</td>\n",
       "<td>0.0629276</td>\n",
       "<td>0.9208379</td>\n",
       "<td>0.9982348</td>\n",
       "<td>0.9973312</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1538446</td>\n",
       "<td>0.0802435</td>\n",
       "<td>0.8985912</td>\n",
       "<td>0.9968124</td>\n",
       "<td>0.9943648</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.569 sec</td>\n",
       "<td>4233 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1203671</td>\n",
       "<td>0.0471079</td>\n",
       "<td>0.9391293</td>\n",
       "<td>0.9988600</td>\n",
       "<td>0.9982608</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1574384</td>\n",
       "<td>0.0790773</td>\n",
       "<td>0.8937981</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9976512</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.663 sec</td>\n",
       "<td>4232 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1249248</td>\n",
       "<td>0.0527575</td>\n",
       "<td>0.9344324</td>\n",
       "<td>0.9992277</td>\n",
       "<td>0.9988124</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1413101</td>\n",
       "<td>0.0628661</td>\n",
       "<td>0.9144426</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9959837</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.757 sec</td>\n",
       "<td>4225 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1134005</td>\n",
       "<td>0.0452435</td>\n",
       "<td>0.9459716</td>\n",
       "<td>0.9987129</td>\n",
       "<td>0.9981706</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1682952</td>\n",
       "<td>0.1140999</td>\n",
       "<td>0.8786459</td>\n",
       "<td>0.9954463</td>\n",
       "<td>0.9924168</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.851 sec</td>\n",
       "<td>4225 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1224699</td>\n",
       "<td>0.0504858</td>\n",
       "<td>0.9369840</td>\n",
       "<td>0.9987496</td>\n",
       "<td>0.9980920</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1855953</td>\n",
       "<td>0.1346172</td>\n",
       "<td>0.8524141</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9932987</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.944 sec</td>\n",
       "<td>4225 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1329042</td>\n",
       "<td>0.0589529</td>\n",
       "<td>0.9257887</td>\n",
       "<td>0.9994116</td>\n",
       "<td>0.9990783</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0088757</td>\n",
       "<td>0.1448802</td>\n",
       "<td>0.0744085</td>\n",
       "<td>0.9100649</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9954184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:46</td>\n",
       "<td> 0.961 sec</td>\n",
       "<td>4209 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1499593</td>\n",
       "<td>0.0751439</td>\n",
       "<td>0.9055202</td>\n",
       "<td>0.9970947</td>\n",
       "<td>0.9955916</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1316145</td>\n",
       "<td>0.0588840</td>\n",
       "<td>0.9257804</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-142.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-142 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-142 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-142 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-142 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-142 .h2o-table th,\n",
       "#h2o-table-142 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-142 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-142\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0230330</td></tr>\n",
       "<tr><td>physician-fee-freeze.?</td>\n",
       "<td>0.9854410</td>\n",
       "<td>0.9854410</td>\n",
       "<td>0.0226976</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9835914</td>\n",
       "<td>0.9835914</td>\n",
       "<td>0.0226550</td></tr>\n",
       "<tr><td>religious-groups-in-schools.n</td>\n",
       "<td>0.9777946</td>\n",
       "<td>0.9777946</td>\n",
       "<td>0.0225215</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.?</td>\n",
       "<td>0.9761850</td>\n",
       "<td>0.9761850</td>\n",
       "<td>0.0224844</td></tr>\n",
       "<tr><td>superfund-right-to-sue.n</td>\n",
       "<td>0.9708084</td>\n",
       "<td>0.9708084</td>\n",
       "<td>0.0223606</td></tr>\n",
       "<tr><td>handicapped-infants.y</td>\n",
       "<td>0.9654315</td>\n",
       "<td>0.9654315</td>\n",
       "<td>0.0222368</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.9653418</td>\n",
       "<td>0.9653418</td>\n",
       "<td>0.0222347</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.9554791</td>\n",
       "<td>0.9554791</td>\n",
       "<td>0.0220075</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.y</td>\n",
       "<td>0.9539094</td>\n",
       "<td>0.9539094</td>\n",
       "<td>0.0219714</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1450\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate              rate_rms              momentum    mean_weight             weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  ---------------------  --------------------  ----------  ----------------------  -------------------  -----------------------  ---------------------\n",
       "    1        64       Input    0.0\n",
       "    2        100      Tanh     0.0        0.0   0.0   0.25470612603076914    0.4300272464752197    0.0         0.0029735185033368337   0.10943356156349182  -0.0006237825568776558   0.006165862083435059\n",
       "    3        100      Tanh     0.0        0.0   0.0   0.011861960638593882   0.012387227267026901  0.0         0.0005503674001993204   0.10098439455032349  -0.00047674686738618757  0.004859739914536476\n",
       "    4        100      Tanh     0.0        0.0   0.0   0.027578046414162963   0.053109392523765564  0.0         0.0010802546546707162   0.10057023167610168  0.0002810132091452572    0.0018700412474572659\n",
       "    5        2        Softmax             0.0   0.0   0.0044754409953020515  0.001604023389518261  0.0         -0.0074745364696718756  0.5535500049591064   -5.800481622797449e-18   0.0008556435350328684\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.022487782171216938\n",
       "RMSE: 0.14995926837383855\n",
       "LogLoss: 0.07514393643645458\n",
       "Mean Per-Class Error: 0.02486025301559282\n",
       "AUC: 0.9970947337452192\n",
       "AUCPR: 0.9955915684327467\n",
       "Gini: 0.9941894674904383\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6304233638481587\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    202         4             0.0194   (4.0/206.0)\n",
       "republican  4           128           0.0303   (4.0/132.0)\n",
       "Total       206         132           0.0237   (8.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.630423     0.969697  93\n",
       "max f2                       0.404092     0.975976  99\n",
       "max f0point5                 0.909297     0.975806  83\n",
       "max accuracy                 0.630423     0.976331  93\n",
       "max precision                0.999851     1         0\n",
       "max recall                   0.109858     1         110\n",
       "max specificity              0.999851     1         0\n",
       "max absolute_mcc             0.630423     0.950279  93\n",
       "max min_per_class_accuracy   0.451228     0.970874  96\n",
       "max mean_per_class_accuracy  0.630423     0.97514   93\n",
       "max tns                      0.999851     206       0\n",
       "max fns                      0.999851     131       0\n",
       "max fps                      2.33911e-05  206       269\n",
       "max tps                      0.109858     132       110\n",
       "max tnr                      0.999851     1         0\n",
       "max fnr                      0.999851     0.992424  0\n",
       "max fpr                      2.33911e-05  1         269\n",
       "max tpr                      0.109858     1         110\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 40.10 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0177515                   0.999611           2.56061   2.56061            1                0.999657     1                           0.999657            0.0454545       0.0454545                  156.061   156.061            0.0454545\n",
       "2        0.0207101                   0.999523           2.56061   2.56061            1                0.999578     1                           0.999645            0.00757576      0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.999466           2.56061   2.56061            1                0.999489     1                           0.999588            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.999281           2.56061   2.56061            1                0.999355     1                           0.999538            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.056213                    0.999153           2.56061   2.56061            1                0.999183     1                           0.999445            0.0378788       0.143939                   156.061   156.061            0.143939\n",
       "6        0.109467                    0.9987             2.56061   2.56061            1                0.998849     1                           0.999155            0.136364        0.280303                   156.061   156.061            0.280303\n",
       "7        0.150888                    0.997088           2.56061   2.56061            1                0.997841     1                           0.998794            0.106061        0.386364                   156.061   156.061            0.386364\n",
       "8        0.207101                    0.995321           2.56061   2.56061            1                0.996207     1                           0.998092            0.143939        0.530303                   156.061   156.061            0.530303\n",
       "9        0.301775                    0.978449           2.56061   2.56061            1                0.98914      1                           0.995283            0.242424        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.444412           2.09504   2.4468             0.818182         0.870875     0.955556                    0.964873            0.204545        0.977273                   109.504   144.68             0.948147\n",
       "11       0.5                         0.0143764          0.225936  2                  0.0882353        0.142547     0.781065                    0.799434            0.0227273       1                          -77.4064  100                0.820388\n",
       "12       0.600592                    0.004614           0         1.66502            0                0.00769237   0.650246                    0.666827            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.00187678         0         1.4322             0                0.00293977   0.559322                    0.573996            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    0.000989259        0         1.25185            0                0.00143689   0.488889                    0.501896            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    0.000263884        0         1.11184            0                0.000532141  0.434211                    0.445822            0               1                          -100      11.1842            0.165049\n",
       "16       1                           2.33911e-05        0         1                  0                0.000130046  0.390533                    0.400989            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.017322386518148526\n",
       "RMSE: 0.13161453763983874\n",
       "LogLoss: 0.05888400335760787\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9986338797814207\n",
       "AUCPR: 0.9978353761330616\n",
       "Gini: 0.9972677595628414\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6765892901996935\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    61          0             0        (0.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       62          35            0.0103   (1.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.676589     0.985915  31\n",
       "max f2                       0.131826     0.983607  35\n",
       "max f0point5                 0.676589     0.994318  31\n",
       "max accuracy                 0.676589     0.989691  31\n",
       "max precision                0.999228     1         0\n",
       "max recall                   0.131826     1         35\n",
       "max specificity              0.999228     1         0\n",
       "max absolute_mcc             0.676589     0.978029  31\n",
       "max min_per_class_accuracy   0.676589     0.972222  31\n",
       "max mean_per_class_accuracy  0.676589     0.986111  31\n",
       "max tns                      0.999228     61        0\n",
       "max fns                      0.999228     35        0\n",
       "max fps                      7.25135e-05  61        91\n",
       "max tps                      0.131826     36        35\n",
       "max tnr                      0.999228     1         0\n",
       "max fnr                      0.999228     0.972222  0\n",
       "max fpr                      7.25135e-05  1         91\n",
       "max tpr                      0.131826     1         35\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 36.88 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   0.999156           2.69444  2.69444            1                0.999228     1                           0.999228            0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   0.999066           2.69444  2.69444            1                0.999153     1                           0.999191            0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0412371                   0.999059           2.69444  2.69444            1                0.999059     1                           0.999125            0.0555556       0.111111                   169.444  169.444            0.111111\n",
       "4        0.0412371                   0.999048           0        2.69444            0                0            1                           0.999125            0               0.111111                   -100     169.444            0.111111\n",
       "5        0.0515464                   0.999046           2.69444  2.69444            1                0.999046     1                           0.999109            0.0277778       0.138889                   169.444  169.444            0.138889\n",
       "6        0.103093                    0.998833           2.69444  2.69444            1                0.998965     1                           0.999037            0.138889        0.277778                   169.444  169.444            0.277778\n",
       "7        0.154639                    0.997958           2.69444  2.69444            1                0.998565     1                           0.99888             0.138889        0.416667                   169.444  169.444            0.416667\n",
       "8        0.206186                    0.995084           2.69444  2.69444            1                0.996494     1                           0.998283            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "9        0.298969                    0.937036           2.69444  2.69444            1                0.975429     1                           0.991191            0.25            0.805556                   169.444  169.444            0.805556\n",
       "10       0.402062                    0.123561           1.88611  2.48718            0.7              0.659237     0.923077                    0.906074            0.194444        1                          88.6111  148.718            0.95082\n",
       "11       0.505155                    0.00923515         0        1.97959            0                0.0347463    0.734694                    0.728252            0               1                          -100     97.9592            0.786885\n",
       "12       0.597938                    0.00370408         0        1.67241            0                0.00498373   0.62069                     0.616021            0               1                          -100     67.2414            0.639344\n",
       "13       0.701031                    0.00208763         0        1.42647            0                0.00279789   0.529412                    0.525841            0               1                          -100     42.6471            0.47541\n",
       "14       0.793814                    0.000972122        0        1.25974            0                0.00145662   0.467532                    0.464549            0               1                          -100     25.974             0.327869\n",
       "15       0.896907                    0.00026146         0        1.11494            0                0.000534938  0.413793                    0.411214            0               1                          -100     11.4943            0.163934\n",
       "16       1                           7.25135e-05        0        1                  0                0.000126917  0.371134                    0.368834            0               1                          -100     0                  0\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:45  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:45  0.089 sec   4694 obs/sec      1         1             338        0.149959         0.0751439           0.90552        0.997095        0.995592           2.56061          0.0236686                        0.131615           0.058884              0.92578          0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:48:45  0.184 sec   4418 obs/sec      2         2             676        0.141384         0.0718852           0.916017       0.996948        0.995114           2.56061          0.0207101                        0.140997           0.0648132             0.914822         0.998179          0.997053             2.69444            0.0206186\n",
       "    2025-05-26 14:48:46  0.277 sec   4351 obs/sec      3         3             1014       0.132497         0.0600974           0.926243       0.998088        0.996843           2.56061          0.0147929                        0.138685           0.0597066             0.917592         0.997723          0.996101             2.69444            0.0206186\n",
       "    2025-05-26 14:48:46  0.376 sec   4305 obs/sec      4         4             1352       0.12579          0.0544589           0.933521       0.997904        0.996574           2.56061          0.0177515                        0.159284           0.0947178             0.891293         0.995902          0.993299             2.69444            0.0206186\n",
       "    2025-05-26 14:48:46  0.476 sec   4225 obs/sec      5         5             1690       0.137266         0.0629276           0.920838       0.998235        0.997331           2.56061          0.0207101                        0.153845           0.0802435             0.898591         0.996812          0.994365             2.69444            0.0206186\n",
       "    2025-05-26 14:48:46  0.569 sec   4233 obs/sec      6         6             2028       0.120367         0.0471079           0.939129       0.99886         0.998261           2.56061          0.0177515                        0.157438           0.0790773             0.893798         0.998634          0.997651             2.69444            0.0103093\n",
       "    2025-05-26 14:48:46  0.663 sec   4232 obs/sec      7         7             2366       0.124925         0.0527575           0.934432       0.999228        0.998812           2.56061          0.0147929                        0.14131            0.0628661             0.914443         0.997268          0.995984             2.69444            0.0103093\n",
       "    2025-05-26 14:48:46  0.757 sec   4225 obs/sec      8         8             2704       0.1134           0.0452435           0.945972       0.998713        0.998171           2.56061          0.0147929                        0.168295           0.1141                0.878646         0.995446          0.992417             2.69444            0.0206186\n",
       "    2025-05-26 14:48:46  0.851 sec   4225 obs/sec      9         9             3042       0.12247          0.0504858           0.936984       0.99875         0.998092           2.56061          0.0177515                        0.185595           0.134617              0.852414         0.995902          0.993299             2.69444            0.0206186\n",
       "    2025-05-26 14:48:46  0.944 sec   4225 obs/sec      10        10            3380       0.132904         0.0589529           0.925789       0.999412        0.999078           2.56061          0.00887574                       0.14488            0.0744085             0.910065         0.997268          0.995418             2.69444            0.0206186\n",
       "    2025-05-26 14:48:46  0.961 sec   4209 obs/sec      10        10            3380       0.149959         0.0751439           0.90552        0.997095        0.995592           2.56061          0.0236686                        0.131615           0.058884              0.92578          0.998634          0.997835             2.69444            0.0103093\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.023032976618573266\n",
       "physician-fee-freeze.?                              0.9854409694671631     0.9854409694671631   0.02269763880872134\n",
       "synfuels-corporation-cutback.n                      0.9835914373397827     0.9835914373397827   0.02265503857847609\n",
       "religious-groups-in-schools.n                       0.9777945876121521     0.9777945876121521   0.02252151987423819\n",
       "adoption-of-the-budget-resolution.?                 0.9761850237846375     0.9761850237846375   0.022484446828232942\n",
       "superfund-right-to-sue.n                            0.9708083868026733     0.9708083868026733   0.022360606874340806\n",
       "handicapped-infants.y                               0.9654315114021301     0.9654315114021301   0.022236761428959115\n",
       "aid-to-nicaraguan-contras.y                         0.9653418064117432     0.9653418064117432   0.022234695256012963\n",
       "duty-free-exports.?                                 0.955479085445404      0.955479085445404    0.02200752743459976\n",
       "export-administration-act-south-africa.y            0.9539093971252441     0.9539093971252441   0.02197137284022307\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[100,100,100], nfolds=0, activation=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b27f60fd101493",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [5,5,5], cross folds = 5, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "791aa0b8d1b5e38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1473\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-143.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-143 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-143 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-143 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-143 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-143 .h2o-table th,\n",
       "#h2o-table-143 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-143 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-143\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2523985</td>\n",
       "<td>0.4311669</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0150976</td>\n",
       "<td>0.1779892</td>\n",
       "<td>-0.0010596</td>\n",
       "<td>0.1225944</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0019809</td>\n",
       "<td>0.0007254</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0625058</td>\n",
       "<td>0.4883827</td>\n",
       "<td>0.0678760</td>\n",
       "<td>0.0309350</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0110674</td>\n",
       "<td>0.0131454</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1716897</td>\n",
       "<td>0.3957357</td>\n",
       "<td>0.0577567</td>\n",
       "<td>0.0293457</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029493</td>\n",
       "<td>0.0004861</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6811196</td>\n",
       "<td>1.0491529</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0905948</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01498420270229417\n",
       "RMSE: 0.12240997795234737\n",
       "LogLoss: 0.06761104157752912\n",
       "Mean Per-Class Error: 0.013496616651956457\n",
       "AUC: 0.9958811415122095\n",
       "AUCPR: 0.9943769422396921\n",
       "Gini: 0.991762283024419</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-144.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-144 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-144 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-144 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-144 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-144 .h2o-table th,\n",
       "#h2o-table-144 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-144 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-144\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4126378161683046</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>202.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0194</td>\n",
       "<td> (4.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>203.0</td>\n",
       "<td>135.0</td>\n",
       "<td>0.0148</td>\n",
       "<td> (5.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-145.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-145 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-145 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-145 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-145 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-145 .h2o-table th,\n",
       "#h2o-table-145 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-145 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-145\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9812734</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9879336</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7504512</td>\n",
       "<td>0.9827044</td>\n",
       "<td>87.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4689879</td>\n",
       "<td>0.9852071</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9948774</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0051177</td>\n",
       "<td>1.0</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9948774</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9692181</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4689879</td>\n",
       "<td>0.9848485</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9865034</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9948774</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9948774</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0023228</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0051177</td>\n",
       "<td>132.0</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9948774</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9948774</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0023228</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0051177</td>\n",
       "<td>1.0</td>\n",
       "<td>157.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-146.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-146 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-146 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-146 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-146 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-146 .h2o-table th,\n",
       "#h2o-table-146 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-146 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-146\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9940103</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943581</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943581</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9936174</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937851</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9941125</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.9929642</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930865</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936850</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0909091</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0909091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9928430</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928736</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935691</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9926368</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927845</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9934306</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9908788</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9916871</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925589</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9874873</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9896747</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9915975</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9821893</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9847686</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9898902</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3047337</td>\n",
       "<td>0.9619203</td>\n",
       "<td>2.4874459</td>\n",
       "<td>2.5357458</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9753460</td>\n",
       "<td>0.9902913</td>\n",
       "<td>0.9849480</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>148.7445887</td>\n",
       "<td>153.5745808</td>\n",
       "<td>0.7678729</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4098200</td>\n",
       "<td>2.3205492</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.90625</td>\n",
       "<td>0.7836350</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9372294</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9924242</td>\n",
       "<td>132.0549242</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0081417</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0588599</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7605160</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6035503</td>\n",
       "<td>0.0045911</td>\n",
       "<td>0.0731602</td>\n",
       "<td>1.6568627</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0057996</td>\n",
       "<td>0.6470588</td>\n",
       "<td>0.6310304</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.6839827</td>\n",
       "<td>65.6862745</td>\n",
       "<td>0.6504854</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0038542</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042049</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5460371</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8047337</td>\n",
       "<td>0.0031851</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2426471</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0034794</td>\n",
       "<td>0.4852941</td>\n",
       "<td>0.4742280</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.2647059</td>\n",
       "<td>0.3203883</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0028688</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0030717</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4246326</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0023228</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026798</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3821876</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.01453753366980719\n",
       "RMSE: 0.12057169514362477\n",
       "LogLoss: 0.0555894978715649\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-147.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-147 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-147 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-147 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-147 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-147 .h2o-table th,\n",
       "#h2o-table-147 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-147 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-147\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5951267160204192</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>62.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (1.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-148.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-148 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-148 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-148 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-148 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-148 .h2o-table th,\n",
       "#h2o-table-148 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-148 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-148\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9859155</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0974078</td>\n",
       "<td>0.9890110</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9943182</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9896907</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0974078</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9780293</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9722222</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9861111</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9946142</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9946142</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0024439</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0974078</td>\n",
       "<td>36.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9946142</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0024439</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0974078</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-149.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-149 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-149 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-149 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-149 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-149 .h2o-table th,\n",
       "#h2o-table-149 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-149 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-149\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.27 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9930307</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9946142</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9928741</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929647</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937895</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9928094</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928662</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9934817</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9924843</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928017</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933117</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9920826</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924239</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931341</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9913939</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9918919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925130</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9902192</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9909260</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919840</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9876434</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9885179</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9911175</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9083470</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9784442</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9871844</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0444293</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.5249142</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.8686536</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0072823</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0147291</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.6943833</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0049817</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0055901</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5875016</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0040196</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0045396</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5017719</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0032802</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0036281</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4435473</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0030136</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0031589</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3929279</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0024439</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026538</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3526935</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.03209160930097024\n",
       "RMSE: 0.17914131098373218\n",
       "LogLoss: 0.12072624980568418\n",
       "Mean Per-Class Error: 0.03048690791409238\n",
       "AUC: 0.9883789349808767\n",
       "AUCPR: 0.9789723346329348\n",
       "Gini: 0.9767578699617534</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-150.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-150 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-150 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-150 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-150 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-150 .h2o-table th,\n",
       "#h2o-table-150 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-150 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-150\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2740680998715461</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>195.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0534</td>\n",
       "<td> (11.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>196.0</td>\n",
       "<td>142.0</td>\n",
       "<td>0.0355</td>\n",
       "<td> (12.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-151.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-151 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-151 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-151 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-151 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-151 .h2o-table th,\n",
       "#h2o-table-151 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-151 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-151\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.2740681</td>\n",
       "<td>0.9562044</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2740681</td>\n",
       "<td>0.9776119</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7026211</td>\n",
       "<td>0.953125</td>\n",
       "<td>114.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2740681</td>\n",
       "<td>0.9644970</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9921755</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0076251</td>\n",
       "<td>1.0</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9921755</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2740681</td>\n",
       "<td>0.9281669</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5002883</td>\n",
       "<td>0.9563107</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2740681</td>\n",
       "<td>0.9695131</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9921755</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9921755</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0030079</td>\n",
       "<td>206.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0076251</td>\n",
       "<td>132.0</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9921755</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9921755</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0030079</td>\n",
       "<td>1.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0076251</td>\n",
       "<td>1.0</td>\n",
       "<td>192.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-152.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-152 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-152 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-152 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-152 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-152 .h2o-table th,\n",
       "#h2o-table-152 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-152 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-152\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.12 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9915962</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9918192</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9918192</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9906873</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9912587</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9915790</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9900150</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9903021</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9911147</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9895503</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9897305</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9908181</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9892955</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9893788</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9905641</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9838539</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9868609</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9887125</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9811234</td>\n",
       "<td>2.4099822</td>\n",
       "<td>2.5103981</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9825814</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9866688</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.3787879</td>\n",
       "<td>140.9982175</td>\n",
       "<td>151.0398099</td>\n",
       "<td>0.3739335</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9781857</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5229501</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9797169</td>\n",
       "<td>0.9852941</td>\n",
       "<td>0.9849308</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5075758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>152.2950089</td>\n",
       "<td>0.5027214</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9612572</td>\n",
       "<td>2.4099822</td>\n",
       "<td>2.4852941</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9730710</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9809775</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.75</td>\n",
       "<td>140.9982175</td>\n",
       "<td>148.5294118</td>\n",
       "<td>0.7354369</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.5093001</td>\n",
       "<td>2.0950413</td>\n",
       "<td>2.3898990</td>\n",
       "<td>0.8181818</td>\n",
       "<td>0.8076916</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.9386188</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.9545455</td>\n",
       "<td>109.5041322</td>\n",
       "<td>138.9898990</td>\n",
       "<td>0.9108561</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0154509</td>\n",
       "<td>0.3765597</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.1470588</td>\n",
       "<td>0.1311159</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7761626</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-62.3440285</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0079166</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6524108</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0102038</td>\n",
       "<td>0.6453202</td>\n",
       "<td>0.6478739</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>65.2410808</td>\n",
       "<td>0.6429097</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0062173</td>\n",
       "<td>0.0775941</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0069913</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5582590</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.2405877</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0050137</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0056499</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4886711</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0040992</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0044711</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4345172</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0030079</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0036129</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3911718</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-153.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-153 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-153 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-153 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-153 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-153 .h2o-table th,\n",
       "#h2o-table-153 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-153 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-153\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9786116</td>\n",
       "<td>0.0261821</td>\n",
       "<td>0.984127</td>\n",
       "<td>0.9367089</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9904728</td>\n",
       "<td>0.0114096</td>\n",
       "<td>0.9883721</td>\n",
       "<td>0.9722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9917695</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0213884</td>\n",
       "<td>0.0261821</td>\n",
       "<td>0.0158730</td>\n",
       "<td>0.0632911</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.6</td>\n",
       "<td>2.0736442</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9634106</td>\n",
       "<td>0.0379299</td>\n",
       "<td>0.9615384</td>\n",
       "<td>0.9114583</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9440559</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9746457</td>\n",
       "<td>0.0278417</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9333333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9642857</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9863569</td>\n",
       "<td>0.0179691</td>\n",
       "<td>0.990099</td>\n",
       "<td>0.9562842</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9854015</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6260316</td>\n",
       "<td>0.3718952</td>\n",
       "<td>3.15</td>\n",
       "<td>2.1944444</td>\n",
       "<td>2.357143</td>\n",
       "<td>2.7619047</td>\n",
       "<td>2.6666667</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9567024</td>\n",
       "<td>0.0513207</td>\n",
       "<td>0.9644856</td>\n",
       "<td>0.8758109</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9432153</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9811498</td>\n",
       "<td>0.0250031</td>\n",
       "<td>0.9883721</td>\n",
       "<td>0.9395995</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9777778</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0188501</td>\n",
       "<td>0.0250031</td>\n",
       "<td>0.0116279</td>\n",
       "<td>0.0604005</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0222222</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0297601</td>\n",
       "<td>0.0255934</td>\n",
       "<td>0.0257163</td>\n",
       "<td>0.0675469</td>\n",
       "<td>0.0121625</td>\n",
       "<td>0.0025056</td>\n",
       "<td>0.0408692</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9850143</td>\n",
       "<td>0.0152949</td>\n",
       "<td>0.9676687</td>\n",
       "<td>0.9714206</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859821</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9561703</td>\n",
       "<td>0.0445477</td>\n",
       "<td>0.9523810</td>\n",
       "<td>0.8974359</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9310345</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8747949</td>\n",
       "<td>0.1035246</td>\n",
       "<td>0.8813164</td>\n",
       "<td>0.7276741</td>\n",
       "<td>0.9502069</td>\n",
       "<td>0.9891522</td>\n",
       "<td>0.8256246</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9944444</td>\n",
       "<td>0.0124226</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1565523</td>\n",
       "<td>0.0810206</td>\n",
       "<td>0.1603629</td>\n",
       "<td>0.2598979</td>\n",
       "<td>0.1102837</td>\n",
       "<td>0.0500555</td>\n",
       "<td>0.2021614</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9678553</td>\n",
       "<td>0.0387397</td>\n",
       "<td>0.9767442</td>\n",
       "<td>0.9069768</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9555556</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-154.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-154 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-154 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-154 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-154 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-154 .h2o-table th,\n",
       "#h2o-table-154 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-154 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-154\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:50</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:50</td>\n",
       "<td> 0.924 sec</td>\n",
       "<td>112666 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2109433</td>\n",
       "<td>0.1634058</td>\n",
       "<td>0.8130508</td>\n",
       "<td>0.9817961</td>\n",
       "<td>0.9628444</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0532544</td>\n",
       "<td>0.2219103</td>\n",
       "<td>0.1685375</td>\n",
       "<td>0.7890079</td>\n",
       "<td>0.9886157</td>\n",
       "<td>0.9810854</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:50</td>\n",
       "<td> 0.949 sec</td>\n",
       "<td>35578 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1843473</td>\n",
       "<td>0.1296516</td>\n",
       "<td>0.8572205</td>\n",
       "<td>0.9881951</td>\n",
       "<td>0.9785739</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.1915001</td>\n",
       "<td>0.1243378</td>\n",
       "<td>0.8428735</td>\n",
       "<td>0.9927140</td>\n",
       "<td>0.9875940</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:50</td>\n",
       "<td> 0.975 sec</td>\n",
       "<td>31687 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1658221</td>\n",
       "<td>0.1089020</td>\n",
       "<td>0.8844747</td>\n",
       "<td>0.9906222</td>\n",
       "<td>0.9831777</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.1757758</td>\n",
       "<td>0.1026639</td>\n",
       "<td>0.8676179</td>\n",
       "<td>0.9949909</td>\n",
       "<td>0.9914792</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:50</td>\n",
       "<td> 0.994 sec</td>\n",
       "<td>30044 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1570520</td>\n",
       "<td>0.0992638</td>\n",
       "<td>0.8963715</td>\n",
       "<td>0.9918358</td>\n",
       "<td>0.9857957</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1555667</td>\n",
       "<td>0.0836351</td>\n",
       "<td>0.8963082</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9930641</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:50</td>\n",
       "<td> 1.014 sec</td>\n",
       "<td>28644 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1464146</td>\n",
       "<td>0.0894230</td>\n",
       "<td>0.9099340</td>\n",
       "<td>0.9931230</td>\n",
       "<td>0.9884188</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1453706</td>\n",
       "<td>0.0763246</td>\n",
       "<td>0.9094551</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:51</td>\n",
       "<td> 1.034 sec</td>\n",
       "<td>28166 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1393621</td>\n",
       "<td>0.0830717</td>\n",
       "<td>0.9184016</td>\n",
       "<td>0.9938217</td>\n",
       "<td>0.9899479</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1360821</td>\n",
       "<td>0.0686306</td>\n",
       "<td>0.9206562</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:51</td>\n",
       "<td> 1.055 sec</td>\n",
       "<td>27195 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1376766</td>\n",
       "<td>0.0800181</td>\n",
       "<td>0.9203634</td>\n",
       "<td>0.9942630</td>\n",
       "<td>0.9909781</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1258424</td>\n",
       "<td>0.0590951</td>\n",
       "<td>0.9321477</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:51</td>\n",
       "<td> 1.075 sec</td>\n",
       "<td>26772 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1322235</td>\n",
       "<td>0.0754169</td>\n",
       "<td>0.9265470</td>\n",
       "<td>0.9948147</td>\n",
       "<td>0.9922661</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1217894</td>\n",
       "<td>0.0557746</td>\n",
       "<td>0.9364478</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:51</td>\n",
       "<td> 1.096 sec</td>\n",
       "<td>26224 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1265907</td>\n",
       "<td>0.0716402</td>\n",
       "<td>0.9326720</td>\n",
       "<td>0.9950353</td>\n",
       "<td>0.9927280</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1226970</td>\n",
       "<td>0.0578272</td>\n",
       "<td>0.9354971</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:51</td>\n",
       "<td> 1.116 sec</td>\n",
       "<td>26000 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1244544</td>\n",
       "<td>0.0691636</td>\n",
       "<td>0.9349252</td>\n",
       "<td>0.9956605</td>\n",
       "<td>0.9940361</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1178598</td>\n",
       "<td>0.0523910</td>\n",
       "<td>0.9404828</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:51</td>\n",
       "<td> 1.138 sec</td>\n",
       "<td>25641 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1224100</td>\n",
       "<td>0.0676110</td>\n",
       "<td>0.9370456</td>\n",
       "<td>0.9958811</td>\n",
       "<td>0.9943769</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1205717</td>\n",
       "<td>0.0555895</td>\n",
       "<td>0.9377124</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-155.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-155 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-155 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-155 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-155 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-155 .h2o-table th,\n",
       "#h2o-table-155 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-155 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-155\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0478782</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.7252435</td>\n",
       "<td>0.7252435</td>\n",
       "<td>0.0347233</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.7016298</td>\n",
       "<td>0.7016298</td>\n",
       "<td>0.0335928</td></tr>\n",
       "<tr><td>el-salvador-aid.?</td>\n",
       "<td>0.6368201</td>\n",
       "<td>0.6368201</td>\n",
       "<td>0.0304898</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.6236753</td>\n",
       "<td>0.6236753</td>\n",
       "<td>0.0298604</td></tr>\n",
       "<tr><td>water-project-cost-sharing.y</td>\n",
       "<td>0.5995092</td>\n",
       "<td>0.5995092</td>\n",
       "<td>0.0287034</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.n</td>\n",
       "<td>0.5956001</td>\n",
       "<td>0.5956001</td>\n",
       "<td>0.0285163</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.5744899</td>\n",
       "<td>0.5744899</td>\n",
       "<td>0.0275055</td></tr>\n",
       "<tr><td>crime.n</td>\n",
       "<td>0.5695922</td>\n",
       "<td>0.5695922</td>\n",
       "<td>0.0272710</td></tr>\n",
       "<tr><td>education-spending.?</td>\n",
       "<td>0.5183975</td>\n",
       "<td>0.5183975</td>\n",
       "<td>0.0248199</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1473\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias              bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ---------------------  --------------------\n",
       "    1        64       Input    0.0\n",
       "    2        5        Tanh     0.0        0.0   0.0   0.25239849831141326    0.4311668872833252      0.0         -0.015097625058115228  0.1779891848564148  -0.001059561762942135  0.12259435653686523\n",
       "    3        5        Tanh     0.0        0.0   0.0   0.001980850868858397   0.000725434860214591    0.0         -0.06250577300786972   0.4883826971054077  0.06787601578286812    0.03093498945236206\n",
       "    4        5        Tanh     0.0        0.0   0.0   0.011067370460368693   0.01314544677734375     0.0         0.17168970016762614    0.3957357406616211  0.05775672508541674    0.029345683753490448\n",
       "    5        2        Softmax             0.0   0.0   0.0029493304900825024  0.00048607157077640295  0.0         1.6811195679008961     1.0491528511047363  9.71445146547012e-17   0.0905948281288147\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01498420270229417\n",
       "RMSE: 0.12240997795234737\n",
       "LogLoss: 0.06761104157752912\n",
       "Mean Per-Class Error: 0.013496616651956457\n",
       "AUC: 0.9958811415122095\n",
       "AUCPR: 0.9943769422396921\n",
       "Gini: 0.991762283024419\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4126378161683046\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    202         4             0.0194   (4.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       203         135           0.0148   (5.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.412638     0.981273  96\n",
       "max f2                       0.412638     0.987934  96\n",
       "max f0point5                 0.750451     0.982704  87\n",
       "max accuracy                 0.468988     0.985207  94\n",
       "max precision                0.994877     1         0\n",
       "max recall                   0.00511771   1         157\n",
       "max specificity              0.994877     1         0\n",
       "max absolute_mcc             0.412638     0.969218  96\n",
       "max min_per_class_accuracy   0.468988     0.984848  94\n",
       "max mean_per_class_accuracy  0.412638     0.986503  96\n",
       "max tns                      0.994877     206       0\n",
       "max fns                      0.994877     131       0\n",
       "max fps                      0.00232277   206       269\n",
       "max tps                      0.00511771   132       157\n",
       "max tnr                      0.994877     1         0\n",
       "max fnr                      0.994877     0.992424  0\n",
       "max fpr                      0.00232277   1         269\n",
       "max tpr                      0.00511771   1         157\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0118343                   0.99401            2.56061    2.56061            1                0.994358    1                           0.994358            0.030303        0.030303                   156.061  156.061            0.030303\n",
       "2        0.0207101                   0.993617           2.56061    2.56061            1                0.993785    1                           0.994113            0.0227273       0.0530303                  156.061  156.061            0.0530303\n",
       "3        0.035503                    0.992964           2.56061    2.56061            1                0.993087    1                           0.993685            0.0378788       0.0909091                  156.061  156.061            0.0909091\n",
       "4        0.0414201                   0.992843           2.56061    2.56061            1                0.992874    1                           0.993569            0.0151515       0.106061                   156.061  156.061            0.106061\n",
       "5        0.0502959                   0.992637           2.56061    2.56061            1                0.992784    1                           0.993431            0.0227273       0.128788                   156.061  156.061            0.128788\n",
       "6        0.100592                    0.990879           2.56061    2.56061            1                0.991687    1                           0.992559            0.128788        0.257576                   156.061  156.061            0.257576\n",
       "7        0.150888                    0.987487           2.56061    2.56061            1                0.989675    1                           0.991597            0.128788        0.386364                   156.061  156.061            0.386364\n",
       "8        0.201183                    0.982189           2.56061    2.56061            1                0.984769    1                           0.98989             0.128788        0.515152                   156.061  156.061            0.515152\n",
       "9        0.304734                    0.96192            2.48745    2.53575            0.971429         0.975346    0.990291                    0.984948            0.257576        0.772727                   148.745  153.575            0.767873\n",
       "10       0.399408                    0.40982            2.32055    2.48474            0.90625          0.783635    0.97037                     0.937229            0.219697        0.992424                   132.055  148.474            0.973007\n",
       "11       0.5                         0.00814168         0          1.98485            0                0.0588599   0.775148                    0.760516            0               0.992424                   -100     98.4848            0.807958\n",
       "12       0.60355                     0.00459109         0.0731602  1.65686            0.0285714        0.00579964  0.647059                    0.63103             0.00757576      1                          -92.684  65.6863            0.650485\n",
       "13       0.698225                    0.00385417         0          1.4322             0                0.00420491  0.559322                    0.546037            0               1                          -100     43.2203            0.495146\n",
       "14       0.804734                    0.00318513         0          1.24265            0                0.00347941  0.485294                    0.474228            0               1                          -100     24.2647            0.320388\n",
       "15       0.899408                    0.0028688          0          1.11184            0                0.00307169  0.434211                    0.424633            0               1                          -100     11.1842            0.165049\n",
       "16       1                           0.00232277         0          1                  0                0.0026798   0.390533                    0.382188            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.01453753366980719\n",
       "RMSE: 0.12057169514362477\n",
       "LogLoss: 0.0555894978715649\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5951267160204192\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    61          0             0        (0.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       62          35            0.0103   (1.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.595127     0.985915  31\n",
       "max f2                       0.0974078    0.989011  34\n",
       "max f0point5                 0.595127     0.994318  31\n",
       "max accuracy                 0.595127     0.989691  31\n",
       "max precision                0.994614     1         0\n",
       "max recall                   0.0974078    1         34\n",
       "max specificity              0.994614     1         0\n",
       "max absolute_mcc             0.595127     0.978029  31\n",
       "max min_per_class_accuracy   0.595127     0.972222  31\n",
       "max mean_per_class_accuracy  0.595127     0.986111  31\n",
       "max tns                      0.994614     61        0\n",
       "max fns                      0.994614     35        0\n",
       "max fps                      0.00244387   61        91\n",
       "max tps                      0.0974078    36        34\n",
       "max tnr                      0.994614     1         0\n",
       "max fnr                      0.994614     0.972222  0\n",
       "max fpr                      0.00244387   1         91\n",
       "max tpr                      0.0974078    1         34\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.27 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   0.993031           2.69444  2.69444            1                0.994614    1                           0.994614            0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   0.992874           2.69444  2.69444            1                0.992965    1                           0.993789            0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0309278                   0.992809           2.69444  2.69444            1                0.992866    1                           0.993482            0.0277778       0.0833333                  169.444  169.444            0.0833333\n",
       "4        0.0412371                   0.992484           2.69444  2.69444            1                0.992802    1                           0.993312            0.0277778       0.111111                   169.444  169.444            0.111111\n",
       "5        0.0515464                   0.992083           2.69444  2.69444            1                0.992424    1                           0.993134            0.0277778       0.138889                   169.444  169.444            0.138889\n",
       "6        0.103093                    0.991394           2.69444  2.69444            1                0.991892    1                           0.992513            0.138889        0.277778                   169.444  169.444            0.277778\n",
       "7        0.154639                    0.990219           2.69444  2.69444            1                0.990926    1                           0.991984            0.138889        0.416667                   169.444  169.444            0.416667\n",
       "8        0.206186                    0.987643           2.69444  2.69444            1                0.988518    1                           0.991117            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "9        0.298969                    0.908347           2.69444  2.69444            1                0.978444    1                           0.987184            0.25            0.805556                   169.444  169.444            0.805556\n",
       "10       0.402062                    0.0444293          1.88611  2.48718            0.7              0.524914    0.923077                    0.868654            0.194444        1                          88.6111  148.718            0.95082\n",
       "11       0.505155                    0.00728231         0        1.97959            0                0.0147291   0.734694                    0.694383            0               1                          -100     97.9592            0.786885\n",
       "12       0.597938                    0.00498166         0        1.67241            0                0.00559014  0.62069                     0.587502            0               1                          -100     67.2414            0.639344\n",
       "13       0.701031                    0.0040196          0        1.42647            0                0.00453963  0.529412                    0.501772            0               1                          -100     42.6471            0.47541\n",
       "14       0.793814                    0.00328021         0        1.25974            0                0.00362812  0.467532                    0.443547            0               1                          -100     25.974             0.327869\n",
       "15       0.896907                    0.00301362         0        1.11494            0                0.00315895  0.413793                    0.392928            0               1                          -100     11.4943            0.163934\n",
       "16       1                           0.00244387         0        1                  0                0.00265384  0.371134                    0.352693            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.03209160930097024\n",
       "RMSE: 0.17914131098373218\n",
       "LogLoss: 0.12072624980568418\n",
       "Mean Per-Class Error: 0.03048690791409238\n",
       "AUC: 0.9883789349808767\n",
       "AUCPR: 0.9789723346329348\n",
       "Gini: 0.9767578699617534\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.2740680998715461\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    195         11            0.0534   (11.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       196         142           0.0355   (12.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.274068     0.956204  129\n",
       "max f2                       0.274068     0.977612  129\n",
       "max f0point5                 0.702621     0.953125  114\n",
       "max accuracy                 0.274068     0.964497  129\n",
       "max precision                0.992176     1         0\n",
       "max recall                   0.00762514   1         192\n",
       "max specificity              0.992176     1         0\n",
       "max absolute_mcc             0.274068     0.928167  129\n",
       "max min_per_class_accuracy   0.500288     0.956311  123\n",
       "max mean_per_class_accuracy  0.274068     0.969513  129\n",
       "max tns                      0.992176     206       0\n",
       "max fns                      0.992176     131       0\n",
       "max fps                      0.00300792   206       317\n",
       "max tps                      0.00762514   132       192\n",
       "max tnr                      0.992176     1         0\n",
       "max fnr                      0.992176     0.992424  0\n",
       "max fpr                      0.00300792   1         317\n",
       "max tpr                      0.00762514   1         192\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.12 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.991596           2.56061    2.56061            1                0.991819    1                           0.991819            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.990687           2.56061    2.56061            1                0.991259    1                           0.991579            0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.990015           2.56061    2.56061            1                0.990302    1                           0.991115            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.98955            2.56061    2.56061            1                0.98973     1                           0.990818            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.989296           2.56061    2.56061            1                0.989379    1                           0.990564            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.983854           2.56061    2.56061            1                0.986861    1                           0.988713            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.981123           2.40998    2.5104             0.941176         0.982581    0.980392                    0.986669            0.121212        0.378788                   140.998   151.04             0.373934\n",
       "8        0.201183                    0.978186           2.56061    2.52295            1                0.979717    0.985294                    0.984931            0.128788        0.507576                   156.061   152.295            0.502721\n",
       "9        0.301775                    0.961257           2.40998    2.48529            0.941176         0.973071    0.970588                    0.980978            0.242424        0.75                       140.998   148.529            0.735437\n",
       "10       0.399408                    0.5093             2.09504    2.3899             0.818182         0.807692    0.933333                    0.938619            0.204545        0.954545                   109.504   138.99             0.910856\n",
       "11       0.5                         0.0154509          0.37656    1.98485            0.147059         0.131116    0.775148                    0.776163            0.0378788       0.992424                   -62.344   98.4848            0.807958\n",
       "12       0.600592                    0.00791664         0          1.65241            0                0.0102038   0.64532                     0.647874            0               0.992424                   -100      65.2411            0.64291\n",
       "13       0.698225                    0.00621728         0.0775941  1.4322             0.030303         0.00699129  0.559322                    0.558259            0.00757576      1                          -92.2406  43.2203            0.495146\n",
       "14       0.798817                    0.00501369         0          1.25185            0                0.00564985  0.488889                    0.488671            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    0.00409916         0          1.11184            0                0.00447113  0.434211                    0.434517            0               1                          -100      11.1842            0.165049\n",
       "16       1                           0.00300792         0          1                  0                0.00361292  0.390533                    0.391172            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.9786116    0.026182106  0.984127      0.93670887    1.0           1.0           0.9722222\n",
       "aic                      nan          0.0          nan           nan           nan           nan           nan\n",
       "auc                      0.9904728    0.01140957   0.9883721     0.9722222     1.0           1.0           0.99176955\n",
       "err                      0.021388387  0.026182106  0.015873017   0.06329114    0.0           0.0           0.027777778\n",
       "err_count                1.6          2.0736442    1.0           5.0           0.0           0.0           2.0\n",
       "f0point5                 0.96341056   0.037929915  0.96153843    0.9114583     1.0           1.0           0.9440559\n",
       "f1                       0.97464573   0.027841747  0.9756098     0.93333334    1.0           1.0           0.96428573\n",
       "f2                       0.9863569    0.017969104  0.990099      0.95628417    1.0           1.0           0.98540145\n",
       "lift_top_group           2.6260316    0.37189522   3.15          2.1944444     2.357143      2.7619047     2.6666667\n",
       "loglikelihood            nan          0.0          nan           nan           nan           nan           nan\n",
       "---                      ---          ---          ---           ---           ---           ---           ---\n",
       "mcc                      0.95670235   0.05132075   0.96448565    0.8758109     1.0           1.0           0.9432153\n",
       "mean_per_class_accuracy  0.98114985   0.025003105  0.9883721     0.93959945    1.0           1.0           0.9777778\n",
       "mean_per_class_error     0.01885013   0.025003105  0.011627907   0.060400516   0.0           0.0           0.022222223\n",
       "mse                      0.029760096  0.02559344   0.025716264   0.06754694    0.012162499   0.0025055553  0.040869217\n",
       "pr_auc                   0.98501426   0.015294936  0.96766865    0.9714206     1.0           1.0           0.98598206\n",
       "precision                0.95617026   0.04454768   0.95238096    0.8974359     1.0           1.0           0.9310345\n",
       "r2                       0.8747949    0.10352457   0.8813164     0.7276741     0.95020694    0.98915225    0.82562464\n",
       "recall                   0.99444443   0.0124226    1.0           0.9722222     1.0           1.0           1.0\n",
       "rmse                     0.1565523    0.08102064   0.16036291    0.25989795    0.11028372    0.050055522   0.20216137\n",
       "specificity              0.9678553    0.038739704  0.9767442     0.90697676    1.0           1.0           0.95555556\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:50  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:50  0.924 sec   112666 obs/sec    1         1             338        0.210943         0.163406            0.813051       0.981796        0.962844           2.56061          0.0532544                        0.22191            0.168537              0.789008         0.988616          0.981085             2.69444            0.0412371\n",
       "    2025-05-26 14:48:50  0.949 sec   35578 obs/sec     2         2             676        0.184347         0.129652            0.857221       0.988195        0.978574           2.56061          0.0414201                        0.1915             0.124338              0.842874         0.992714          0.987594             2.69444            0.0309278\n",
       "    2025-05-26 14:48:50  0.975 sec   31687 obs/sec     3         3             1014       0.165822         0.108902            0.884475       0.990622        0.983178           2.56061          0.0325444                        0.175776           0.102664              0.867618         0.994991          0.991479             2.69444            0.0309278\n",
       "    2025-05-26 14:48:50  0.994 sec   30044 obs/sec     4         4             1352       0.157052         0.0992638           0.896371       0.991836        0.985796           2.56061          0.0236686                        0.155567           0.0836351             0.896308         0.995902          0.993064             2.69444            0.0309278\n",
       "    2025-05-26 14:48:50  1.014 sec   28644 obs/sec     5         5             1690       0.146415         0.089423            0.909934       0.993123        0.988419           2.56061          0.0207101                        0.145371           0.0763246             0.909455         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:51  1.034 sec   28166 obs/sec     6         6             2028       0.139362         0.0830717           0.918402       0.993822        0.989948           2.56061          0.0207101                        0.136082           0.0686306             0.920656         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:51  1.055 sec   27195 obs/sec     7         7             2366       0.137677         0.0800181           0.920363       0.994263        0.990978           2.56061          0.0177515                        0.125842           0.0590951             0.932148         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:48:51  1.075 sec   26772 obs/sec     8         8             2704       0.132223         0.0754169           0.926547       0.994815        0.992266           2.56061          0.0177515                        0.121789           0.0557746             0.936448         0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:48:51  1.096 sec   26224 obs/sec     9         9             3042       0.126591         0.0716402           0.932672       0.995035        0.992728           2.56061          0.0177515                        0.122697           0.0578272             0.935497         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:51  1.116 sec   26000 obs/sec     10        10            3380       0.124454         0.0691636           0.934925       0.99566         0.994036           2.56061          0.0147929                        0.11786            0.052391              0.940483         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:48:51  1.138 sec   25641 obs/sec     11        11            3718       0.12241          0.067611            0.937046       0.995881        0.994377           2.56061          0.0147929                        0.120572           0.0555895             0.937712         0.999089          0.998518             2.69444            0.0103093\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.04787818652837487\n",
       "physician-fee-freeze.n                              0.7252435088157654     0.7252435088157654   0.034723343993574296\n",
       "synfuels-corporation-cutback.n                      0.7016297578811646     0.7016297578811646   0.033592760421692895\n",
       "el-salvador-aid.?                                   0.6368200778961182     0.6368200778961182   0.030489790474524558\n",
       "adoption-of-the-budget-resolution.y                 0.6236753463745117     0.6236753463745117   0.029860444566867678\n",
       "water-project-cost-sharing.y                        0.5995091795921326     0.5995091795921326   0.02870341232598511\n",
       "anti-satellite-test-ban.n                           0.5956000685691833     0.5956000685691833   0.02851625117926822\n",
       "mx-missile.n                                        0.5744898915290833     0.5744898915290833   0.02750553418529529\n",
       "crime.n                                             0.5695921778678894     0.5695921778678894   0.027271040537062082\n",
       "education-spending.?                                0.5183975100517273     0.5183975100517273   0.024819932682101684\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[5,5,5], nfolds=5, activation=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c5d43ac61436ff",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [20,20,20], cross folds = 5, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54d1cf9f9fdc9dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1638\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-156.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-156 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-156 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-156 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-156 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-156 .h2o-table th,\n",
       "#h2o-table-156 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-156 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-156\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2528265</td>\n",
       "<td>0.4309566</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0006878</td>\n",
       "<td>0.1583468</td>\n",
       "<td>-0.0028398</td>\n",
       "<td>0.0332660</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0041718</td>\n",
       "<td>0.0040898</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0050448</td>\n",
       "<td>0.2223840</td>\n",
       "<td>0.0081535</td>\n",
       "<td>0.0276089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0047794</td>\n",
       "<td>0.0039462</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0157751</td>\n",
       "<td>0.2144551</td>\n",
       "<td>0.0048399</td>\n",
       "<td>0.0145661</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0050722</td>\n",
       "<td>0.0019112</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0369950</td>\n",
       "<td>1.1557760</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0100588</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.013591574998182653\n",
       "RMSE: 0.11658291040363786\n",
       "LogLoss: 0.04653735974662889\n",
       "Mean Per-Class Error: 0.01106943218593704\n",
       "AUC: 0.9989702853780523\n",
       "AUCPR: 0.9983648341082199\n",
       "Gini: 0.9979405707561047</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-157.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-157 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-157 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-157 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-157 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-157 .h2o-table th,\n",
       "#h2o-table-157 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-157 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-157\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3079197538244427</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>203.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0146</td>\n",
       "<td> (3.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>204.0</td>\n",
       "<td>134.0</td>\n",
       "<td>0.0118</td>\n",
       "<td> (4.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-158.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-158 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-158 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-158 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-158 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-158 .h2o-table th,\n",
       "#h2o-table-158 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-158 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-158\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9849624</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1789347</td>\n",
       "<td>0.9909910</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3321215</td>\n",
       "<td>0.9848485</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3321215</td>\n",
       "<td>0.9881657</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999801</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1789347</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999801</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9752822</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9854369</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9889306</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999801</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999801</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000033</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1789347</td>\n",
       "<td>132.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999801</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999801</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000033</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1789347</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-159.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-159 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-159 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-159 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-159 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-159 .h2o-table th,\n",
       "#h2o-table-159 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-159 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-159\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.9999394</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999475</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999475</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0378788</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0378788</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9998462</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998827</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999290</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9998155</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998286</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998925</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9997725</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997823</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998631</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9997356</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997399</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998486</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9992784</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995291</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996888</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1568047</td>\n",
       "<td>0.9976363</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985426</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992779</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.4015152</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.4015152</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2071006</td>\n",
       "<td>0.9940715</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9955869</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983815</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5303030</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9700510</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9875674</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9949889</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.2783261</td>\n",
       "<td>2.2502296</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.8787879</td>\n",
       "<td>0.7778914</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9419206</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9924242</td>\n",
       "<td>125.0229568</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0043331</td>\n",
       "<td>0.0753119</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0577081</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7640317</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0006593</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016236</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6363377</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0001915</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003842</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5474120</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0000800</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001240</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4784943</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000289</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000534</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4249844</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000033</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000158</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3822361</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.025036851139801974\n",
       "RMSE: 0.1582303736322517\n",
       "LogLoss: 0.0878856002549917\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9972677595628415\n",
       "AUCPR: 0.9955991765061915\n",
       "Gini: 0.994535519125683</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-160.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-160 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-160 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-160 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-160 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-160 .h2o-table th,\n",
       "#h2o-table-160 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-160 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-160\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1662999056749567</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0164</td>\n",
       "<td> (1.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-161.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-161 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-161 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-161 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-161 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-161 .h2o-table th,\n",
       "#h2o-table-161 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-161 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-161\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0227605</td>\n",
       "<td>0.9782609</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6785613</td>\n",
       "<td>0.9821429</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9793814</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0227605</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9558288</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9779144</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9998623</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9998623</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000023</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0227605</td>\n",
       "<td>36.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9998623</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000023</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0227605</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-162.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-162 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-162 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-162 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-162 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-162 .h2o-table th,\n",
       "#h2o-table-162 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-162 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-162\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.43 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9998369</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998623</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9998129</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998491</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9998109</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998109</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998262</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9997116</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998262</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1388889</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9994207</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996258</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997260</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9987753</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990925</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995148</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9983089</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985800</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992811</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9069151</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9810874</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936348</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0448873</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.4464004</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8533183</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0027758</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0096030</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.6811315</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0006094</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016215</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5756903</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0002673</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003774</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.4910854</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.8041237</td>\n",
       "<td>0.0001040</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2435897</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001625</td>\n",
       "<td>0.4615385</td>\n",
       "<td>0.4281466</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.3589744</td>\n",
       "<td>0.3114754</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000355</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000602</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3838618</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000023</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000160</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3442901</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.034726718350793405\n",
       "RMSE: 0.18635106211340305\n",
       "LogLoss: 0.10936305237150198\n",
       "Mean Per-Class Error: 0.04894822006472492\n",
       "AUC: 0.9933436304795528\n",
       "AUCPR: 0.9901427328719857\n",
       "Gini: 0.9866872609591055</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-163.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-163 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-163 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-163 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-163 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-163 .h2o-table th,\n",
       "#h2o-table-163 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-163 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-163\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7775675858840484</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>203.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0146</td>\n",
       "<td> (3.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>11.0</td>\n",
       "<td>121.0</td>\n",
       "<td>0.0833</td>\n",
       "<td> (11.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>214.0</td>\n",
       "<td>124.0</td>\n",
       "<td>0.0414</td>\n",
       "<td> (14.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-164.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-164 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-164 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-164 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-164 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-164 .h2o-table th,\n",
       "#h2o-table-164 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-164 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-164\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.7775676</td>\n",
       "<td>0.9453125</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1626281</td>\n",
       "<td>0.9643917</td>\n",
       "<td>133.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7775676</td>\n",
       "<td>0.9633758</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7775676</td>\n",
       "<td>0.9585799</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999193</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0408865</td>\n",
       "<td>1.0</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999193</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7775676</td>\n",
       "<td>0.9131860</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3791152</td>\n",
       "<td>0.9545455</td>\n",
       "<td>122.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3722344</td>\n",
       "<td>0.9567888</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999193</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999193</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000112</td>\n",
       "<td>206.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0408865</td>\n",
       "<td>132.0</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999193</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999193</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000112</td>\n",
       "<td>1.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0408865</td>\n",
       "<td>1.0</td>\n",
       "<td>146.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-165.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-165 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-165 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-165 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-165 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-165 .h2o-table th,\n",
       "#h2o-table-165 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-165 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-165\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.07 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9997761</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998473</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998473</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9995614</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996478</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997618</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.9993860</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994503</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996320</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0909091</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0909091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9990839</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991430</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995342</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9987537</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990550</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994778</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9975354</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9982174</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988476</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9954701</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9967363</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981439</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9917646</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9940390</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9971177</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9680020</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9828364</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9923572</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.3778260</td>\n",
       "<td>1.8622590</td>\n",
       "<td>2.3898990</td>\n",
       "<td>0.7272727</td>\n",
       "<td>0.7955639</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.9442522</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.9545455</td>\n",
       "<td>86.2258953</td>\n",
       "<td>138.9898990</td>\n",
       "<td>0.9108561</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0153946</td>\n",
       "<td>0.4518717</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.1269907</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7798327</td>\n",
       "<td>0.0454545</td>\n",
       "<td>1.0</td>\n",
       "<td>-54.8128342</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0022649</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0055426</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6501487</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0008204</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015392</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5594533</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0003897</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005853</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4890773</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001429</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002499</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4344058</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>1.119e-05</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000801</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3907162</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-166.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-166 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-166 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-166 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-166 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-166 .h2o-table th,\n",
       "#h2o-table-166 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-166 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-166\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9667004</td>\n",
       "<td>0.0295498</td>\n",
       "<td>0.9523810</td>\n",
       "<td>0.9240506</td>\n",
       "<td>0.9848485</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9917835</td>\n",
       "<td>0.0090665</td>\n",
       "<td>0.9906977</td>\n",
       "<td>0.9773902</td>\n",
       "<td>0.9990602</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9917695</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0332995</td>\n",
       "<td>0.0295498</td>\n",
       "<td>0.0476191</td>\n",
       "<td>0.0759494</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>2.4</td>\n",
       "<td>2.302173</td>\n",
       "<td>3.0</td>\n",
       "<td>6.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9507173</td>\n",
       "<td>0.0487912</td>\n",
       "<td>0.8928571</td>\n",
       "<td>0.9042553</td>\n",
       "<td>0.9722222</td>\n",
       "<td>1.0</td>\n",
       "<td>0.984252</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9586292</td>\n",
       "<td>0.0341724</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9189189</td>\n",
       "<td>0.9824561</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9615384</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9675394</td>\n",
       "<td>0.0299815</td>\n",
       "<td>0.9708738</td>\n",
       "<td>0.9340659</td>\n",
       "<td>0.9929078</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9398496</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6260316</td>\n",
       "<td>0.3718952</td>\n",
       "<td>3.15</td>\n",
       "<td>2.1944444</td>\n",
       "<td>2.357143</td>\n",
       "<td>2.7619047</td>\n",
       "<td>2.6666667</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9318437</td>\n",
       "<td>0.0594420</td>\n",
       "<td>0.8993875</td>\n",
       "<td>0.8486844</td>\n",
       "<td>0.9695921</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9415545</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9681264</td>\n",
       "<td>0.0282888</td>\n",
       "<td>0.9651163</td>\n",
       "<td>0.9257106</td>\n",
       "<td>0.9868421</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0318736</td>\n",
       "<td>0.0282888</td>\n",
       "<td>0.0348837</td>\n",
       "<td>0.0742894</td>\n",
       "<td>0.0131579</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0370370</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0326161</td>\n",
       "<td>0.0264384</td>\n",
       "<td>0.0383365</td>\n",
       "<td>0.0732584</td>\n",
       "<td>0.0102846</td>\n",
       "<td>0.0078729</td>\n",
       "<td>0.0333279</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9884441</td>\n",
       "<td>0.0109736</td>\n",
       "<td>0.9798607</td>\n",
       "<td>0.9754738</td>\n",
       "<td>0.9987468</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9881394</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9459639</td>\n",
       "<td>0.0605869</td>\n",
       "<td>0.8695652</td>\n",
       "<td>0.8947368</td>\n",
       "<td>0.9655172</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8618662</td>\n",
       "<td>0.1075717</td>\n",
       "<td>0.8230728</td>\n",
       "<td>0.7046475</td>\n",
       "<td>0.9578949</td>\n",
       "<td>0.9659144</td>\n",
       "<td>0.8578011</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9740741</td>\n",
       "<td>0.0360992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9444444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9259259</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1678323</td>\n",
       "<td>0.0745684</td>\n",
       "<td>0.195797</td>\n",
       "<td>0.2706629</td>\n",
       "<td>0.1014131</td>\n",
       "<td>0.0887295</td>\n",
       "<td>0.1825592</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9621787</td>\n",
       "<td>0.0420151</td>\n",
       "<td>0.9302326</td>\n",
       "<td>0.9069768</td>\n",
       "<td>0.9736842</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-167.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-167 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-167 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-167 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-167 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-167 .h2o-table th,\n",
       "#h2o-table-167 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-167 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-167\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 0.911 sec</td>\n",
       "<td>56333 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2207238</td>\n",
       "<td>0.1613350</td>\n",
       "<td>0.7953129</td>\n",
       "<td>0.9839291</td>\n",
       "<td>0.9748325</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0591716</td>\n",
       "<td>0.2616883</td>\n",
       "<td>0.2390545</td>\n",
       "<td>0.7065868</td>\n",
       "<td>0.9685792</td>\n",
       "<td>0.9593676</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0927835</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 0.934 sec</td>\n",
       "<td>29391 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1836335</td>\n",
       "<td>0.1144381</td>\n",
       "<td>0.8583240</td>\n",
       "<td>0.9930127</td>\n",
       "<td>0.9892854</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.2193056</td>\n",
       "<td>0.1600240</td>\n",
       "<td>0.7939319</td>\n",
       "<td>0.9840619</td>\n",
       "<td>0.9765677</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 0.958 sec</td>\n",
       "<td>26000 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1605320</td>\n",
       "<td>0.0894164</td>\n",
       "<td>0.8917281</td>\n",
       "<td>0.9956605</td>\n",
       "<td>0.9932067</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1877236</td>\n",
       "<td>0.1206921</td>\n",
       "<td>0.8490098</td>\n",
       "<td>0.9922587</td>\n",
       "<td>0.9889741</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 0.982 sec</td>\n",
       "<td>24142 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1506416</td>\n",
       "<td>0.0786731</td>\n",
       "<td>0.9046584</td>\n",
       "<td>0.9969109</td>\n",
       "<td>0.9950810</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1751166</td>\n",
       "<td>0.1041747</td>\n",
       "<td>0.8686090</td>\n",
       "<td>0.9936248</td>\n",
       "<td>0.9906904</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 1.005 sec</td>\n",
       "<td>23150 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1404111</td>\n",
       "<td>0.0679485</td>\n",
       "<td>0.9171686</td>\n",
       "<td>0.9972786</td>\n",
       "<td>0.9957266</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1673279</td>\n",
       "<td>0.0976448</td>\n",
       "<td>0.8800369</td>\n",
       "<td>0.9945355</td>\n",
       "<td>0.9917333</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 1.030 sec</td>\n",
       "<td>22533 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1364133</td>\n",
       "<td>0.0656268</td>\n",
       "<td>0.9218183</td>\n",
       "<td>0.9978670</td>\n",
       "<td>0.9965925</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1773899</td>\n",
       "<td>0.1100505</td>\n",
       "<td>0.8651755</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 1.056 sec</td>\n",
       "<td>21907 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1260746</td>\n",
       "<td>0.0565443</td>\n",
       "<td>0.9332198</td>\n",
       "<td>0.9979773</td>\n",
       "<td>0.9967656</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1538515</td>\n",
       "<td>0.0798664</td>\n",
       "<td>0.8985822</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 1.082 sec</td>\n",
       "<td>21291 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1254440</td>\n",
       "<td>0.0540615</td>\n",
       "<td>0.9338862</td>\n",
       "<td>0.9981980</td>\n",
       "<td>0.9971564</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1674418</td>\n",
       "<td>0.0949686</td>\n",
       "<td>0.8798735</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 1.107 sec</td>\n",
       "<td>21125 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1282885</td>\n",
       "<td>0.0560890</td>\n",
       "<td>0.9308539</td>\n",
       "<td>0.9984187</td>\n",
       "<td>0.9975124</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1761549</td>\n",
       "<td>0.1148253</td>\n",
       "<td>0.8670463</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 1.132 sec</td>\n",
       "<td>20864 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1149926</td>\n",
       "<td>0.0473662</td>\n",
       "<td>0.9444439</td>\n",
       "<td>0.9987864</td>\n",
       "<td>0.9980953</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1552790</td>\n",
       "<td>0.0833018</td>\n",
       "<td>0.8966914</td>\n",
       "<td>0.9963570</td>\n",
       "<td>0.9943960</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:54</td>\n",
       "<td> 1.164 sec</td>\n",
       "<td>20655 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1165829</td>\n",
       "<td>0.0465374</td>\n",
       "<td>0.9428966</td>\n",
       "<td>0.9989703</td>\n",
       "<td>0.9983648</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1582304</td>\n",
       "<td>0.0878856</td>\n",
       "<td>0.8927269</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9955992</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-168.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-168 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-168 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-168 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-168 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-168 .h2o-table th,\n",
       "#h2o-table-168 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-168 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-168\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>el-salvador-aid.?</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270212</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.9811991</td>\n",
       "<td>0.9811991</td>\n",
       "<td>0.0265132</td></tr>\n",
       "<tr><td>crime.?</td>\n",
       "<td>0.9726504</td>\n",
       "<td>0.9726504</td>\n",
       "<td>0.0262822</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9533860</td>\n",
       "<td>0.9533860</td>\n",
       "<td>0.0257617</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.?</td>\n",
       "<td>0.9520403</td>\n",
       "<td>0.9520403</td>\n",
       "<td>0.0257253</td></tr>\n",
       "<tr><td>superfund-right-to-sue.y</td>\n",
       "<td>0.9136627</td>\n",
       "<td>0.9136627</td>\n",
       "<td>0.0246883</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.9100732</td>\n",
       "<td>0.9100732</td>\n",
       "<td>0.0245913</td></tr>\n",
       "<tr><td>physician-fee-freeze.y</td>\n",
       "<td>0.8963868</td>\n",
       "<td>0.8963868</td>\n",
       "<td>0.0242215</td></tr>\n",
       "<tr><td>mx-missile.y</td>\n",
       "<td>0.8612557</td>\n",
       "<td>0.8612557</td>\n",
       "<td>0.0232722</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.8610666</td>\n",
       "<td>0.8610666</td>\n",
       "<td>0.0232671</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1638\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  --------------------\n",
       "    1        64       Input    0.0\n",
       "    2        20       Tanh     0.0        0.0   0.0   0.252826455190916      0.4309566020965576     0.0         -0.0006878006061526776  0.15834683179855347  -0.002839801723190552  0.03326600790023804\n",
       "    3        20       Tanh     0.0        0.0   0.0   0.004171751558678807   0.004089832305908203   0.0         0.005044844619114883    0.22238397598266602  0.008153478113334615   0.027608871459960938\n",
       "    4        20       Tanh     0.0        0.0   0.0   0.004779363527632086   0.003946200013160706   0.0         0.015775103969644988    0.21445506811141968  0.004839899927885796   0.014566101133823395\n",
       "    5        2        Softmax             0.0   0.0   0.0050722042447887365  0.0019112210720777512  0.0         0.03699496565386653     1.155776023864746    0.0                    0.010058801621198654\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.013591574998182653\n",
       "RMSE: 0.11658291040363786\n",
       "LogLoss: 0.04653735974662889\n",
       "Mean Per-Class Error: 0.01106943218593704\n",
       "AUC: 0.9989702853780523\n",
       "AUCPR: 0.9983648341082199\n",
       "Gini: 0.9979405707561047\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3079197538244427\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    203         3             0.0146   (3.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       204         134           0.0118   (4.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.30792      0.984962  95\n",
       "max f2                       0.178935     0.990991  99\n",
       "max f0point5                 0.332121     0.984848  93\n",
       "max accuracy                 0.332121     0.988166  93\n",
       "max precision                0.99998      1         0\n",
       "max recall                   0.178935     1         99\n",
       "max specificity              0.99998      1         0\n",
       "max absolute_mcc             0.30792      0.975282  95\n",
       "max min_per_class_accuracy   0.30792      0.985437  95\n",
       "max mean_per_class_accuracy  0.30792      0.988931  95\n",
       "max tns                      0.99998      206       0\n",
       "max fns                      0.99998      131       0\n",
       "max fps                      3.32585e-06  206       269\n",
       "max tps                      0.178935     132       99\n",
       "max tnr                      0.99998      1         0\n",
       "max fnr                      0.99998      0.992424  0\n",
       "max fpr                      3.32585e-06  1         269\n",
       "max tpr                      0.178935     1         99\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0147929                   0.999939           2.56061    2.56061            1                0.999948     1                           0.999948            0.0378788       0.0378788                  156.061   156.061            0.0378788\n",
       "2        0.0207101                   0.999846           2.56061    2.56061            1                0.999883     1                           0.999929            0.0151515       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.999815           2.56061    2.56061            1                0.999829     1                           0.999892            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0443787                   0.999772           2.56061    2.56061            1                0.999782     1                           0.999863            0.030303        0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.999736           2.56061    2.56061            1                0.99974      1                           0.999849            0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.999278           2.56061    2.56061            1                0.999529     1                           0.999689            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.156805                    0.997636           2.56061    2.56061            1                0.998543     1                           0.999278            0.143939        0.401515                   156.061   156.061            0.401515\n",
       "8        0.207101                    0.994071           2.56061    2.56061            1                0.995587     1                           0.998382            0.128788        0.530303                   156.061   156.061            0.530303\n",
       "9        0.301775                    0.970051           2.56061    2.56061            1                0.987567     1                           0.994989            0.242424        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.278326           2.25023    2.48474            0.878788         0.777891     0.97037                     0.941921            0.219697        0.992424                   125.023   148.474            0.973007\n",
       "11       0.5                         0.00433311         0.0753119  2                  0.0294118        0.0577081    0.781065                    0.764032            0.00757576      1                          -92.4688  100                0.820388\n",
       "12       0.600592                    0.000659332        0          1.66502            0                0.00162364   0.650246                    0.636338            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.000191481        0          1.4322             0                0.000384212  0.559322                    0.547412            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    7.99512e-05        0          1.25185            0                0.000124008  0.488889                    0.478494            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    2.89116e-05        0          1.11184            0                5.34013e-05  0.434211                    0.424984            0               1                          -100      11.1842            0.165049\n",
       "16       1                           3.32585e-06        0          1                  0                1.57549e-05  0.390533                    0.382236            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.025036851139801974\n",
       "RMSE: 0.1582303736322517\n",
       "LogLoss: 0.0878856002549917\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9972677595628415\n",
       "AUCPR: 0.9955991765061915\n",
       "Gini: 0.994535519125683\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1662999056749567\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    60          1             0.0164   (1.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       61          36            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.1663       0.972222  32\n",
       "max f2                       0.0227605    0.978261  36\n",
       "max f0point5                 0.678561     0.982143  29\n",
       "max accuracy                 0.1663       0.979381  32\n",
       "max precision                0.999862     1         0\n",
       "max recall                   0.0227605    1         36\n",
       "max specificity              0.999862     1         0\n",
       "max absolute_mcc             0.1663       0.955829  32\n",
       "max min_per_class_accuracy   0.1663       0.972222  32\n",
       "max mean_per_class_accuracy  0.1663       0.977914  32\n",
       "max tns                      0.999862     61        0\n",
       "max fns                      0.999862     35        0\n",
       "max fps                      2.30685e-06  61        91\n",
       "max tps                      0.0227605    36        36\n",
       "max tnr                      0.999862     1         0\n",
       "max fnr                      0.999862     0.972222  0\n",
       "max fpr                      2.30685e-06  1         91\n",
       "max tpr                      0.0227605    1         36\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.43 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0103093                   0.999837           2.69444   2.69444            1                0.999862     1                           0.999862            0.0277778       0.0277778                  169.444   169.444            0.0277778\n",
       "2        0.0206186                   0.999813           2.69444   2.69444            1                0.999836     1                           0.999849            0.0277778       0.0555556                  169.444   169.444            0.0555556\n",
       "3        0.0515464                   0.999811           2.69444   2.69444            1                0.999811     1                           0.999826            0.0833333       0.138889                   169.444   169.444            0.138889\n",
       "4        0.0515464                   0.999712           0         2.69444            0                0            1                           0.999826            0               0.138889                   -100      169.444            0.138889\n",
       "5        0.103093                    0.999421           2.69444   2.69444            1                0.999626     1                           0.999726            0.138889        0.277778                   169.444   169.444            0.277778\n",
       "6        0.154639                    0.998775           2.69444   2.69444            1                0.999092     1                           0.999515            0.138889        0.416667                   169.444   169.444            0.416667\n",
       "7        0.206186                    0.998309           2.69444   2.69444            1                0.99858      1                           0.999281            0.138889        0.555556                   169.444   169.444            0.555556\n",
       "8        0.298969                    0.906915           2.69444   2.69444            1                0.981087     1                           0.993635            0.25            0.805556                   169.444   169.444            0.805556\n",
       "9        0.402062                    0.0448873          1.61667   2.41809            0.6              0.4464       0.897436                    0.853318            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "10       0.505155                    0.00277584         0.269444  1.97959            0.1              0.00960296   0.734694                    0.681131            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "11       0.597938                    0.000609418        0         1.67241            0                0.0016215    0.62069                     0.57569             0               1                          -100      67.2414            0.639344\n",
       "12       0.701031                    0.000267336        0         1.42647            0                0.000377448  0.529412                    0.491085            0               1                          -100      42.6471            0.47541\n",
       "13       0.804124                    0.000104002        0         1.24359            0                0.000162481  0.461538                    0.428147            0               1                          -100      24.359             0.311475\n",
       "14       0.896907                    3.54575e-05        0         1.11494            0                6.01668e-05  0.413793                    0.383862            0               1                          -100      11.4943            0.163934\n",
       "15       1                           2.30685e-06        0         1                  0                1.59654e-05  0.371134                    0.34429             0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.034726718350793405\n",
       "RMSE: 0.18635106211340305\n",
       "LogLoss: 0.10936305237150198\n",
       "Mean Per-Class Error: 0.04894822006472492\n",
       "AUC: 0.9933436304795528\n",
       "AUCPR: 0.9901427328719857\n",
       "Gini: 0.9866872609591055\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7775675858840484\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    203         3             0.0146   (3.0/206.0)\n",
       "republican  11          121           0.0833   (11.0/132.0)\n",
       "Total       214         124           0.0414   (14.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.777568     0.945312  111\n",
       "max f2                       0.162628     0.964392  133\n",
       "max f0point5                 0.777568     0.963376  111\n",
       "max accuracy                 0.777568     0.95858   111\n",
       "max precision                0.999919     1         0\n",
       "max recall                   0.0408865    1         146\n",
       "max specificity              0.999919     1         0\n",
       "max absolute_mcc             0.777568     0.913186  111\n",
       "max min_per_class_accuracy   0.379115     0.954545  122\n",
       "max mean_per_class_accuracy  0.372234     0.956789  124\n",
       "max tns                      0.999919     206       0\n",
       "max fns                      0.999919     131       0\n",
       "max fps                      1.11923e-05  206       317\n",
       "max tps                      0.0408865    132       146\n",
       "max tnr                      0.999919     1         0\n",
       "max fnr                      0.999919     0.992424  0\n",
       "max fpr                      1.11923e-05  1         317\n",
       "max tpr                      0.0408865    1         146\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.07 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.999776           2.56061   2.56061            1                0.999847     1                           0.999847            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.999561           2.56061   2.56061            1                0.999648     1                           0.999762            0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.035503                    0.999386           2.56061   2.56061            1                0.99945      1                           0.999632            0.0378788       0.0909091                  156.061   156.061            0.0909091\n",
       "4        0.0443787                   0.999084           2.56061   2.56061            1                0.999143     1                           0.999534            0.0227273       0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.998754           2.56061   2.56061            1                0.999055     1                           0.999478            0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.997535           2.56061   2.56061            1                0.998217     1                           0.998848            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.99547            2.56061   2.56061            1                0.996736     1                           0.998144            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.201183                    0.991765           2.56061   2.56061            1                0.994039     1                           0.997118            0.128788        0.515152                   156.061   156.061            0.515152\n",
       "9        0.301775                    0.968002           2.56061   2.56061            1                0.982836     1                           0.992357            0.257576        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.377826           1.86226   2.3899             0.727273         0.795564     0.933333                    0.944252            0.181818        0.954545                   86.2259   138.99             0.910856\n",
       "11       0.5                         0.0153946          0.451872  2                  0.176471         0.126991     0.781065                    0.779833            0.0454545       1                          -54.8128  100                0.820388\n",
       "12       0.600592                    0.00226493         0         1.66502            0                0.00554258   0.650246                    0.650149            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.000820397        0         1.4322             0                0.0015392    0.559322                    0.559453            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    0.000389674        0         1.25185            0                0.000585266  0.488889                    0.489077            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    0.000142888        0         1.11184            0                0.000249918  0.434211                    0.434406            0               1                          -100      11.1842            0.165049\n",
       "16       1                           1.119e-05          0         1                  0                8.01209e-05  0.390533                    0.390716            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.96670043   0.029549772  0.95238096    0.9240506     0.9848485     1.0           0.9722222\n",
       "aic                      nan          0.0          nan           nan           nan           nan           nan\n",
       "auc                      0.9917835    0.009066523  0.9906977     0.97739017    0.99906015    1.0           0.99176955\n",
       "err                      0.033299543  0.029549772  0.04761905    0.07594936    0.015151516   0.0           0.027777778\n",
       "err_count                2.4          2.302173     3.0           6.0           1.0           0.0           2.0\n",
       "f0point5                 0.95071733   0.048791222  0.89285713    0.90425533    0.9722222     1.0           0.984252\n",
       "f1                       0.9586292    0.03417238   0.9302326     0.9189189     0.98245615    1.0           0.96153843\n",
       "f2                       0.9675394    0.0299815    0.9708738     0.93406594    0.9929078     1.0           0.9398496\n",
       "lift_top_group           2.6260316    0.37189522   3.15          2.1944444     2.357143      2.7619047     2.6666667\n",
       "loglikelihood            nan          0.0          nan           nan           nan           nan           nan\n",
       "---                      ---          ---          ---           ---           ---           ---           ---\n",
       "mcc                      0.9318437    0.059441995  0.8993875     0.8486844     0.96959215    1.0           0.9415545\n",
       "mean_per_class_accuracy  0.9681264    0.028288808  0.96511626    0.9257106     0.9868421     1.0           0.962963\n",
       "mean_per_class_error     0.03187361   0.028288808  0.034883723   0.074289404   0.013157895   0.0           0.037037037\n",
       "mse                      0.032616053  0.026438352  0.038336463   0.07325841    0.01028462    0.0078729205  0.033327855\n",
       "pr_auc                   0.98844415   0.0109736    0.9798607     0.9754738     0.99874675    1.0           0.9881394\n",
       "precision                0.94596386   0.06058693   0.8695652     0.8947368     0.9655172     1.0           1.0\n",
       "r2                       0.8618662    0.10757175   0.8230728     0.7046475     0.9578949     0.9659144     0.85780114\n",
       "recall                   0.97407407   0.036099236  1.0           0.9444444     1.0           1.0           0.9259259\n",
       "rmse                     0.16783233   0.07456843   0.195797      0.2706629     0.101413116   0.08872948    0.18255918\n",
       "specificity              0.9621787    0.042015146  0.9302326     0.90697676    0.9736842     1.0           1.0\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:54  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:54  0.911 sec   56333 obs/sec     1         1             338        0.220724         0.161335            0.795313       0.983929        0.974833           2.56061          0.0591716                        0.261688           0.239055              0.706587         0.968579          0.959368             2.69444            0.0927835\n",
       "    2025-05-26 14:48:54  0.934 sec   29391 obs/sec     2         2             676        0.183634         0.114438            0.858324       0.993013        0.989285           2.56061          0.0384615                        0.219306           0.160024              0.793932         0.984062          0.976568             2.69444            0.0618557\n",
       "    2025-05-26 14:48:54  0.958 sec   26000 obs/sec     3         3             1014       0.160532         0.0894164           0.891728       0.99566         0.993207           2.56061          0.0266272                        0.187724           0.120692              0.84901          0.992259          0.988974             2.69444            0.0309278\n",
       "    2025-05-26 14:48:54  0.982 sec   24142 obs/sec     4         4             1352       0.150642         0.0786731           0.904658       0.996911        0.995081           2.56061          0.0236686                        0.175117           0.104175              0.868609         0.993625          0.99069              2.69444            0.0309278\n",
       "    2025-05-26 14:48:54  1.005 sec   23150 obs/sec     5         5             1690       0.140411         0.0679485           0.917169       0.997279        0.995727           2.56061          0.0207101                        0.167328           0.0976448             0.880037         0.994536          0.991733             2.69444            0.0309278\n",
       "    2025-05-26 14:48:54  1.030 sec   22533 obs/sec     6         6             2028       0.136413         0.0656268           0.921818       0.997867        0.996593           2.56061          0.0177515                        0.17739            0.11005               0.865176         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:54  1.056 sec   21907 obs/sec     7         7             2366       0.126075         0.0565443           0.93322        0.997977        0.996766           2.56061          0.0177515                        0.153851           0.0798664             0.898582         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:54  1.082 sec   21291 obs/sec     8         8             2704       0.125444         0.0540615           0.933886       0.998198        0.997156           2.56061          0.0177515                        0.167442           0.0949686             0.879873         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:54  1.107 sec   21125 obs/sec     9         9             3042       0.128288         0.056089            0.930854       0.998419        0.997512           2.56061          0.0177515                        0.176155           0.114825              0.867046         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:48:54  1.132 sec   20864 obs/sec     10        10            3380       0.114993         0.0473662           0.944444       0.998786        0.998095           2.56061          0.0147929                        0.155279           0.0833018             0.896691         0.996357          0.994396             2.69444            0.0206186\n",
       "    2025-05-26 14:48:54  1.164 sec   20655 obs/sec     11        11            3718       0.116583         0.0465374           0.942897       0.99897         0.998365           2.56061          0.0118343                        0.15823            0.0878856             0.892727         0.997268          0.995599             2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "el-salvador-aid.?                                   1.0                    1.0                  0.027021235297789322\n",
       "duty-free-exports.?                                 0.9811990857124329     0.9811990857124329   0.0265132113690114\n",
       "crime.?                                             0.972650408744812      0.972650408744812    0.026282215557184525\n",
       "synfuels-corporation-cutback.n                      0.9533860087394714     0.9533860087394714   0.025761667671769482\n",
       "synfuels-corporation-cutback.?                      0.9520403146743774     0.9520403146743774   0.02572530535579774\n",
       "superfund-right-to-sue.y                            0.9136627316474915     0.9136627316474915   0.02468829565466781\n",
       "adoption-of-the-budget-resolution.y                 0.9100732207298279     0.9100732207298279   0.024591302635557637\n",
       "physician-fee-freeze.y                              0.8963868021965027     0.8963868021965027   0.024221478699984634\n",
       "mx-missile.y                                        0.8612557053565979     0.8612557053565979   0.023272193066004143\n",
       "mx-missile.n                                        0.8610665798187256     0.8610665798187256   0.023267082660344475\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[20,20,20], nfolds=5, activation=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefd79c3d309a9d",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [100,100,100], cross folds = 5, activation function = \"tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67260778b0647807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1807\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-169.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-169 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-169 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-169 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-169 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-169 .h2o-table th,\n",
       "#h2o-table-169 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-169 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-169\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,042 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2542381</td>\n",
       "<td>0.4302535</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0028610</td>\n",
       "<td>0.1096230</td>\n",
       "<td>-0.0019316</td>\n",
       "<td>0.0161017</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0166134</td>\n",
       "<td>0.0157943</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005696</td>\n",
       "<td>0.1013302</td>\n",
       "<td>-0.0023457</td>\n",
       "<td>0.0155728</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0515807</td>\n",
       "<td>0.1256160</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0011256</td>\n",
       "<td>0.1007906</td>\n",
       "<td>-0.0011291</td>\n",
       "<td>0.0082231</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0059545</td>\n",
       "<td>0.0018373</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0074746</td>\n",
       "<td>0.5524006</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0045544</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.014998880199205224\n",
       "RMSE: 0.12246991548623369\n",
       "LogLoss: 0.05048575285903044\n",
       "Mean Per-Class Error: 0.015923801117975873\n",
       "AUC: 0.9987496322447779\n",
       "AUCPR: 0.9980920417232073\n",
       "Gini: 0.9974992644895557</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-170.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-170 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-170 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-170 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-170 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-170 .h2o-table th,\n",
       "#h2o-table-170 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-170 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-170\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08438767889091867</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>201.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0243</td>\n",
       "<td> (5.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>202.0</td>\n",
       "<td>136.0</td>\n",
       "<td>0.0178</td>\n",
       "<td> (6.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-171.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-171 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-171 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-171 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-171 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-171 .h2o-table th,\n",
       "#h2o-table-171 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-171 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-171\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.0843877</td>\n",
       "<td>0.9776119</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0843877</td>\n",
       "<td>0.9864458</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8203105</td>\n",
       "<td>0.984375</td>\n",
       "<td>88.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4468284</td>\n",
       "<td>0.9822485</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0098061</td>\n",
       "<td>1.0</td>\n",
       "<td>105.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.0843877</td>\n",
       "<td>0.9632060</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3017793</td>\n",
       "<td>0.9805825</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0843877</td>\n",
       "<td>0.9840762</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0098061</td>\n",
       "<td>132.0</td>\n",
       "<td>105.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0098061</td>\n",
       "<td>1.0</td>\n",
       "<td>105.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-172.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-172 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-172 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-172 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-172 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-172 .h2o-table th,\n",
       "#h2o-table-172 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-172 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-172\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.33 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9999992</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999996</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0295858</td>\n",
       "<td>0.9999989</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999990</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999992</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0757576</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0757576</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.9999989</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999992</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0909091</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0909091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9999985</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999986</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999991</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9999967</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999979</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1035503</td>\n",
       "<td>0.9999848</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999904</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999945</td>\n",
       "<td>0.1363636</td>\n",
       "<td>0.2651515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2651515</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9998798</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999612</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999841</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2071006</td>\n",
       "<td>0.9996803</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997662</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999249</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.5303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5303030</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9962075</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988353</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995831</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.1192102</td>\n",
       "<td>2.1726354</td>\n",
       "<td>2.4657688</td>\n",
       "<td>0.8484848</td>\n",
       "<td>0.8274066</td>\n",
       "<td>0.9629630</td>\n",
       "<td>0.9574955</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.9848485</td>\n",
       "<td>117.2635445</td>\n",
       "<td>146.5768799</td>\n",
       "<td>0.9605766</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0000795</td>\n",
       "<td>0.1506239</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0086893</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7666114</td>\n",
       "<td>0.0151515</td>\n",
       "<td>1.0</td>\n",
       "<td>-84.9376114</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0000079</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000255</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6382177</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0000015</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000041</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5489760</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8047337</td>\n",
       "<td>0.0000004</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2426471</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000008</td>\n",
       "<td>0.4852941</td>\n",
       "<td>0.4763175</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.2647059</td>\n",
       "<td>0.3203883</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4261788</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3833088</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.034445601745164936\n",
       "RMSE: 0.18559526326166015\n",
       "LogLoss: 0.1346172361114347\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9959016393442623\n",
       "AUCPR: 0.9932987194831044\n",
       "Gini: 0.9918032786885247</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-173.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-173 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-173 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-173 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-173 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-173 .h2o-table th,\n",
       "#h2o-table-173 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-173 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-173\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.13930074519982527</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0164</td>\n",
       "<td> (1.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-174.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-174 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-174 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-174 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-174 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-174 .h2o-table th,\n",
       "#h2o-table-174 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-174 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-174\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1393007</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0012753</td>\n",
       "<td>0.9729730</td>\n",
       "<td>37.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.1393007</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1393007</td>\n",
       "<td>0.9793814</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0012753</td>\n",
       "<td>1.0</td>\n",
       "<td>37.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1393007</td>\n",
       "<td>0.9558288</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1393007</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1393007</td>\n",
       "<td>0.9779144</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999989</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999989</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0012753</td>\n",
       "<td>36.0</td>\n",
       "<td>37.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0012753</td>\n",
       "<td>1.0</td>\n",
       "<td>37.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-175.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-175 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-175 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-175 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-175 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-175 .h2o-table th,\n",
       "#h2o-table-175 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-175 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-175\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 33.97 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9999977</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9999972</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999977</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999983</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9999959</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999972</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999979</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0618557</td>\n",
       "<td>0.9999957</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999957</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999968</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1666667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1666667</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9999902</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999914</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999946</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9999828</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999883</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999925</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9998136</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999465</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999810</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9281108</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9941276</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9981644</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0030039</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.3995829</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8446820</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0000497</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0005850</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.6724173</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0000084</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000245</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5680805</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0000031</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000052</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.4845400</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0000004</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000010</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4279056</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000002</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3787211</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3396776</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.025870828321756082\n",
       "RMSE: 0.16084411186535888\n",
       "LogLoss: 0.08478157745927448\n",
       "Mean Per-Class Error: 0.03515739923506914\n",
       "AUC: 0.9961017946454839\n",
       "AUCPR: 0.994352665949165\n",
       "Gini: 0.9922035892909677</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-176.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-176 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-176 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-176 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-176 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-176 .h2o-table th,\n",
       "#h2o-table-176 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-176 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-176\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8130805001224114</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>204.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0097</td>\n",
       "<td> (2.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>8.0</td>\n",
       "<td>124.0</td>\n",
       "<td>0.0606</td>\n",
       "<td> (8.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>212.0</td>\n",
       "<td>126.0</td>\n",
       "<td>0.0296</td>\n",
       "<td> (10.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-177.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-177 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-177 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-177 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-177 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-177 .h2o-table th,\n",
       "#h2o-table-177 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-177 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-177\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.8130805</td>\n",
       "<td>0.9612403</td>\n",
       "<td>113.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1148726</td>\n",
       "<td>0.9747024</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8130805</td>\n",
       "<td>0.9748428</td>\n",
       "<td>113.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.8130805</td>\n",
       "<td>0.9704142</td>\n",
       "<td>113.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999917</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0130094</td>\n",
       "<td>1.0</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999917</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.8130805</td>\n",
       "<td>0.9380010</td>\n",
       "<td>113.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.2902162</td>\n",
       "<td>0.9563107</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1924713</td>\n",
       "<td>0.9705796</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999917</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999917</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000001</td>\n",
       "<td>206.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0130094</td>\n",
       "<td>132.0</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999917</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999917</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000001</td>\n",
       "<td>1.0</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0130094</td>\n",
       "<td>1.0</td>\n",
       "<td>152.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-178.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-178 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-178 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-178 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-178 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-178 .h2o-table th,\n",
       "#h2o-table-178 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-178 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-178\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.66 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9999780</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999852</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999852</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9999527</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999647</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999764</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.9999111</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999323</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999580</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0909091</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0909091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9998992</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998993</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999496</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9998781</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998894</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999390</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9993269</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996298</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997844</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9980741</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9986654</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994114</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9954914</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9968130</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987618</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9617362</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9824984</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933407</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.2996977</td>\n",
       "<td>1.8622590</td>\n",
       "<td>2.3898990</td>\n",
       "<td>0.7272727</td>\n",
       "<td>0.7993854</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.9459294</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.9545455</td>\n",
       "<td>86.2258953</td>\n",
       "<td>138.9898990</td>\n",
       "<td>0.9108561</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0092473</td>\n",
       "<td>0.4518717</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1764706</td>\n",
       "<td>0.0797854</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7716756</td>\n",
       "<td>0.0454545</td>\n",
       "<td>1.0</td>\n",
       "<td>-54.8128342</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0027786</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0052865</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6433148</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0007900</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0014881</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5535679</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0001978</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003913</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4839086</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000271</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000900</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4297973</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>6e-08</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000091</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3865642</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-179.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-179 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-179 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-179 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-179 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-179 .h2o-table th,\n",
       "#h2o-table-179 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-179 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-179\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9777225</td>\n",
       "<td>0.0206432</td>\n",
       "<td>0.9682540</td>\n",
       "<td>0.9620253</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9583333</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9959441</td>\n",
       "<td>0.0040165</td>\n",
       "<td>0.9953488</td>\n",
       "<td>0.9909561</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9934156</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0222775</td>\n",
       "<td>0.0206432</td>\n",
       "<td>0.0317460</td>\n",
       "<td>0.0379747</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0416667</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>1.6</td>\n",
       "<td>1.5165751</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9654174</td>\n",
       "<td>0.0348629</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.9659091</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9352518</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9711164</td>\n",
       "<td>0.0267246</td>\n",
       "<td>0.9523810</td>\n",
       "<td>0.9577465</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9454545</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.977199</td>\n",
       "<td>0.0237667</td>\n",
       "<td>0.9803922</td>\n",
       "<td>0.9497207</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9558824</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6260316</td>\n",
       "<td>0.3718952</td>\n",
       "<td>3.15</td>\n",
       "<td>2.1944444</td>\n",
       "<td>2.357143</td>\n",
       "<td>2.7619047</td>\n",
       "<td>2.6666667</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9533525</td>\n",
       "<td>0.0431100</td>\n",
       "<td>0.931025</td>\n",
       "<td>0.9235782</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9121593</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9793196</td>\n",
       "<td>0.0200938</td>\n",
       "<td>0.9767442</td>\n",
       "<td>0.9605943</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9592593</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0206804</td>\n",
       "<td>0.0200938</td>\n",
       "<td>0.0232558</td>\n",
       "<td>0.0394057</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0407407</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0244970</td>\n",
       "<td>0.0194705</td>\n",
       "<td>0.0316722</td>\n",
       "<td>0.0467356</td>\n",
       "<td>0.0003686</td>\n",
       "<td>0.0081754</td>\n",
       "<td>0.0355330</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9941978</td>\n",
       "<td>0.0053147</td>\n",
       "<td>0.990469</td>\n",
       "<td>0.9908672</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9896527</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9618182</td>\n",
       "<td>0.0415138</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9714286</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8953791</td>\n",
       "<td>0.0812112</td>\n",
       "<td>0.8538291</td>\n",
       "<td>0.8115782</td>\n",
       "<td>0.9984912</td>\n",
       "<td>0.9646047</td>\n",
       "<td>0.8483923</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.0261891</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9444444</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1384538</td>\n",
       "<td>0.0816051</td>\n",
       "<td>0.1779669</td>\n",
       "<td>0.2161842</td>\n",
       "<td>0.0191978</td>\n",
       "<td>0.0904180</td>\n",
       "<td>0.1885021</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9771576</td>\n",
       "<td>0.0227519</td>\n",
       "<td>0.9534883</td>\n",
       "<td>0.9767442</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9555556</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 8 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-180.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-180 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-180 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-180 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-180 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-180 .h2o-table th,\n",
       "#h2o-table-180 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-180 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-180\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:48:59</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:48:59</td>\n",
       "<td> 1.416 sec</td>\n",
       "<td>4970 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.1499593</td>\n",
       "<td>0.0751439</td>\n",
       "<td>0.9055202</td>\n",
       "<td>0.9970947</td>\n",
       "<td>0.9955916</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1316145</td>\n",
       "<td>0.0588840</td>\n",
       "<td>0.9257804</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 1.512 sec</td>\n",
       "<td>4447 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1413837</td>\n",
       "<td>0.0718852</td>\n",
       "<td>0.9160171</td>\n",
       "<td>0.9969476</td>\n",
       "<td>0.9951138</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1409968</td>\n",
       "<td>0.0648132</td>\n",
       "<td>0.9148216</td>\n",
       "<td>0.9981785</td>\n",
       "<td>0.9970529</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 1.621 sec</td>\n",
       "<td>4121 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1324967</td>\n",
       "<td>0.0600974</td>\n",
       "<td>0.9262432</td>\n",
       "<td>0.9980877</td>\n",
       "<td>0.9968429</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1386852</td>\n",
       "<td>0.0597066</td>\n",
       "<td>0.9175916</td>\n",
       "<td>0.9977231</td>\n",
       "<td>0.9961014</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 1.717 sec</td>\n",
       "<td>4121 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1257899</td>\n",
       "<td>0.0544589</td>\n",
       "<td>0.9335211</td>\n",
       "<td>0.9979038</td>\n",
       "<td>0.9965739</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1592843</td>\n",
       "<td>0.0947178</td>\n",
       "<td>0.8912932</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9932987</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 1.809 sec</td>\n",
       "<td>4152 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1372659</td>\n",
       "<td>0.0629276</td>\n",
       "<td>0.9208379</td>\n",
       "<td>0.9982348</td>\n",
       "<td>0.9973312</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1538446</td>\n",
       "<td>0.0802435</td>\n",
       "<td>0.8985912</td>\n",
       "<td>0.9968124</td>\n",
       "<td>0.9943648</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 1.901 sec</td>\n",
       "<td>4172 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1203671</td>\n",
       "<td>0.0471079</td>\n",
       "<td>0.9391293</td>\n",
       "<td>0.9988600</td>\n",
       "<td>0.9982608</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1574384</td>\n",
       "<td>0.0790773</td>\n",
       "<td>0.8937981</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9976512</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 1.996 sec</td>\n",
       "<td>4180 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1249248</td>\n",
       "<td>0.0527575</td>\n",
       "<td>0.9344324</td>\n",
       "<td>0.9992277</td>\n",
       "<td>0.9988124</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1413101</td>\n",
       "<td>0.0628661</td>\n",
       "<td>0.9144426</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9959837</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 2.089 sec</td>\n",
       "<td>4192 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1134005</td>\n",
       "<td>0.0452435</td>\n",
       "<td>0.9459716</td>\n",
       "<td>0.9987129</td>\n",
       "<td>0.9981706</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1682952</td>\n",
       "<td>0.1140999</td>\n",
       "<td>0.8786459</td>\n",
       "<td>0.9954463</td>\n",
       "<td>0.9924168</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:00</td>\n",
       "<td> 2.184 sec</td>\n",
       "<td>4195 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1224699</td>\n",
       "<td>0.0504858</td>\n",
       "<td>0.9369840</td>\n",
       "<td>0.9987496</td>\n",
       "<td>0.9980920</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1855953</td>\n",
       "<td>0.1346172</td>\n",
       "<td>0.8524141</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9932987</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-181.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-181 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-181 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-181 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-181 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-181 .h2o-table th,\n",
       "#h2o-table-181 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-181 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-181\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0233443</td></tr>\n",
       "<tr><td>physician-fee-freeze.?</td>\n",
       "<td>0.9726896</td>\n",
       "<td>0.9726896</td>\n",
       "<td>0.0227067</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9714439</td>\n",
       "<td>0.9714439</td>\n",
       "<td>0.0226776</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.?</td>\n",
       "<td>0.9619028</td>\n",
       "<td>0.9619028</td>\n",
       "<td>0.0224549</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9602698</td>\n",
       "<td>0.9602698</td>\n",
       "<td>0.0224168</td></tr>\n",
       "<tr><td>religious-groups-in-schools.n</td>\n",
       "<td>0.9594933</td>\n",
       "<td>0.9594933</td>\n",
       "<td>0.0223987</td></tr>\n",
       "<tr><td>superfund-right-to-sue.n</td>\n",
       "<td>0.9545972</td>\n",
       "<td>0.9545972</td>\n",
       "<td>0.0222844</td></tr>\n",
       "<tr><td>handicapped-infants.y</td>\n",
       "<td>0.9495268</td>\n",
       "<td>0.9495268</td>\n",
       "<td>0.0221660</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.9487916</td>\n",
       "<td>0.9487916</td>\n",
       "<td>0.0221488</td></tr>\n",
       "<tr><td>education-spending.n</td>\n",
       "<td>0.9420477</td>\n",
       "<td>0.9420477</td>\n",
       "<td>0.0219914</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1807\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,042 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias               bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  ----------------------  ---------------------\n",
       "    1        64       Input    0.0\n",
       "    2        100      Tanh     0.0        0.0   0.0   0.2542380617823528    0.4302535057067871    0.0         0.002860984636457644   0.10962304472923279  -0.0019316008571227095  0.016101747751235962\n",
       "    3        100      Tanh     0.0        0.0   0.0   0.016613428225019017  0.015794269740581512  0.0         0.0005696288145270046  0.1013302206993103   -0.0023456889666684296  0.015572823584079742\n",
       "    4        100      Tanh     0.0        0.0   0.0   0.051580740910035096  0.1256159543991089    0.0         0.001125604475197906   0.10079056024551392  -0.001129116880542333   0.008223116397857666\n",
       "    5        2        Softmax             0.0   0.0   0.005954488324932754  0.001837337389588356  0.0         -0.007474560034461319  0.5524005889892578   5.204170427930421e-18   0.0045544058084487915\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.014998880199205224\n",
       "RMSE: 0.12246991548623369\n",
       "LogLoss: 0.05048575285903044\n",
       "Mean Per-Class Error: 0.015923801117975873\n",
       "AUC: 0.9987496322447779\n",
       "AUCPR: 0.9980920417232073\n",
       "Gini: 0.9974992644895557\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.08438767889091867\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    201         5             0.0243   (5.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       202         136           0.0178   (6.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.0843877    0.977612  97\n",
       "max f2                       0.0843877    0.986446  97\n",
       "max f0point5                 0.820311     0.984375  88\n",
       "max accuracy                 0.446828     0.982249  91\n",
       "max precision                1            1         0\n",
       "max recall                   0.0098061    1         105\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.0843877    0.963206  97\n",
       "max min_per_class_accuracy   0.301779     0.980583  95\n",
       "max mean_per_class_accuracy  0.0843877    0.984076  97\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      3.78069e-10  206       269\n",
       "max tps                      0.0098061    132       105\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      3.78069e-10  1         269\n",
       "max tpr                      0.0098061    1         105\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.33 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.999999           2.56061   2.56061            1                1            1                           1                   0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0295858                   0.999999           2.56061   2.56061            1                0.999999     1                           0.999999            0.0454545       0.0757576                  156.061   156.061            0.0757576\n",
       "3        0.035503                    0.999999           2.56061   2.56061            1                0.999999     1                           0.999999            0.0151515       0.0909091                  156.061   156.061            0.0909091\n",
       "4        0.0414201                   0.999999           2.56061   2.56061            1                0.999999     1                           0.999999            0.0151515       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.999997           2.56061   2.56061            1                0.999998     1                           0.999999            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.10355                     0.999985           2.56061   2.56061            1                0.99999      1                           0.999995            0.136364        0.265152                   156.061   156.061            0.265152\n",
       "7        0.150888                    0.99988            2.56061   2.56061            1                0.999961     1                           0.999984            0.121212        0.386364                   156.061   156.061            0.386364\n",
       "8        0.207101                    0.99968            2.56061   2.56061            1                0.999766     1                           0.999925            0.143939        0.530303                   156.061   156.061            0.530303\n",
       "9        0.301775                    0.996208           2.56061   2.56061            1                0.998835     1                           0.999583            0.242424        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.11921            2.17264   2.46577            0.848485         0.827407     0.962963                    0.957495            0.212121        0.984848                   117.264   146.577            0.960577\n",
       "11       0.5                         7.95214e-05        0.150624  2                  0.0588235        0.00868935   0.781065                    0.766611            0.0151515       1                          -84.9376  100                0.820388\n",
       "12       0.600592                    7.88258e-06        0         1.66502            0                2.54643e-05  0.650246                    0.638218            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    1.49577e-06        0         1.4322             0                4.1149e-06   0.559322                    0.548976            0               1                          -100      43.2203            0.495146\n",
       "14       0.804734                    3.57336e-07        0         1.24265            0                7.90835e-07  0.485294                    0.476318            0               1                          -100      24.2647            0.320388\n",
       "15       0.899408                    4.21841e-08        0         1.11184            0                1.76177e-07  0.434211                    0.426179            0               1                          -100      11.1842            0.165049\n",
       "16       1                           3.78069e-10        0         1                  0                1.15027e-08  0.390533                    0.383309            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.034445601745164936\n",
       "RMSE: 0.18559526326166015\n",
       "LogLoss: 0.1346172361114347\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9959016393442623\n",
       "AUCPR: 0.9932987194831044\n",
       "Gini: 0.9918032786885247\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.13930074519982527\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    60          1             0.0164   (1.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       61          36            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.139301     0.972222  32\n",
       "max f2                       0.00127531   0.972973  37\n",
       "max f0point5                 0.139301     0.972222  32\n",
       "max accuracy                 0.139301     0.979381  32\n",
       "max precision                0.999999     1         0\n",
       "max recall                   0.00127531   1         37\n",
       "max specificity              0.999999     1         0\n",
       "max absolute_mcc             0.139301     0.955829  32\n",
       "max min_per_class_accuracy   0.139301     0.972222  32\n",
       "max mean_per_class_accuracy  0.139301     0.977914  32\n",
       "max tns                      0.999999     61        0\n",
       "max fns                      0.999999     35        0\n",
       "max fps                      3.15691e-09  61        91\n",
       "max tps                      0.00127531   36        37\n",
       "max tnr                      0.999999     1         0\n",
       "max fnr                      0.999999     0.972222  0\n",
       "max fpr                      3.15691e-09  1         91\n",
       "max tpr                      0.00127531   1         37\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 33.97 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0103093                   0.999998           2.69444   2.69444            1                0.999999     1                           0.999999            0.0277778       0.0277778                  169.444   169.444            0.0277778\n",
       "2        0.0206186                   0.999997           2.69444   2.69444            1                0.999998     1                           0.999998            0.0277778       0.0555556                  169.444   169.444            0.0555556\n",
       "3        0.0309278                   0.999996           2.69444   2.69444            1                0.999997     1                           0.999998            0.0277778       0.0833333                  169.444   169.444            0.0833333\n",
       "4        0.0618557                   0.999996           2.69444   2.69444            1                0.999996     1                           0.999997            0.0833333       0.166667                   169.444   169.444            0.166667\n",
       "5        0.103093                    0.99999            2.69444   2.69444            1                0.999991     1                           0.999995            0.111111        0.277778                   169.444   169.444            0.277778\n",
       "6        0.154639                    0.999983           2.69444   2.69444            1                0.999988     1                           0.999993            0.138889        0.416667                   169.444   169.444            0.416667\n",
       "7        0.206186                    0.999814           2.69444   2.69444            1                0.999947     1                           0.999981            0.138889        0.555556                   169.444   169.444            0.555556\n",
       "8        0.298969                    0.928111           2.69444   2.69444            1                0.994128     1                           0.998164            0.25            0.805556                   169.444   169.444            0.805556\n",
       "9        0.402062                    0.00300389         1.61667   2.41809            0.6              0.399583     0.897436                    0.844682            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "10       0.505155                    4.9699e-05         0.269444  1.97959            0.1              0.00058499   0.734694                    0.672417            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "11       0.597938                    8.37658e-06        0         1.67241            0                2.44606e-05  0.62069                     0.56808             0               1                          -100      67.2414            0.639344\n",
       "12       0.701031                    3.10102e-06        0         1.42647            0                5.20525e-06  0.529412                    0.48454             0               1                          -100      42.6471            0.47541\n",
       "13       0.793814                    4.071e-07          0         1.25974            0                9.9381e-07   0.467532                    0.427906            0               1                          -100      25.974             0.327869\n",
       "14       0.896907                    8.89429e-08        0         1.11494            0                2.17071e-07  0.413793                    0.378721            0               1                          -100      11.4943            0.163934\n",
       "15       1                           3.15691e-09        0         1                  0                2.12666e-08  0.371134                    0.339678            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.025870828321756082\n",
       "RMSE: 0.16084411186535888\n",
       "LogLoss: 0.08478157745927448\n",
       "Mean Per-Class Error: 0.03515739923506914\n",
       "AUC: 0.9961017946454839\n",
       "AUCPR: 0.994352665949165\n",
       "Gini: 0.9922035892909677\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.8130805001224114\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    204         2             0.0097   (2.0/206.0)\n",
       "republican  8           124           0.0606   (8.0/132.0)\n",
       "Total       212         126           0.0296   (10.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.813081     0.96124   113\n",
       "max f2                       0.114873     0.974702  131\n",
       "max f0point5                 0.813081     0.974843  113\n",
       "max accuracy                 0.813081     0.970414  113\n",
       "max precision                0.999992     1         0\n",
       "max recall                   0.0130094    1         152\n",
       "max specificity              0.999992     1         0\n",
       "max absolute_mcc             0.813081     0.938001  113\n",
       "max min_per_class_accuracy   0.290216     0.956311  123\n",
       "max mean_per_class_accuracy  0.192471     0.97058   126\n",
       "max tns                      0.999992     206       0\n",
       "max fns                      0.999992     131       0\n",
       "max fps                      6.47066e-08  206       317\n",
       "max tps                      0.0130094    132       152\n",
       "max tnr                      0.999992     1         0\n",
       "max fnr                      0.999992     0.992424  0\n",
       "max fpr                      6.47066e-08  1         317\n",
       "max tpr                      0.0130094    1         152\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.66 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.999978           2.56061   2.56061            1                0.999985     1                           0.999985            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.999953           2.56061   2.56061            1                0.999965     1                           0.999976            0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.035503                    0.999911           2.56061   2.56061            1                0.999932     1                           0.999958            0.0378788       0.0909091                  156.061   156.061            0.0909091\n",
       "4        0.0414201                   0.999899           2.56061   2.56061            1                0.999899     1                           0.99995             0.0151515       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.999878           2.56061   2.56061            1                0.999889     1                           0.999939            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.999327           2.56061   2.56061            1                0.99963      1                           0.999784            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.998074           2.56061   2.56061            1                0.998665     1                           0.999411            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.201183                    0.995491           2.56061   2.56061            1                0.996813     1                           0.998762            0.128788        0.515152                   156.061   156.061            0.515152\n",
       "9        0.301775                    0.961736           2.56061   2.56061            1                0.982498     1                           0.993341            0.257576        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.299698           1.86226   2.3899             0.727273         0.799385     0.933333                    0.945929            0.181818        0.954545                   86.2259   138.99             0.910856\n",
       "11       0.5                         0.00924729         0.451872  2                  0.176471         0.0797854    0.781065                    0.771676            0.0454545       1                          -54.8128  100                0.820388\n",
       "12       0.600592                    0.00277855         0         1.66502            0                0.00528645   0.650246                    0.643315            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.000789996        0         1.4322             0                0.00148808   0.559322                    0.553568            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    0.000197812        0         1.25185            0                0.000391287  0.488889                    0.483909            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    2.7142e-05         0         1.11184            0                9.00409e-05  0.434211                    0.429797            0               1                          -100      11.1842            0.165049\n",
       "16       1                           6e-08              0         1                  0                9.10941e-06  0.390533                    0.386564            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid     cv_4_valid    cv_5_valid\n",
       "-----------------------  -----------  ------------  ------------  ------------  -------------  ------------  ------------\n",
       "accuracy                 0.9777225    0.02064321    0.96825397    0.96202534    1.0            1.0           0.9583333\n",
       "aic                      nan          0.0           nan           nan           nan            nan           nan\n",
       "auc                      0.9959441    0.0040164827  0.9953488     0.99095607    1.0            1.0           0.99341565\n",
       "err                      0.022277476  0.02064321    0.031746034   0.03797468    0.0            0.0           0.041666668\n",
       "err_count                1.6          1.5165751     2.0           3.0           0.0            0.0           3.0\n",
       "f0point5                 0.9654174    0.034862924   0.9259259     0.96590906    1.0            1.0           0.9352518\n",
       "f1                       0.9711164    0.026724648   0.95238096    0.9577465     1.0            1.0           0.94545454\n",
       "f2                       0.977199     0.023766708   0.98039216    0.9497207     1.0            1.0           0.9558824\n",
       "lift_top_group           2.6260316    0.37189522    3.15          2.1944444     2.357143       2.7619047     2.6666667\n",
       "loglikelihood            nan          0.0           nan           nan           nan            nan           nan\n",
       "---                      ---          ---           ---           ---           ---            ---           ---\n",
       "mcc                      0.9533525    0.043109972   0.931025      0.9235782     1.0            1.0           0.9121593\n",
       "mean_per_class_accuracy  0.9793196    0.020093806   0.9767442     0.9605943     1.0            1.0           0.9592593\n",
       "mean_per_class_error     0.020680448  0.020093806   0.023255814   0.039405685   0.0            0.0           0.04074074\n",
       "mse                      0.024496967  0.01947055    0.03167221    0.0467356     0.00036855484  0.008175417   0.03553305\n",
       "pr_auc                   0.9941978    0.0053147306  0.990469      0.9908672     1.0            1.0           0.98965275\n",
       "precision                0.96181816   0.041513775   0.90909094    0.9714286     1.0            1.0           0.9285714\n",
       "r2                       0.8953791    0.081211194   0.8538291     0.8115782     0.99849117     0.96460474    0.8483923\n",
       "recall                   0.9814815    0.02618914    1.0           0.9444444     1.0            1.0           0.962963\n",
       "rmse                     0.1384538    0.08160509    0.17796688    0.21618418    0.019197783    0.09041801    0.18850212\n",
       "specificity              0.97715765   0.022751935   0.95348835    0.9767442     1.0            1.0           0.95555556\n",
       "[22 rows x 8 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:48:59  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:48:59  1.416 sec   4970 obs/sec      1         1             338        0.149959         0.0751439           0.90552        0.997095        0.995592           2.56061          0.0236686                        0.131615           0.058884              0.92578          0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:49:00  1.512 sec   4447 obs/sec      2         2             676        0.141384         0.0718852           0.916017       0.996948        0.995114           2.56061          0.0207101                        0.140997           0.0648132             0.914822         0.998179          0.997053             2.69444            0.0206186\n",
       "    2025-05-26 14:49:00  1.621 sec   4121 obs/sec      3         3             1014       0.132497         0.0600974           0.926243       0.998088        0.996843           2.56061          0.0147929                        0.138685           0.0597066             0.917592         0.997723          0.996101             2.69444            0.0206186\n",
       "    2025-05-26 14:49:00  1.717 sec   4121 obs/sec      4         4             1352       0.12579          0.0544589           0.933521       0.997904        0.996574           2.56061          0.0177515                        0.159284           0.0947178             0.891293         0.995902          0.993299             2.69444            0.0206186\n",
       "    2025-05-26 14:49:00  1.809 sec   4152 obs/sec      5         5             1690       0.137266         0.0629276           0.920838       0.998235        0.997331           2.56061          0.0207101                        0.153845           0.0802435             0.898591         0.996812          0.994365             2.69444            0.0206186\n",
       "    2025-05-26 14:49:00  1.901 sec   4172 obs/sec      6         6             2028       0.120367         0.0471079           0.939129       0.99886         0.998261           2.56061          0.0177515                        0.157438           0.0790773             0.893798         0.998634          0.997651             2.69444            0.0103093\n",
       "    2025-05-26 14:49:00  1.996 sec   4180 obs/sec      7         7             2366       0.124925         0.0527575           0.934432       0.999228        0.998812           2.56061          0.0147929                        0.14131            0.0628661             0.914443         0.997268          0.995984             2.69444            0.0103093\n",
       "    2025-05-26 14:49:00  2.089 sec   4192 obs/sec      8         8             2704       0.1134           0.0452435           0.945972       0.998713        0.998171           2.56061          0.0147929                        0.168295           0.1141                0.878646         0.995446          0.992417             2.69444            0.0206186\n",
       "    2025-05-26 14:49:00  2.184 sec   4195 obs/sec      9         9             3042       0.12247          0.0504858           0.936984       0.99875         0.998092           2.56061          0.0177515                        0.185595           0.134617              0.852414         0.995902          0.993299             2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.023344267146188688\n",
       "physician-fee-freeze.?                              0.9726895689964294     0.9726895689964294   0.022706725148963783\n",
       "synfuels-corporation-cutback.n                      0.9714438915252686     0.9714438915252686   0.022677645721299013\n",
       "adoption-of-the-budget-resolution.?                 0.9619027972221375     0.9619027972221375   0.022454915867019743\n",
       "physician-fee-freeze.n                              0.9602698087692261     0.9602698087692261   0.022416794948328336\n",
       "religious-groups-in-schools.n                       0.9594933390617371     0.9594933390617371   0.02239866883204579\n",
       "superfund-right-to-sue.n                            0.9545972347259521     0.9545972347259521   0.022284372864455615\n",
       "handicapped-infants.y                               0.949526846408844      0.949526846408844    0.02216600836504613\n",
       "aid-to-nicaraguan-contras.y                         0.9487915635108948     0.9487915635108948   0.022148843724648377\n",
       "education-spending.n                                0.942047655582428      0.942047655582428    0.02199141213635695\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[100,100,100], nfolds=5, activation=\"tanh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203d7f974a18f619",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [5,5,5], cross folds = 10, activation function = \"tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "964861e836facd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1954\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-182.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-182 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-182 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-182 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-182 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-182 .h2o-table th,\n",
       "#h2o-table-182 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-182 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-182\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2523985</td>\n",
       "<td>0.4311669</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0150976</td>\n",
       "<td>0.1779892</td>\n",
       "<td>-0.0010596</td>\n",
       "<td>0.1225944</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0019809</td>\n",
       "<td>0.0007254</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0625058</td>\n",
       "<td>0.4883827</td>\n",
       "<td>0.0678760</td>\n",
       "<td>0.0309350</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>5</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0110674</td>\n",
       "<td>0.0131454</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1716897</td>\n",
       "<td>0.3957357</td>\n",
       "<td>0.0577567</td>\n",
       "<td>0.0293457</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0029493</td>\n",
       "<td>0.0004861</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6811196</td>\n",
       "<td>1.0491529</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0905948</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01498420270229417\n",
       "RMSE: 0.12240997795234737\n",
       "LogLoss: 0.06761104157752912\n",
       "Mean Per-Class Error: 0.013496616651956457\n",
       "AUC: 0.9958811415122095\n",
       "AUCPR: 0.9943769422396921\n",
       "Gini: 0.991762283024419</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-183.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-183 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-183 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-183 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-183 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-183 .h2o-table th,\n",
       "#h2o-table-183 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-183 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-183\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4126378161683046</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>202.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0194</td>\n",
       "<td> (4.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>203.0</td>\n",
       "<td>135.0</td>\n",
       "<td>0.0148</td>\n",
       "<td> (5.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-184.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-184 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-184 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-184 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-184 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-184 .h2o-table th,\n",
       "#h2o-table-184 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-184 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-184\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9812734</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9879336</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7504512</td>\n",
       "<td>0.9827044</td>\n",
       "<td>87.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4689879</td>\n",
       "<td>0.9852071</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9948774</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0051177</td>\n",
       "<td>1.0</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9948774</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9692181</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4689879</td>\n",
       "<td>0.9848485</td>\n",
       "<td>94.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4126378</td>\n",
       "<td>0.9865034</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9948774</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9948774</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0023228</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0051177</td>\n",
       "<td>132.0</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9948774</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9948774</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0023228</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0051177</td>\n",
       "<td>1.0</td>\n",
       "<td>157.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-185.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-185 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-185 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-185 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-185 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-185 .h2o-table th,\n",
       "#h2o-table-185 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-185 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-185\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9940103</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943581</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9943581</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9936174</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937851</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9941125</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0355030</td>\n",
       "<td>0.9929642</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9930865</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936850</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0909091</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0909091</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9928430</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928736</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9935691</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9926368</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9927845</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9934306</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9908788</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9916871</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925589</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9874873</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9896747</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9915975</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9821893</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9847686</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9898902</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3047337</td>\n",
       "<td>0.9619203</td>\n",
       "<td>2.4874459</td>\n",
       "<td>2.5357458</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9753460</td>\n",
       "<td>0.9902913</td>\n",
       "<td>0.9849480</td>\n",
       "<td>0.2575758</td>\n",
       "<td>0.7727273</td>\n",
       "<td>148.7445887</td>\n",
       "<td>153.5745808</td>\n",
       "<td>0.7678729</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4098200</td>\n",
       "<td>2.3205492</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.90625</td>\n",
       "<td>0.7836350</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9372294</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9924242</td>\n",
       "<td>132.0549242</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0081417</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0588599</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7605160</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6035503</td>\n",
       "<td>0.0045911</td>\n",
       "<td>0.0731602</td>\n",
       "<td>1.6568627</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0057996</td>\n",
       "<td>0.6470588</td>\n",
       "<td>0.6310304</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.6839827</td>\n",
       "<td>65.6862745</td>\n",
       "<td>0.6504854</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0038542</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0042049</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5460371</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8047337</td>\n",
       "<td>0.0031851</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2426471</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0034794</td>\n",
       "<td>0.4852941</td>\n",
       "<td>0.4742280</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.2647059</td>\n",
       "<td>0.3203883</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0028688</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0030717</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4246326</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0023228</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026798</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3821876</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.01453753366980719\n",
       "RMSE: 0.12057169514362477\n",
       "LogLoss: 0.0555894978715649\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-186.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-186 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-186 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-186 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-186 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-186 .h2o-table th,\n",
       "#h2o-table-186 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-186 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-186\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5951267160204192</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>62.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0103</td>\n",
       "<td> (1.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-187.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-187 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-187 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-187 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-187 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-187 .h2o-table th,\n",
       "#h2o-table-187 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-187 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-187\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9859155</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0974078</td>\n",
       "<td>0.9890110</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9943182</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9896907</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0974078</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9780293</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9722222</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5951267</td>\n",
       "<td>0.9861111</td>\n",
       "<td>31.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9946142</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9946142</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0024439</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0974078</td>\n",
       "<td>36.0</td>\n",
       "<td>34.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9946142</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0024439</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0974078</td>\n",
       "<td>1.0</td>\n",
       "<td>34.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-188.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-188 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-188 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-188 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-188 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-188 .h2o-table th,\n",
       "#h2o-table-188 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-188 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-188\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.27 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9930307</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9946142</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9946142</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9928741</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9929647</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9937895</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9928094</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928662</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9934817</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9924843</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928017</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933117</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9920826</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9924239</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931341</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9913939</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9918919</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925130</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9902192</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9909260</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919840</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9876434</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9885179</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9911175</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9083470</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9784442</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9871844</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0444293</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.5249142</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.8686536</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0072823</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0147291</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.6943833</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0049817</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0055901</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5875016</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0040196</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0045396</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5017719</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0032802</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0036281</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4435473</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0030136</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0031589</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3929279</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0024439</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0026538</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3526935</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.02516950720561065\n",
       "RMSE: 0.1586490063177537\n",
       "LogLoss: 0.10011817012447274\n",
       "Mean Per-Class Error: 0.025632538982053546\n",
       "AUC: 0.990879670491321\n",
       "AUCPR: 0.9871645918298849\n",
       "Gini: 0.981759340982642</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-189.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-189 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-189 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-189 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-189 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-189 .h2o-table th,\n",
       "#h2o-table-189 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-189 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-189\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3774709315100019</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>197.0</td>\n",
       "<td>9.0</td>\n",
       "<td>0.0437</td>\n",
       "<td> (9.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>198.0</td>\n",
       "<td>140.0</td>\n",
       "<td>0.0296</td>\n",
       "<td> (10.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-190.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-190 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-190 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-190 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-190 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-190 .h2o-table th,\n",
       "#h2o-table-190 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-190 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-190\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3774709</td>\n",
       "<td>0.9632353</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3774709</td>\n",
       "<td>0.9805389</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7370885</td>\n",
       "<td>0.9662577</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7370885</td>\n",
       "<td>0.9704142</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9947214</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0069355</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9947214</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3774709</td>\n",
       "<td>0.9396559</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5712663</td>\n",
       "<td>0.9660194</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3774709</td>\n",
       "<td>0.9743675</td>\n",
       "<td>134.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9947214</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9947214</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0029342</td>\n",
       "<td>206.0</td>\n",
       "<td>326.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0069355</td>\n",
       "<td>132.0</td>\n",
       "<td>231.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9947214</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9947214</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0029342</td>\n",
       "<td>1.0</td>\n",
       "<td>326.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0069355</td>\n",
       "<td>1.0</td>\n",
       "<td>231.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-191.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-191 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-191 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-191 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-191 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-191 .h2o-table th,\n",
       "#h2o-table-191 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-191 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-191\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.31 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.9927595</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933452</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9933452</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0378788</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0378788</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9925434</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9926536</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9931476</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9918956</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9922824</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9928330</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9913472</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9916245</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9925740</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9909444</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9911735</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9923269</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9838507</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9879670</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9901470</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9795628</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9818103</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9873681</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2041420</td>\n",
       "<td>0.9752992</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9776640</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9848366</td>\n",
       "<td>0.1363636</td>\n",
       "<td>0.5227273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5227273</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9507701</td>\n",
       "<td>2.4830119</td>\n",
       "<td>2.5355021</td>\n",
       "<td>0.9696970</td>\n",
       "<td>0.9670387</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9790784</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7651515</td>\n",
       "<td>148.3011938</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.5041721</td>\n",
       "<td>2.0950413</td>\n",
       "<td>2.4278339</td>\n",
       "<td>0.8181818</td>\n",
       "<td>0.8241082</td>\n",
       "<td>0.9481481</td>\n",
       "<td>0.9411968</td>\n",
       "<td>0.2045455</td>\n",
       "<td>0.9696970</td>\n",
       "<td>109.5041322</td>\n",
       "<td>142.7833895</td>\n",
       "<td>0.9357164</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0196524</td>\n",
       "<td>0.2259358</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.0882353</td>\n",
       "<td>0.1356666</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7791375</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-77.4064171</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0095380</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6524108</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0133408</td>\n",
       "<td>0.6453202</td>\n",
       "<td>0.6508760</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>65.2410808</td>\n",
       "<td>0.6429097</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0069495</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4213534</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0080089</td>\n",
       "<td>0.5550847</td>\n",
       "<td>0.5609835</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.1353364</td>\n",
       "<td>0.4827155</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0050904</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0059943</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4910960</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0040381</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0044963</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4366737</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0029342</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0036564</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3931157</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-192.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-192 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-192 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-192 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-192 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-192 .h2o-table th,\n",
       "#h2o-table-192 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-192 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-192\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th>\n",
       "<th>cv_6_valid</th>\n",
       "<th>cv_7_valid</th>\n",
       "<th>cv_8_valid</th>\n",
       "<th>cv_9_valid</th>\n",
       "<th>cv_10_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9833192</td>\n",
       "<td>0.0189047</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9795919</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9512195</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.9666666</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.993441</td>\n",
       "<td>0.0087639</td>\n",
       "<td>0.9768519</td>\n",
       "<td>0.9795919</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920635</td>\n",
       "<td>0.9947917</td>\n",
       "<td>0.9911111</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0166808</td>\n",
       "<td>0.0189047</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0204082</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0487805</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.6</td>\n",
       "<td>0.6992059</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9720041</td>\n",
       "<td>0.0410269</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.990099</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9859155</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9775637</td>\n",
       "<td>0.0263622</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9756098</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.96</td>\n",
       "<td>0.9655172</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9838923</td>\n",
       "<td>0.0195556</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9615384</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.9836066</td>\n",
       "<td>0.9459459</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6806576</td>\n",
       "<td>0.6947111</td>\n",
       "<td>4.375</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.6363637</td>\n",
       "<td>2.4166667</td>\n",
       "<td>2.9285715</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>3.2222223</td>\n",
       "<td>2.3846154</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9649889</td>\n",
       "<td>0.0394981</td>\n",
       "<td>0.9251849</td>\n",
       "<td>0.9589266</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9001029</td>\n",
       "<td>0.9302605</td>\n",
       "<td>0.9354144</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9856052</td>\n",
       "<td>0.0159761</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9761905</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.96875</td>\n",
       "<td>0.9666666</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0143948</td>\n",
       "<td>0.0159761</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0234150</td>\n",
       "<td>0.0217108</td>\n",
       "<td>0.0305841</td>\n",
       "<td>0.0454511</td>\n",
       "<td>0.0052321</td>\n",
       "<td>0.0047585</td>\n",
       "<td>0.0381614</td>\n",
       "<td>0.0207605</td>\n",
       "<td>0.0674634</td>\n",
       "<td>0.0129099</td>\n",
       "<td>0.0005803</td>\n",
       "<td>0.0082488</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9851783</td>\n",
       "<td>0.0311055</td>\n",
       "<td>0.8986337</td>\n",
       "<td>0.9824162</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9854868</td>\n",
       "<td>0.9933298</td>\n",
       "<td>0.9919167</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9686966</td>\n",
       "<td>0.0517352</td>\n",
       "<td>0.8888889</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8986214</td>\n",
       "<td>0.0914678</td>\n",
       "<td>0.8265484</td>\n",
       "<td>0.8144082</td>\n",
       "<td>0.977777</td>\n",
       "<td>0.980383</td>\n",
       "<td>0.8302926</td>\n",
       "<td>0.9152281</td>\n",
       "<td>0.7301464</td>\n",
       "<td>0.9480187</td>\n",
       "<td>0.9972888</td>\n",
       "<td>0.9661235</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9885714</td>\n",
       "<td>0.0245083</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9333333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1357096</td>\n",
       "<td>0.0745200</td>\n",
       "<td>0.1748832</td>\n",
       "<td>0.2131925</td>\n",
       "<td>0.0723329</td>\n",
       "<td>0.0689816</td>\n",
       "<td>0.1953496</td>\n",
       "<td>0.1440849</td>\n",
       "<td>0.2597372</td>\n",
       "<td>0.1136218</td>\n",
       "<td>0.0240893</td>\n",
       "<td>0.0908229</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9826389</td>\n",
       "<td>0.0293464</td>\n",
       "<td>0.962963</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9259259</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 13 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-193.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-193 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-193 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-193 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-193 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-193 .h2o-table th,\n",
       "#h2o-table-193 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-193 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-193\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 1.991 sec</td>\n",
       "<td>169000 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2109433</td>\n",
       "<td>0.1634058</td>\n",
       "<td>0.8130508</td>\n",
       "<td>0.9817961</td>\n",
       "<td>0.9628444</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0532544</td>\n",
       "<td>0.2219103</td>\n",
       "<td>0.1685375</td>\n",
       "<td>0.7890079</td>\n",
       "<td>0.9886157</td>\n",
       "<td>0.9810854</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0412371</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.011 sec</td>\n",
       "<td>45066 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1843473</td>\n",
       "<td>0.1296516</td>\n",
       "<td>0.8572205</td>\n",
       "<td>0.9881951</td>\n",
       "<td>0.9785739</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.1915001</td>\n",
       "<td>0.1243378</td>\n",
       "<td>0.8428735</td>\n",
       "<td>0.9927140</td>\n",
       "<td>0.9875940</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.034 sec</td>\n",
       "<td>32709 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1658221</td>\n",
       "<td>0.1089020</td>\n",
       "<td>0.8844747</td>\n",
       "<td>0.9906222</td>\n",
       "<td>0.9831777</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.1757758</td>\n",
       "<td>0.1026639</td>\n",
       "<td>0.8676179</td>\n",
       "<td>0.9949909</td>\n",
       "<td>0.9914792</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.055 sec</td>\n",
       "<td>30727 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1570520</td>\n",
       "<td>0.0992638</td>\n",
       "<td>0.8963715</td>\n",
       "<td>0.9918358</td>\n",
       "<td>0.9857957</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1555667</td>\n",
       "<td>0.0836351</td>\n",
       "<td>0.8963082</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9930641</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.075 sec</td>\n",
       "<td>29649 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1464146</td>\n",
       "<td>0.0894230</td>\n",
       "<td>0.9099340</td>\n",
       "<td>0.9931230</td>\n",
       "<td>0.9884188</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1453706</td>\n",
       "<td>0.0763246</td>\n",
       "<td>0.9094551</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.109 sec</td>\n",
       "<td>28166 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1393621</td>\n",
       "<td>0.0830717</td>\n",
       "<td>0.9184016</td>\n",
       "<td>0.9938217</td>\n",
       "<td>0.9899479</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1360821</td>\n",
       "<td>0.0686306</td>\n",
       "<td>0.9206562</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.129 sec</td>\n",
       "<td>27511 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1376766</td>\n",
       "<td>0.0800181</td>\n",
       "<td>0.9203634</td>\n",
       "<td>0.9942630</td>\n",
       "<td>0.9909781</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1258424</td>\n",
       "<td>0.0590951</td>\n",
       "<td>0.9321477</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9977359</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.152 sec</td>\n",
       "<td>26772 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1322235</td>\n",
       "<td>0.0754169</td>\n",
       "<td>0.9265470</td>\n",
       "<td>0.9948147</td>\n",
       "<td>0.9922661</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1217894</td>\n",
       "<td>0.0557746</td>\n",
       "<td>0.9364478</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.174 sec</td>\n",
       "<td>26000 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1265907</td>\n",
       "<td>0.0716402</td>\n",
       "<td>0.9326720</td>\n",
       "<td>0.9950353</td>\n",
       "<td>0.9927280</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1226970</td>\n",
       "<td>0.0578272</td>\n",
       "<td>0.9354971</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:05</td>\n",
       "<td> 2.194 sec</td>\n",
       "<td>25801 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1244544</td>\n",
       "<td>0.0691636</td>\n",
       "<td>0.9349252</td>\n",
       "<td>0.9956605</td>\n",
       "<td>0.9940361</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1178598</td>\n",
       "<td>0.0523910</td>\n",
       "<td>0.9404828</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:06</td>\n",
       "<td> 2.218 sec</td>\n",
       "<td>25121 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1224100</td>\n",
       "<td>0.0676110</td>\n",
       "<td>0.9370456</td>\n",
       "<td>0.9958811</td>\n",
       "<td>0.9943769</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1205717</td>\n",
       "<td>0.0555895</td>\n",
       "<td>0.9377124</td>\n",
       "<td>0.9990893</td>\n",
       "<td>0.9985184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-194.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-194 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-194 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-194 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-194 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-194 .h2o-table th,\n",
       "#h2o-table-194 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-194 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-194\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0478782</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.7252435</td>\n",
       "<td>0.7252435</td>\n",
       "<td>0.0347233</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.7016298</td>\n",
       "<td>0.7016298</td>\n",
       "<td>0.0335928</td></tr>\n",
       "<tr><td>el-salvador-aid.?</td>\n",
       "<td>0.6368201</td>\n",
       "<td>0.6368201</td>\n",
       "<td>0.0304898</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.6236753</td>\n",
       "<td>0.6236753</td>\n",
       "<td>0.0298604</td></tr>\n",
       "<tr><td>water-project-cost-sharing.y</td>\n",
       "<td>0.5995092</td>\n",
       "<td>0.5995092</td>\n",
       "<td>0.0287034</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.n</td>\n",
       "<td>0.5956001</td>\n",
       "<td>0.5956001</td>\n",
       "<td>0.0285163</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.5744899</td>\n",
       "<td>0.5744899</td>\n",
       "<td>0.0275055</td></tr>\n",
       "<tr><td>crime.n</td>\n",
       "<td>0.5695922</td>\n",
       "<td>0.5695922</td>\n",
       "<td>0.0272710</td></tr>\n",
       "<tr><td>education-spending.?</td>\n",
       "<td>0.5183975</td>\n",
       "<td>0.5183975</td>\n",
       "<td>0.0248199</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_1954\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 397 weights/biases, 15.7 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate              rate_rms                momentum    mean_weight            weight_rms          mean_bias              bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  ---------------------  ----------------------  ----------  ---------------------  ------------------  ---------------------  --------------------\n",
       "    1        64       Input    0.0\n",
       "    2        5        Tanh     0.0        0.0   0.0   0.25239849831141326    0.4311668872833252      0.0         -0.015097625058115228  0.1779891848564148  -0.001059561762942135  0.12259435653686523\n",
       "    3        5        Tanh     0.0        0.0   0.0   0.001980850868858397   0.000725434860214591    0.0         -0.06250577300786972   0.4883826971054077  0.06787601578286812    0.03093498945236206\n",
       "    4        5        Tanh     0.0        0.0   0.0   0.011067370460368693   0.01314544677734375     0.0         0.17168970016762614    0.3957357406616211  0.05775672508541674    0.029345683753490448\n",
       "    5        2        Softmax             0.0   0.0   0.0029493304900825024  0.00048607157077640295  0.0         1.6811195679008961     1.0491528511047363  9.71445146547012e-17   0.0905948281288147\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01498420270229417\n",
       "RMSE: 0.12240997795234737\n",
       "LogLoss: 0.06761104157752912\n",
       "Mean Per-Class Error: 0.013496616651956457\n",
       "AUC: 0.9958811415122095\n",
       "AUCPR: 0.9943769422396921\n",
       "Gini: 0.991762283024419\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4126378161683046\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    202         4             0.0194   (4.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       203         135           0.0148   (5.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.412638     0.981273  96\n",
       "max f2                       0.412638     0.987934  96\n",
       "max f0point5                 0.750451     0.982704  87\n",
       "max accuracy                 0.468988     0.985207  94\n",
       "max precision                0.994877     1         0\n",
       "max recall                   0.00511771   1         157\n",
       "max specificity              0.994877     1         0\n",
       "max absolute_mcc             0.412638     0.969218  96\n",
       "max min_per_class_accuracy   0.468988     0.984848  94\n",
       "max mean_per_class_accuracy  0.412638     0.986503  96\n",
       "max tns                      0.994877     206       0\n",
       "max fns                      0.994877     131       0\n",
       "max fps                      0.00232277   206       269\n",
       "max tps                      0.00511771   132       157\n",
       "max tnr                      0.994877     1         0\n",
       "max fnr                      0.994877     0.992424  0\n",
       "max fpr                      0.00232277   1         269\n",
       "max tpr                      0.00511771   1         157\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0118343                   0.99401            2.56061    2.56061            1                0.994358    1                           0.994358            0.030303        0.030303                   156.061  156.061            0.030303\n",
       "2        0.0207101                   0.993617           2.56061    2.56061            1                0.993785    1                           0.994113            0.0227273       0.0530303                  156.061  156.061            0.0530303\n",
       "3        0.035503                    0.992964           2.56061    2.56061            1                0.993087    1                           0.993685            0.0378788       0.0909091                  156.061  156.061            0.0909091\n",
       "4        0.0414201                   0.992843           2.56061    2.56061            1                0.992874    1                           0.993569            0.0151515       0.106061                   156.061  156.061            0.106061\n",
       "5        0.0502959                   0.992637           2.56061    2.56061            1                0.992784    1                           0.993431            0.0227273       0.128788                   156.061  156.061            0.128788\n",
       "6        0.100592                    0.990879           2.56061    2.56061            1                0.991687    1                           0.992559            0.128788        0.257576                   156.061  156.061            0.257576\n",
       "7        0.150888                    0.987487           2.56061    2.56061            1                0.989675    1                           0.991597            0.128788        0.386364                   156.061  156.061            0.386364\n",
       "8        0.201183                    0.982189           2.56061    2.56061            1                0.984769    1                           0.98989             0.128788        0.515152                   156.061  156.061            0.515152\n",
       "9        0.304734                    0.96192            2.48745    2.53575            0.971429         0.975346    0.990291                    0.984948            0.257576        0.772727                   148.745  153.575            0.767873\n",
       "10       0.399408                    0.40982            2.32055    2.48474            0.90625          0.783635    0.97037                     0.937229            0.219697        0.992424                   132.055  148.474            0.973007\n",
       "11       0.5                         0.00814168         0          1.98485            0                0.0588599   0.775148                    0.760516            0               0.992424                   -100     98.4848            0.807958\n",
       "12       0.60355                     0.00459109         0.0731602  1.65686            0.0285714        0.00579964  0.647059                    0.63103             0.00757576      1                          -92.684  65.6863            0.650485\n",
       "13       0.698225                    0.00385417         0          1.4322             0                0.00420491  0.559322                    0.546037            0               1                          -100     43.2203            0.495146\n",
       "14       0.804734                    0.00318513         0          1.24265            0                0.00347941  0.485294                    0.474228            0               1                          -100     24.2647            0.320388\n",
       "15       0.899408                    0.0028688          0          1.11184            0                0.00307169  0.434211                    0.424633            0               1                          -100     11.1842            0.165049\n",
       "16       1                           0.00232277         0          1                  0                0.0026798   0.390533                    0.382188            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.01453753366980719\n",
       "RMSE: 0.12057169514362477\n",
       "LogLoss: 0.0555894978715649\n",
       "Mean Per-Class Error: 0.013888888888888888\n",
       "AUC: 0.9990892531876138\n",
       "AUCPR: 0.9985184307176577\n",
       "Gini: 0.9981785063752275\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5951267160204192\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    61          0             0        (0.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       62          35            0.0103   (1.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.595127     0.985915  31\n",
       "max f2                       0.0974078    0.989011  34\n",
       "max f0point5                 0.595127     0.994318  31\n",
       "max accuracy                 0.595127     0.989691  31\n",
       "max precision                0.994614     1         0\n",
       "max recall                   0.0974078    1         34\n",
       "max specificity              0.994614     1         0\n",
       "max absolute_mcc             0.595127     0.978029  31\n",
       "max min_per_class_accuracy   0.595127     0.972222  31\n",
       "max mean_per_class_accuracy  0.595127     0.986111  31\n",
       "max tns                      0.994614     61        0\n",
       "max fns                      0.994614     35        0\n",
       "max fps                      0.00244387   61        91\n",
       "max tps                      0.0974078    36        34\n",
       "max tnr                      0.994614     1         0\n",
       "max fnr                      0.994614     0.972222  0\n",
       "max fpr                      0.00244387   1         91\n",
       "max tpr                      0.0974078    1         34\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 35.27 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   0.993031           2.69444  2.69444            1                0.994614    1                           0.994614            0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   0.992874           2.69444  2.69444            1                0.992965    1                           0.993789            0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0309278                   0.992809           2.69444  2.69444            1                0.992866    1                           0.993482            0.0277778       0.0833333                  169.444  169.444            0.0833333\n",
       "4        0.0412371                   0.992484           2.69444  2.69444            1                0.992802    1                           0.993312            0.0277778       0.111111                   169.444  169.444            0.111111\n",
       "5        0.0515464                   0.992083           2.69444  2.69444            1                0.992424    1                           0.993134            0.0277778       0.138889                   169.444  169.444            0.138889\n",
       "6        0.103093                    0.991394           2.69444  2.69444            1                0.991892    1                           0.992513            0.138889        0.277778                   169.444  169.444            0.277778\n",
       "7        0.154639                    0.990219           2.69444  2.69444            1                0.990926    1                           0.991984            0.138889        0.416667                   169.444  169.444            0.416667\n",
       "8        0.206186                    0.987643           2.69444  2.69444            1                0.988518    1                           0.991117            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "9        0.298969                    0.908347           2.69444  2.69444            1                0.978444    1                           0.987184            0.25            0.805556                   169.444  169.444            0.805556\n",
       "10       0.402062                    0.0444293          1.88611  2.48718            0.7              0.524914    0.923077                    0.868654            0.194444        1                          88.6111  148.718            0.95082\n",
       "11       0.505155                    0.00728231         0        1.97959            0                0.0147291   0.734694                    0.694383            0               1                          -100     97.9592            0.786885\n",
       "12       0.597938                    0.00498166         0        1.67241            0                0.00559014  0.62069                     0.587502            0               1                          -100     67.2414            0.639344\n",
       "13       0.701031                    0.0040196          0        1.42647            0                0.00453963  0.529412                    0.501772            0               1                          -100     42.6471            0.47541\n",
       "14       0.793814                    0.00328021         0        1.25974            0                0.00362812  0.467532                    0.443547            0               1                          -100     25.974             0.327869\n",
       "15       0.896907                    0.00301362         0        1.11494            0                0.00315895  0.413793                    0.392928            0               1                          -100     11.4943            0.163934\n",
       "16       1                           0.00244387         0        1                  0                0.00265384  0.371134                    0.352693            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.02516950720561065\n",
       "RMSE: 0.1586490063177537\n",
       "LogLoss: 0.10011817012447274\n",
       "Mean Per-Class Error: 0.025632538982053546\n",
       "AUC: 0.990879670491321\n",
       "AUCPR: 0.9871645918298849\n",
       "Gini: 0.981759340982642\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3774709315100019\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    197         9             0.0437   (9.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       198         140           0.0296   (10.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.377471     0.963235  134\n",
       "max f2                       0.377471     0.980539  134\n",
       "max f0point5                 0.737088     0.966258  124\n",
       "max accuracy                 0.737088     0.970414  124\n",
       "max precision                0.994721     1         0\n",
       "max recall                   0.00693549   1         231\n",
       "max specificity              0.994721     1         0\n",
       "max absolute_mcc             0.377471     0.939656  134\n",
       "max min_per_class_accuracy   0.571266     0.966019  129\n",
       "max mean_per_class_accuracy  0.377471     0.974367  134\n",
       "max tns                      0.994721     206       0\n",
       "max fns                      0.994721     131       0\n",
       "max fps                      0.00293421   206       326\n",
       "max tps                      0.00693549   132       231\n",
       "max tnr                      0.994721     1         0\n",
       "max fnr                      0.994721     0.992424  0\n",
       "max fpr                      0.00293421   1         326\n",
       "max tpr                      0.00693549   1         231\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.31 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0147929                   0.99276            2.56061    2.56061            1                0.993345    1                           0.993345            0.0378788       0.0378788                  156.061   156.061            0.0378788\n",
       "2        0.0207101                   0.992543           2.56061    2.56061            1                0.992654    1                           0.993148            0.0151515       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.991896           2.56061    2.56061            1                0.992282    1                           0.992833            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.991347           2.56061    2.56061            1                0.991625    1                           0.992574            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.990944           2.56061    2.56061            1                0.991173    1                           0.992327            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.983851           2.56061    2.56061            1                0.987967    1                           0.990147            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.979563           2.56061    2.56061            1                0.98181     1                           0.987368            0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.204142                    0.975299           2.56061    2.56061            1                0.977664    1                           0.984837            0.136364        0.522727                   156.061   156.061            0.522727\n",
       "9        0.301775                    0.95077            2.48301    2.5355             0.969697         0.967039    0.990196                    0.979078            0.242424        0.765152                   148.301   153.55             0.760297\n",
       "10       0.399408                    0.504172           2.09504    2.42783            0.818182         0.824108    0.948148                    0.941197            0.204545        0.969697                   109.504   142.783            0.935716\n",
       "11       0.5                         0.0196524          0.225936   1.98485            0.0882353        0.135667    0.775148                    0.779137            0.0227273       0.992424                   -77.4064  98.4848            0.807958\n",
       "12       0.600592                    0.00953797         0          1.65241            0                0.0133408   0.64532                     0.650876            0               0.992424                   -100      65.2411            0.64291\n",
       "13       0.698225                    0.00694953         0          1.42135            0                0.00800887  0.555085                    0.560984            0               0.992424                   -100      42.1353            0.482716\n",
       "14       0.798817                    0.00509042         0.0753119  1.25185            0.0294118        0.00599435  0.488889                    0.491096            0.00757576      1                          -92.4688  25.1852            0.330097\n",
       "15       0.899408                    0.00403815         0          1.11184            0                0.00449626  0.434211                    0.436674            0               1                          -100      11.1842            0.165049\n",
       "16       1                           0.00293421         0          1                  0                0.00365637  0.390533                    0.393116            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid     cv_10_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------  -------------\n",
       "accuracy                 0.9833192    0.018904721  0.9714286     0.97959185    1.0           1.0           0.9512195     0.96428573    0.96666664    1.0           1.0            1.0\n",
       "aic                      nan          0.0          nan           nan           nan           nan           nan           nan           nan           nan           nan            nan\n",
       "auc                      0.993441     0.008763889  0.9768519     0.97959185    1.0           1.0           0.99206346    0.9947917     0.9911111     1.0           1.0            1.0\n",
       "err                      0.01668077   0.018904721  0.028571429   0.020408163   0.0           0.0           0.048780486   0.035714287   0.033333335   0.0           0.0            0.0\n",
       "err_count                0.6          0.6992059    1.0           1.0           0.0           0.0           2.0           1.0           1.0           0.0           0.0            0.0\n",
       "f0point5                 0.9720041    0.041026853  0.90909094    0.990099      1.0           1.0           0.8974359     0.9375        0.9859155     1.0           1.0            1.0\n",
       "f1                       0.9775637    0.026362246  0.9411765     0.9756098     1.0           1.0           0.93333334    0.96          0.9655172     1.0           1.0            1.0\n",
       "f2                       0.9838923    0.01955557   0.9756098     0.96153843    1.0           1.0           0.9722222     0.9836066     0.9459459     1.0           1.0            1.0\n",
       "lift_top_group           2.6806576    0.6947111    4.375         2.3333333     2.6363637     2.4166667     2.9285715     2.3333333     2.0           2.1764705     3.2222223      2.3846154\n",
       "loglikelihood            nan          0.0          nan           nan           nan           nan           nan           nan           nan           nan           nan            nan\n",
       "---                      ---          ---          ---           ---           ---           ---           ---           ---           ---           ---           ---            ---\n",
       "mcc                      0.96498895   0.039498113  0.9251849     0.9589266     1.0           1.0           0.90010285    0.93026054    0.9354144     1.0           1.0            1.0\n",
       "mean_per_class_accuracy  0.9856052    0.01597613   0.9814815     0.97619045    1.0           1.0           0.962963      0.96875       0.96666664    1.0           1.0            1.0\n",
       "mean_per_class_error     0.014394841  0.01597613   0.018518519   0.023809524   0.0           0.0           0.037037037   0.03125       0.033333335   0.0           0.0            0.0\n",
       "mse                      0.023415001  0.021710802  0.030584117   0.045451052   0.0052320543  0.004758466   0.03816145    0.020760467   0.067463405   0.012909903   0.00058029476  0.008248806\n",
       "pr_auc                   0.9851783    0.031105476  0.8986337     0.9824162     1.0           1.0           0.9854868     0.99332976    0.9919167     1.0           1.0            1.0\n",
       "precision                0.9686966    0.051735222  0.8888889     1.0           1.0           1.0           0.875         0.9230769     1.0           1.0           1.0            1.0\n",
       "r2                       0.89862144   0.09146781   0.8265484     0.8144082     0.977777      0.980383      0.8302926     0.91522807    0.73014635    0.94801867    0.99728876     0.9661235\n",
       "recall                   0.9885714    0.024508266  1.0           0.95238096    1.0           1.0           1.0           1.0           0.93333334    1.0           1.0            1.0\n",
       "rmse                     0.1357096    0.07452001   0.17488316    0.21319252    0.07233294    0.06898163    0.19534956    0.14408493    0.2597372     0.11362176    0.024089308    0.090822935\n",
       "specificity              0.9826389    0.029346358  0.962963      1.0           1.0           1.0           0.9259259     0.9375        1.0           1.0           1.0            1.0\n",
       "[22 rows x 13 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:49:05  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:49:05  1.991 sec   169000 obs/sec    1         1             338        0.210943         0.163406            0.813051       0.981796        0.962844           2.56061          0.0532544                        0.22191            0.168537              0.789008         0.988616          0.981085             2.69444            0.0412371\n",
       "    2025-05-26 14:49:05  2.011 sec   45066 obs/sec     2         2             676        0.184347         0.129652            0.857221       0.988195        0.978574           2.56061          0.0414201                        0.1915             0.124338              0.842874         0.992714          0.987594             2.69444            0.0309278\n",
       "    2025-05-26 14:49:05  2.034 sec   32709 obs/sec     3         3             1014       0.165822         0.108902            0.884475       0.990622        0.983178           2.56061          0.0325444                        0.175776           0.102664              0.867618         0.994991          0.991479             2.69444            0.0309278\n",
       "    2025-05-26 14:49:05  2.055 sec   30727 obs/sec     4         4             1352       0.157052         0.0992638           0.896371       0.991836        0.985796           2.56061          0.0236686                        0.155567           0.0836351             0.896308         0.995902          0.993064             2.69444            0.0309278\n",
       "    2025-05-26 14:49:05  2.075 sec   29649 obs/sec     5         5             1690       0.146415         0.089423            0.909934       0.993123        0.988419           2.56061          0.0207101                        0.145371           0.0763246             0.909455         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:49:05  2.109 sec   28166 obs/sec     6         6             2028       0.139362         0.0830717           0.918402       0.993822        0.989948           2.56061          0.0207101                        0.136082           0.0686306             0.920656         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:49:05  2.129 sec   27511 obs/sec     7         7             2366       0.137677         0.0800181           0.920363       0.994263        0.990978           2.56061          0.0177515                        0.125842           0.0590951             0.932148         0.998634          0.997736             2.69444            0.0206186\n",
       "    2025-05-26 14:49:05  2.152 sec   26772 obs/sec     8         8             2704       0.132223         0.0754169           0.926547       0.994815        0.992266           2.56061          0.0177515                        0.121789           0.0557746             0.936448         0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:49:05  2.174 sec   26000 obs/sec     9         9             3042       0.126591         0.0716402           0.932672       0.995035        0.992728           2.56061          0.0177515                        0.122697           0.0578272             0.935497         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:49:05  2.194 sec   25801 obs/sec     10        10            3380       0.124454         0.0691636           0.934925       0.99566         0.994036           2.56061          0.0147929                        0.11786            0.052391              0.940483         0.999089          0.998518             2.69444            0.0103093\n",
       "    2025-05-26 14:49:06  2.218 sec   25121 obs/sec     11        11            3718       0.12241          0.067611            0.937046       0.995881        0.994377           2.56061          0.0147929                        0.120572           0.0555895             0.937712         0.999089          0.998518             2.69444            0.0103093\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.04787818652837487\n",
       "physician-fee-freeze.n                              0.7252435088157654     0.7252435088157654   0.034723343993574296\n",
       "synfuels-corporation-cutback.n                      0.7016297578811646     0.7016297578811646   0.033592760421692895\n",
       "el-salvador-aid.?                                   0.6368200778961182     0.6368200778961182   0.030489790474524558\n",
       "adoption-of-the-budget-resolution.y                 0.6236753463745117     0.6236753463745117   0.029860444566867678\n",
       "water-project-cost-sharing.y                        0.5995091795921326     0.5995091795921326   0.02870341232598511\n",
       "anti-satellite-test-ban.n                           0.5956000685691833     0.5956000685691833   0.02851625117926822\n",
       "mx-missile.n                                        0.5744898915290833     0.5744898915290833   0.02750553418529529\n",
       "crime.n                                             0.5695921778678894     0.5695921778678894   0.027271040537062082\n",
       "education-spending.?                                0.5183975100517273     0.5183975100517273   0.024819932682101684\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[5,5,5], nfolds=10, activation=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69203d6813f5baa1",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [20,20,20], cross folds = 10, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "763306693f577931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_2232\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-195.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-195 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-195 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-195 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-195 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-195 .h2o-table th,\n",
       "#h2o-table-195 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-195 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-195\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2528265</td>\n",
       "<td>0.4309566</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0006878</td>\n",
       "<td>0.1583468</td>\n",
       "<td>-0.0028398</td>\n",
       "<td>0.0332660</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0041718</td>\n",
       "<td>0.0040898</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0050448</td>\n",
       "<td>0.2223840</td>\n",
       "<td>0.0081535</td>\n",
       "<td>0.0276089</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>20</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0047794</td>\n",
       "<td>0.0039462</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0157751</td>\n",
       "<td>0.2144551</td>\n",
       "<td>0.0048399</td>\n",
       "<td>0.0145661</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0050722</td>\n",
       "<td>0.0019112</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0369950</td>\n",
       "<td>1.1557760</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0100588</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.013591574998182653\n",
       "RMSE: 0.11658291040363786\n",
       "LogLoss: 0.04653735974662889\n",
       "Mean Per-Class Error: 0.01106943218593704\n",
       "AUC: 0.9989702853780523\n",
       "AUCPR: 0.9983648341082199\n",
       "Gini: 0.9979405707561047</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-196.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-196 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-196 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-196 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-196 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-196 .h2o-table th,\n",
       "#h2o-table-196 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-196 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-196\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3079197538244427</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>203.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0146</td>\n",
       "<td> (3.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0076</td>\n",
       "<td> (1.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>204.0</td>\n",
       "<td>134.0</td>\n",
       "<td>0.0118</td>\n",
       "<td> (4.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-197.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-197 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-197 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-197 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-197 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-197 .h2o-table th,\n",
       "#h2o-table-197 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-197 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-197\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9849624</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1789347</td>\n",
       "<td>0.9909910</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3321215</td>\n",
       "<td>0.9848485</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3321215</td>\n",
       "<td>0.9881657</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999801</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1789347</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999801</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9752822</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9854369</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3079198</td>\n",
       "<td>0.9889306</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999801</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999801</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000033</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.1789347</td>\n",
       "<td>132.0</td>\n",
       "<td>99.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999801</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999801</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000033</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.1789347</td>\n",
       "<td>1.0</td>\n",
       "<td>99.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-198.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-198 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-198 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-198 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-198 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-198 .h2o-table th,\n",
       "#h2o-table-198 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-198 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-198\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.9999394</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999475</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999475</td>\n",
       "<td>0.0378788</td>\n",
       "<td>0.0378788</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0378788</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9998462</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998827</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999290</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9998155</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998286</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998925</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0443787</td>\n",
       "<td>0.9997725</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997823</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998631</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.1136364</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1136364</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9997356</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997399</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998486</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9992784</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995291</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996888</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1568047</td>\n",
       "<td>0.9976363</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985426</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992779</td>\n",
       "<td>0.1439394</td>\n",
       "<td>0.4015152</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.4015152</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2071006</td>\n",
       "<td>0.9940715</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9955869</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9983815</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5303030</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9700510</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9875674</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9949889</td>\n",
       "<td>0.2424242</td>\n",
       "<td>0.7727273</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7727273</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.2783261</td>\n",
       "<td>2.2502296</td>\n",
       "<td>2.4847363</td>\n",
       "<td>0.8787879</td>\n",
       "<td>0.7778914</td>\n",
       "<td>0.9703704</td>\n",
       "<td>0.9419206</td>\n",
       "<td>0.2196970</td>\n",
       "<td>0.9924242</td>\n",
       "<td>125.0229568</td>\n",
       "<td>148.4736251</td>\n",
       "<td>0.9730068</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0043331</td>\n",
       "<td>0.0753119</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0577081</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7640317</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0006593</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016236</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6363377</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0001915</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003842</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5474120</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0000800</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001240</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4784943</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000289</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000534</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4249844</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000033</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000158</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3822361</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.025036851139801974\n",
       "RMSE: 0.1582303736322517\n",
       "LogLoss: 0.0878856002549917\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9972677595628415\n",
       "AUCPR: 0.9955991765061915\n",
       "Gini: 0.994535519125683</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-199.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-199 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-199 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-199 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-199 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-199 .h2o-table th,\n",
       "#h2o-table-199 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-199 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-199\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1662999056749567</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0164</td>\n",
       "<td> (1.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-200.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-200 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-200 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-200 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-200 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-200 .h2o-table th,\n",
       "#h2o-table-200 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-200 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-200\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.0227605</td>\n",
       "<td>0.9782609</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6785613</td>\n",
       "<td>0.9821429</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9793814</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0227605</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9558288</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1662999</td>\n",
       "<td>0.9779144</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9998623</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9998623</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000023</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0227605</td>\n",
       "<td>36.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9998623</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000023</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0227605</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-201.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-201 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-201 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-201 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-201 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-201 .h2o-table th,\n",
       "#h2o-table-201 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-201 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-201\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.43 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9998369</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998623</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998623</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9998129</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998358</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998491</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9998109</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998109</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998262</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9997116</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998262</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1388889</td>\n",
       "<td>-100.0</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9994207</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996258</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997260</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9987753</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9990925</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995148</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9983089</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9985800</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992811</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9069151</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9810874</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9936348</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.0448873</td>\n",
       "<td>1.6166667</td>\n",
       "<td>2.4180912</td>\n",
       "<td>0.6</td>\n",
       "<td>0.4464004</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.8533183</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.9722222</td>\n",
       "<td>61.6666667</td>\n",
       "<td>141.8091168</td>\n",
       "<td>0.9066485</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0027758</td>\n",
       "<td>0.2694444</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0096030</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.6811315</td>\n",
       "<td>0.0277778</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.0555556</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0006094</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0016215</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.5756903</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0002673</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003774</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.4910854</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.8041237</td>\n",
       "<td>0.0001040</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2435897</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001625</td>\n",
       "<td>0.4615385</td>\n",
       "<td>0.4281466</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>24.3589744</td>\n",
       "<td>0.3114754</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000355</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000602</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.3838618</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000023</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000160</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3442901</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.027379532890430474\n",
       "RMSE: 0.16546761885768005\n",
       "LogLoss: 0.09309713385791729\n",
       "Mean Per-Class Error: 0.031075316269491025\n",
       "AUC: 0.9944836716681378\n",
       "AUCPR: 0.9916467621875895\n",
       "Gini: 0.9889673433362756</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-202.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-202 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-202 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-202 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-202 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-202 .h2o-table th,\n",
       "#h2o-table-202 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-202 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-202\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5718110822865685</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>201.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0243</td>\n",
       "<td> (5.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>5.0</td>\n",
       "<td>127.0</td>\n",
       "<td>0.0379</td>\n",
       "<td> (5.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>206.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.0296</td>\n",
       "<td> (10.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-203.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-203 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-203 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-203 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-203 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-203 .h2o-table th,\n",
       "#h2o-table-203 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-203 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-203\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.5718111</td>\n",
       "<td>0.9621212</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1600816</td>\n",
       "<td>0.9689349</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6331709</td>\n",
       "<td>0.96875</td>\n",
       "<td>121.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5718111</td>\n",
       "<td>0.9704142</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999087</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0250863</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999087</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5718111</td>\n",
       "<td>0.9378494</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5718111</td>\n",
       "<td>0.9621212</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5718111</td>\n",
       "<td>0.9689247</td>\n",
       "<td>126.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999087</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999087</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000132</td>\n",
       "<td>206.0</td>\n",
       "<td>326.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0250863</td>\n",
       "<td>132.0</td>\n",
       "<td>159.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999087</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999087</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000132</td>\n",
       "<td>1.0</td>\n",
       "<td>326.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0250863</td>\n",
       "<td>1.0</td>\n",
       "<td>159.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-204.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-204 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-204 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-204 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-204 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-204 .h2o-table th,\n",
       "#h2o-table-204 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-204 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-204\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.04 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9997547</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998350</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998350</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9996717</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997353</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997923</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9994579</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995951</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997206</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9994037</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9994364</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996597</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9993311</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9993676</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996081</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9980501</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9988669</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9992375</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9955794</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9970197</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9984983</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9913440</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9938661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9973402</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9539806</td>\n",
       "<td>2.4852941</td>\n",
       "<td>2.5355021</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9805188</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9917331</td>\n",
       "<td>0.25</td>\n",
       "<td>0.7651515</td>\n",
       "<td>148.5294118</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4105521</td>\n",
       "<td>2.0174472</td>\n",
       "<td>2.4088664</td>\n",
       "<td>0.7878788</td>\n",
       "<td>0.7751318</td>\n",
       "<td>0.9407407</td>\n",
       "<td>0.9387861</td>\n",
       "<td>0.1969697</td>\n",
       "<td>0.9621212</td>\n",
       "<td>101.7447199</td>\n",
       "<td>140.8866442</td>\n",
       "<td>0.9232863</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0160923</td>\n",
       "<td>0.3765597</td>\n",
       "<td>2.0</td>\n",
       "<td>0.1470588</td>\n",
       "<td>0.1441547</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.7789194</td>\n",
       "<td>0.0378788</td>\n",
       "<td>1.0</td>\n",
       "<td>-62.3440285</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0023872</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0066691</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6495770</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0008592</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0015621</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5589648</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0003678</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005875</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4886506</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0001284</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002290</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4340245</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>1.319e-05</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000557</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3903708</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-205.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-205 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-205 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-205 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-205 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-205 .h2o-table th,\n",
       "#h2o-table-205 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-205 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-205\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th>\n",
       "<th>cv_6_valid</th>\n",
       "<th>cv_7_valid</th>\n",
       "<th>cv_8_valid</th>\n",
       "<th>cv_9_valid</th>\n",
       "<th>cv_10_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9797434</td>\n",
       "<td>0.0264320</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9183673</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9677419</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9941482</td>\n",
       "<td>0.0088146</td>\n",
       "<td>0.9861111</td>\n",
       "<td>0.9727891</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9920635</td>\n",
       "<td>0.9947917</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9957265</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0202567</td>\n",
       "<td>0.0264320</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0816327</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0322581</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.8</td>\n",
       "<td>1.2292726</td>\n",
       "<td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.967823</td>\n",
       "<td>0.0401077</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9047619</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9848485</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.942029</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.9731864</td>\n",
       "<td>0.0328030</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9047619</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.96</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9790856</td>\n",
       "<td>0.0318852</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9047619</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.942029</td>\n",
       "<td>0.9836066</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9848485</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6806576</td>\n",
       "<td>0.6947111</td>\n",
       "<td>4.375</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.6363637</td>\n",
       "<td>2.4166667</td>\n",
       "<td>2.9285715</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>3.2222223</td>\n",
       "<td>2.3846154</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9571513</td>\n",
       "<td>0.0545711</td>\n",
       "<td>0.9251849</td>\n",
       "<td>0.8333333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9462601</td>\n",
       "<td>0.9302605</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9364743</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9803406</td>\n",
       "<td>0.0267626</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.96875</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9722222</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0196594</td>\n",
       "<td>0.0267626</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0247629</td>\n",
       "<td>0.0207088</td>\n",
       "<td>0.0359066</td>\n",
       "<td>0.0697548</td>\n",
       "<td>0.0160161</td>\n",
       "<td>0.0079810</td>\n",
       "<td>0.0348682</td>\n",
       "<td>0.0384324</td>\n",
       "<td>0.0179589</td>\n",
       "<td>0.0025348</td>\n",
       "<td>0.0020273</td>\n",
       "<td>0.0221485</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9890385</td>\n",
       "<td>0.0174482</td>\n",
       "<td>0.9493169</td>\n",
       "<td>0.9664294</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.987009</td>\n",
       "<td>0.9933298</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9942994</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9645299</td>\n",
       "<td>0.0469680</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.9047619</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.8916133</td>\n",
       "<td>0.0901424</td>\n",
       "<td>0.7963629</td>\n",
       "<td>0.7151681</td>\n",
       "<td>0.9319720</td>\n",
       "<td>0.9670981</td>\n",
       "<td>0.844938</td>\n",
       "<td>0.8430678</td>\n",
       "<td>0.9281644</td>\n",
       "<td>0.9897938</td>\n",
       "<td>0.9905281</td>\n",
       "<td>0.9090396</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9833333</td>\n",
       "<td>0.0355818</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9047619</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1430471</td>\n",
       "<td>0.0691245</td>\n",
       "<td>0.1894904</td>\n",
       "<td>0.2641113</td>\n",
       "<td>0.1265548</td>\n",
       "<td>0.0893363</td>\n",
       "<td>0.1867303</td>\n",
       "<td>0.1960418</td>\n",
       "<td>0.1340108</td>\n",
       "<td>0.0503465</td>\n",
       "<td>0.0450252</td>\n",
       "<td>0.1488238</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9773479</td>\n",
       "<td>0.0304326</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.9285714</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9444444</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 13 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-206.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-206 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-206 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-206 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-206 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-206 .h2o-table th,\n",
       "#h2o-table-206 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-206 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-206\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.625 sec</td>\n",
       "<td>56333 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.2207238</td>\n",
       "<td>0.1613350</td>\n",
       "<td>0.7953129</td>\n",
       "<td>0.9839291</td>\n",
       "<td>0.9748325</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0591716</td>\n",
       "<td>0.2616883</td>\n",
       "<td>0.2390545</td>\n",
       "<td>0.7065868</td>\n",
       "<td>0.9685792</td>\n",
       "<td>0.9593676</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0927835</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.649 sec</td>\n",
       "<td>29391 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1836335</td>\n",
       "<td>0.1144381</td>\n",
       "<td>0.8583240</td>\n",
       "<td>0.9930127</td>\n",
       "<td>0.9892854</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0384615</td>\n",
       "<td>0.2193056</td>\n",
       "<td>0.1600240</td>\n",
       "<td>0.7939319</td>\n",
       "<td>0.9840619</td>\n",
       "<td>0.9765677</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0618557</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.686 sec</td>\n",
       "<td>22043 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1605320</td>\n",
       "<td>0.0894164</td>\n",
       "<td>0.8917281</td>\n",
       "<td>0.9956605</td>\n",
       "<td>0.9932067</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0266272</td>\n",
       "<td>0.1877236</td>\n",
       "<td>0.1206921</td>\n",
       "<td>0.8490098</td>\n",
       "<td>0.9922587</td>\n",
       "<td>0.9889741</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.728 sec</td>\n",
       "<td>19314 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1506416</td>\n",
       "<td>0.0786731</td>\n",
       "<td>0.9046584</td>\n",
       "<td>0.9969109</td>\n",
       "<td>0.9950810</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1751166</td>\n",
       "<td>0.1041747</td>\n",
       "<td>0.8686090</td>\n",
       "<td>0.9936248</td>\n",
       "<td>0.9906904</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.757 sec</td>\n",
       "<td>18988 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1404111</td>\n",
       "<td>0.0679485</td>\n",
       "<td>0.9171686</td>\n",
       "<td>0.9972786</td>\n",
       "<td>0.9957266</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1673279</td>\n",
       "<td>0.0976448</td>\n",
       "<td>0.8800369</td>\n",
       "<td>0.9945355</td>\n",
       "<td>0.9917333</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.789 sec</td>\n",
       "<td>18270 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1364133</td>\n",
       "<td>0.0656268</td>\n",
       "<td>0.9218183</td>\n",
       "<td>0.9978670</td>\n",
       "<td>0.9965925</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1773899</td>\n",
       "<td>0.1100505</td>\n",
       "<td>0.8651755</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.825 sec</td>\n",
       "<td>17397 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1260746</td>\n",
       "<td>0.0565443</td>\n",
       "<td>0.9332198</td>\n",
       "<td>0.9979773</td>\n",
       "<td>0.9967656</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1538515</td>\n",
       "<td>0.0798664</td>\n",
       "<td>0.8985822</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.856 sec</td>\n",
       "<td>17006 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1254440</td>\n",
       "<td>0.0540615</td>\n",
       "<td>0.9338862</td>\n",
       "<td>0.9981980</td>\n",
       "<td>0.9971564</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1674418</td>\n",
       "<td>0.0949686</td>\n",
       "<td>0.8798735</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.886 sec</td>\n",
       "<td>16900 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1282885</td>\n",
       "<td>0.0560890</td>\n",
       "<td>0.9308539</td>\n",
       "<td>0.9984187</td>\n",
       "<td>0.9975124</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1761549</td>\n",
       "<td>0.1148253</td>\n",
       "<td>0.8670463</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9936564</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0309278</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.916 sec</td>\n",
       "<td>16732 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1149926</td>\n",
       "<td>0.0473662</td>\n",
       "<td>0.9444439</td>\n",
       "<td>0.9987864</td>\n",
       "<td>0.9980953</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1552790</td>\n",
       "<td>0.0833018</td>\n",
       "<td>0.8966914</td>\n",
       "<td>0.9963570</td>\n",
       "<td>0.9943960</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:15</td>\n",
       "<td> 1.946 sec</td>\n",
       "<td>16672 obs/sec</td>\n",
       "<td>11.0</td>\n",
       "<td>11</td>\n",
       "<td>3718.0</td>\n",
       "<td>0.1165829</td>\n",
       "<td>0.0465374</td>\n",
       "<td>0.9428966</td>\n",
       "<td>0.9989703</td>\n",
       "<td>0.9983648</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.1582304</td>\n",
       "<td>0.0878856</td>\n",
       "<td>0.8927269</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9955992</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-207.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-207 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-207 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-207 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-207 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-207 .h2o-table th,\n",
       "#h2o-table-207 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-207 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-207\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>el-salvador-aid.?</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270212</td></tr>\n",
       "<tr><td>duty-free-exports.?</td>\n",
       "<td>0.9811991</td>\n",
       "<td>0.9811991</td>\n",
       "<td>0.0265132</td></tr>\n",
       "<tr><td>crime.?</td>\n",
       "<td>0.9726504</td>\n",
       "<td>0.9726504</td>\n",
       "<td>0.0262822</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9533860</td>\n",
       "<td>0.9533860</td>\n",
       "<td>0.0257617</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.?</td>\n",
       "<td>0.9520403</td>\n",
       "<td>0.9520403</td>\n",
       "<td>0.0257253</td></tr>\n",
       "<tr><td>superfund-right-to-sue.y</td>\n",
       "<td>0.9136627</td>\n",
       "<td>0.9136627</td>\n",
       "<td>0.0246883</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.y</td>\n",
       "<td>0.9100732</td>\n",
       "<td>0.9100732</td>\n",
       "<td>0.0245913</td></tr>\n",
       "<tr><td>physician-fee-freeze.y</td>\n",
       "<td>0.8963868</td>\n",
       "<td>0.8963868</td>\n",
       "<td>0.0242215</td></tr>\n",
       "<tr><td>mx-missile.y</td>\n",
       "<td>0.8612557</td>\n",
       "<td>0.8612557</td>\n",
       "<td>0.0232722</td></tr>\n",
       "<tr><td>mx-missile.n</td>\n",
       "<td>0.8610666</td>\n",
       "<td>0.8610666</td>\n",
       "<td>0.0232671</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_2232\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 2,182 weights/biases, 37.2 KB, 3,718 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate              rate_rms               momentum    mean_weight             weight_rms           mean_bias              bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  ---------------------  ---------------------  ----------  ----------------------  -------------------  ---------------------  --------------------\n",
       "    1        64       Input    0.0\n",
       "    2        20       Tanh     0.0        0.0   0.0   0.252826455190916      0.4309566020965576     0.0         -0.0006878006061526776  0.15834683179855347  -0.002839801723190552  0.03326600790023804\n",
       "    3        20       Tanh     0.0        0.0   0.0   0.004171751558678807   0.004089832305908203   0.0         0.005044844619114883    0.22238397598266602  0.008153478113334615   0.027608871459960938\n",
       "    4        20       Tanh     0.0        0.0   0.0   0.004779363527632086   0.003946200013160706   0.0         0.015775103969644988    0.21445506811141968  0.004839899927885796   0.014566101133823395\n",
       "    5        2        Softmax             0.0   0.0   0.0050722042447887365  0.0019112210720777512  0.0         0.03699496565386653     1.155776023864746    0.0                    0.010058801621198654\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.013591574998182653\n",
       "RMSE: 0.11658291040363786\n",
       "LogLoss: 0.04653735974662889\n",
       "Mean Per-Class Error: 0.01106943218593704\n",
       "AUC: 0.9989702853780523\n",
       "AUCPR: 0.9983648341082199\n",
       "Gini: 0.9979405707561047\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3079197538244427\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    203         3             0.0146   (3.0/206.0)\n",
       "republican  1           131           0.0076   (1.0/132.0)\n",
       "Total       204         134           0.0118   (4.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.30792      0.984962  95\n",
       "max f2                       0.178935     0.990991  99\n",
       "max f0point5                 0.332121     0.984848  93\n",
       "max accuracy                 0.332121     0.988166  93\n",
       "max precision                0.99998      1         0\n",
       "max recall                   0.178935     1         99\n",
       "max specificity              0.99998      1         0\n",
       "max absolute_mcc             0.30792      0.975282  95\n",
       "max min_per_class_accuracy   0.30792      0.985437  95\n",
       "max mean_per_class_accuracy  0.30792      0.988931  95\n",
       "max tns                      0.99998      206       0\n",
       "max fns                      0.99998      131       0\n",
       "max fps                      3.32585e-06  206       269\n",
       "max tps                      0.178935     132       99\n",
       "max tnr                      0.99998      1         0\n",
       "max fnr                      0.99998      0.992424  0\n",
       "max fpr                      3.32585e-06  1         269\n",
       "max tpr                      0.178935     1         99\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 38.22 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0147929                   0.999939           2.56061    2.56061            1                0.999948     1                           0.999948            0.0378788       0.0378788                  156.061   156.061            0.0378788\n",
       "2        0.0207101                   0.999846           2.56061    2.56061            1                0.999883     1                           0.999929            0.0151515       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.999815           2.56061    2.56061            1                0.999829     1                           0.999892            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0443787                   0.999772           2.56061    2.56061            1                0.999782     1                           0.999863            0.030303        0.113636                   156.061   156.061            0.113636\n",
       "5        0.0502959                   0.999736           2.56061    2.56061            1                0.99974      1                           0.999849            0.0151515       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.999278           2.56061    2.56061            1                0.999529     1                           0.999689            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.156805                    0.997636           2.56061    2.56061            1                0.998543     1                           0.999278            0.143939        0.401515                   156.061   156.061            0.401515\n",
       "8        0.207101                    0.994071           2.56061    2.56061            1                0.995587     1                           0.998382            0.128788        0.530303                   156.061   156.061            0.530303\n",
       "9        0.301775                    0.970051           2.56061    2.56061            1                0.987567     1                           0.994989            0.242424        0.772727                   156.061   156.061            0.772727\n",
       "10       0.399408                    0.278326           2.25023    2.48474            0.878788         0.777891     0.97037                     0.941921            0.219697        0.992424                   125.023   148.474            0.973007\n",
       "11       0.5                         0.00433311         0.0753119  2                  0.0294118        0.0577081    0.781065                    0.764032            0.00757576      1                          -92.4688  100                0.820388\n",
       "12       0.600592                    0.000659332        0          1.66502            0                0.00162364   0.650246                    0.636338            0               1                          -100      66.5025            0.65534\n",
       "13       0.698225                    0.000191481        0          1.4322             0                0.000384212  0.559322                    0.547412            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    7.99512e-05        0          1.25185            0                0.000124008  0.488889                    0.478494            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    2.89116e-05        0          1.11184            0                5.34013e-05  0.434211                    0.424984            0               1                          -100      11.1842            0.165049\n",
       "16       1                           3.32585e-06        0          1                  0                1.57549e-05  0.390533                    0.382236            0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.025036851139801974\n",
       "RMSE: 0.1582303736322517\n",
       "LogLoss: 0.0878856002549917\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9972677595628415\n",
       "AUCPR: 0.9955991765061915\n",
       "Gini: 0.994535519125683\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.1662999056749567\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    60          1             0.0164   (1.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       61          36            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.1663       0.972222  32\n",
       "max f2                       0.0227605    0.978261  36\n",
       "max f0point5                 0.678561     0.982143  29\n",
       "max accuracy                 0.1663       0.979381  32\n",
       "max precision                0.999862     1         0\n",
       "max recall                   0.0227605    1         36\n",
       "max specificity              0.999862     1         0\n",
       "max absolute_mcc             0.1663       0.955829  32\n",
       "max min_per_class_accuracy   0.1663       0.972222  32\n",
       "max mean_per_class_accuracy  0.1663       0.977914  32\n",
       "max tns                      0.999862     61        0\n",
       "max fns                      0.999862     35        0\n",
       "max fps                      2.30685e-06  61        91\n",
       "max tps                      0.0227605    36        36\n",
       "max tnr                      0.999862     1         0\n",
       "max fnr                      0.999862     0.972222  0\n",
       "max fpr                      2.30685e-06  1         91\n",
       "max tpr                      0.0227605    1         36\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 34.43 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0103093                   0.999837           2.69444   2.69444            1                0.999862     1                           0.999862            0.0277778       0.0277778                  169.444   169.444            0.0277778\n",
       "2        0.0206186                   0.999813           2.69444   2.69444            1                0.999836     1                           0.999849            0.0277778       0.0555556                  169.444   169.444            0.0555556\n",
       "3        0.0515464                   0.999811           2.69444   2.69444            1                0.999811     1                           0.999826            0.0833333       0.138889                   169.444   169.444            0.138889\n",
       "4        0.0515464                   0.999712           0         2.69444            0                0            1                           0.999826            0               0.138889                   -100      169.444            0.138889\n",
       "5        0.103093                    0.999421           2.69444   2.69444            1                0.999626     1                           0.999726            0.138889        0.277778                   169.444   169.444            0.277778\n",
       "6        0.154639                    0.998775           2.69444   2.69444            1                0.999092     1                           0.999515            0.138889        0.416667                   169.444   169.444            0.416667\n",
       "7        0.206186                    0.998309           2.69444   2.69444            1                0.99858      1                           0.999281            0.138889        0.555556                   169.444   169.444            0.555556\n",
       "8        0.298969                    0.906915           2.69444   2.69444            1                0.981087     1                           0.993635            0.25            0.805556                   169.444   169.444            0.805556\n",
       "9        0.402062                    0.0448873          1.61667   2.41809            0.6              0.4464       0.897436                    0.853318            0.166667        0.972222                   61.6667   141.809            0.906648\n",
       "10       0.505155                    0.00277584         0.269444  1.97959            0.1              0.00960296   0.734694                    0.681131            0.0277778       1                          -73.0556  97.9592            0.786885\n",
       "11       0.597938                    0.000609418        0         1.67241            0                0.0016215    0.62069                     0.57569             0               1                          -100      67.2414            0.639344\n",
       "12       0.701031                    0.000267336        0         1.42647            0                0.000377448  0.529412                    0.491085            0               1                          -100      42.6471            0.47541\n",
       "13       0.804124                    0.000104002        0         1.24359            0                0.000162481  0.461538                    0.428147            0               1                          -100      24.359             0.311475\n",
       "14       0.896907                    3.54575e-05        0         1.11494            0                6.01668e-05  0.413793                    0.383862            0               1                          -100      11.4943            0.163934\n",
       "15       1                           2.30685e-06        0         1                  0                1.59654e-05  0.371134                    0.34429             0               1                          -100      0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.027379532890430474\n",
       "RMSE: 0.16546761885768005\n",
       "LogLoss: 0.09309713385791729\n",
       "Mean Per-Class Error: 0.031075316269491025\n",
       "AUC: 0.9944836716681378\n",
       "AUCPR: 0.9916467621875895\n",
       "Gini: 0.9889673433362756\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5718110822865685\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ------------\n",
       "democrat    201         5             0.0243   (5.0/206.0)\n",
       "republican  5           127           0.0379   (5.0/132.0)\n",
       "Total       206         132           0.0296   (10.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.571811     0.962121  126\n",
       "max f2                       0.160082     0.968935  142\n",
       "max f0point5                 0.633171     0.96875   121\n",
       "max accuracy                 0.571811     0.970414  126\n",
       "max precision                0.999909     1         0\n",
       "max recall                   0.0250863    1         159\n",
       "max specificity              0.999909     1         0\n",
       "max absolute_mcc             0.571811     0.937849  126\n",
       "max min_per_class_accuracy   0.571811     0.962121  126\n",
       "max mean_per_class_accuracy  0.571811     0.968925  126\n",
       "max tns                      0.999909     206       0\n",
       "max fns                      0.999909     131       0\n",
       "max fps                      1.31862e-05  206       326\n",
       "max tps                      0.0250863    132       159\n",
       "max tnr                      0.999909     1         0\n",
       "max fnr                      0.999909     0.992424  0\n",
       "max fpr                      1.31862e-05  1         326\n",
       "max tpr                      0.0250863    1         159\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.04 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0118343                   0.999755           2.56061  2.56061            1                0.999835     1                           0.999835            0.030303        0.030303                   156.061  156.061            0.030303\n",
       "2        0.0207101                   0.999672           2.56061  2.56061            1                0.999735     1                           0.999792            0.0227273       0.0530303                  156.061  156.061            0.0530303\n",
       "3        0.0325444                   0.999458           2.56061  2.56061            1                0.999595     1                           0.999721            0.030303        0.0833333                  156.061  156.061            0.0833333\n",
       "4        0.0414201                   0.999404           2.56061  2.56061            1                0.999436     1                           0.99966             0.0227273       0.106061                   156.061  156.061            0.106061\n",
       "5        0.0502959                   0.999331           2.56061  2.56061            1                0.999368     1                           0.999608            0.0227273       0.128788                   156.061  156.061            0.128788\n",
       "6        0.100592                    0.99805            2.56061  2.56061            1                0.998867     1                           0.999238            0.128788        0.257576                   156.061  156.061            0.257576\n",
       "7        0.150888                    0.995579           2.56061  2.56061            1                0.99702      1                           0.998498            0.128788        0.386364                   156.061  156.061            0.386364\n",
       "8        0.201183                    0.991344           2.56061  2.56061            1                0.993866     1                           0.99734             0.128788        0.515152                   156.061  156.061            0.515152\n",
       "9        0.301775                    0.953981           2.48529  2.5355             0.970588         0.980519     0.990196                    0.991733            0.25            0.765152                   148.529  153.55             0.760297\n",
       "10       0.399408                    0.410552           2.01745  2.40887            0.787879         0.775132     0.940741                    0.938786            0.19697         0.962121                   101.745  140.887            0.923286\n",
       "11       0.5                         0.0160923          0.37656  2                  0.147059         0.144155     0.781065                    0.778919            0.0378788       1                          -62.344  100                0.820388\n",
       "12       0.600592                    0.00238716         0        1.66502            0                0.00666909   0.650246                    0.649577            0               1                          -100     66.5025            0.65534\n",
       "13       0.698225                    0.000859222        0        1.4322             0                0.00156206   0.559322                    0.558965            0               1                          -100     43.2203            0.495146\n",
       "14       0.798817                    0.000367776        0        1.25185            0                0.000587541  0.488889                    0.488651            0               1                          -100     25.1852            0.330097\n",
       "15       0.899408                    0.000128424        0        1.11184            0                0.000228964  0.434211                    0.434024            0               1                          -100     11.1842            0.165049\n",
       "16       1                           1.319e-05          0        1                  0                5.57126e-05  0.390533                    0.390371            0               1                          -100     0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd            cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-----------------------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "accuracy                 0.97974336   0.026432026   0.9714286     0.9183673     1.0           1.0           0.9756098     0.96428573    1.0           1.0           1.0           0.9677419\n",
       "aic                      nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan           nan           nan\n",
       "auc                      0.9941482    0.0088145975  0.9861111     0.9727891     1.0           1.0           0.99206346    0.9947917     1.0           1.0           1.0           0.99572647\n",
       "err                      0.020256668  0.026432026   0.028571429   0.08163265    0.0           0.0           0.024390243   0.035714287   0.0           0.0           0.0           0.032258064\n",
       "err_count                0.8          1.2292726     1.0           4.0           0.0           0.0           1.0           1.0           0.0           0.0           0.0           1.0\n",
       "f0point5                 0.967823     0.040107686   0.90909094    0.9047619     1.0           1.0           0.9848485     0.9375        1.0           1.0           1.0           0.942029\n",
       "f1                       0.97318643   0.032802965   0.9411765     0.9047619     1.0           1.0           0.962963      0.96          1.0           1.0           1.0           0.962963\n",
       "f2                       0.97908556   0.031885203   0.9756098     0.9047619     1.0           1.0           0.942029      0.9836066     1.0           1.0           1.0           0.9848485\n",
       "lift_top_group           2.6806576    0.6947111     4.375         2.3333333     2.6363637     2.4166667     2.9285715     2.3333333     2.0           2.1764705     3.2222223     2.3846154\n",
       "loglikelihood            nan          0.0           nan           nan           nan           nan           nan           nan           nan           nan           nan           nan\n",
       "---                      ---          ---           ---           ---           ---           ---           ---           ---           ---           ---           ---           ---\n",
       "mcc                      0.9571513    0.054571122   0.9251849     0.8333333     1.0           1.0           0.9462601     0.93026054    1.0           1.0           1.0           0.9364743\n",
       "mean_per_class_accuracy  0.9803406    0.026762621   0.9814815     0.9166667     1.0           1.0           0.96428573    0.96875       1.0           1.0           1.0           0.9722222\n",
       "mean_per_class_error     0.01965939   0.026762621   0.018518519   0.083333336   0.0           0.0           0.035714287   0.03125       0.0           0.0           0.0           0.027777778\n",
       "mse                      0.024762852  0.020708797   0.035906624   0.06975475    0.016016113   0.007980971   0.034868203   0.038432386   0.01795891    0.0025347667  0.0020272718  0.022148529\n",
       "pr_auc                   0.98903847   0.017448213   0.94931686    0.9664294     1.0           1.0           0.987009      0.99332976    1.0           1.0           1.0           0.9942994\n",
       "precision                0.96452993   0.04696796    0.8888889     0.9047619     1.0           1.0           1.0           0.9230769     1.0           1.0           1.0           0.9285714\n",
       "r2                       0.89161325   0.090142354   0.7963629     0.7151681     0.93197197    0.96709806    0.844938      0.84306777    0.92816436    0.98979384    0.9905281     0.9090396\n",
       "recall                   0.98333335   0.035581764   1.0           0.9047619     1.0           1.0           0.9285714     1.0           1.0           1.0           1.0           1.0\n",
       "rmse                     0.14304712   0.069124475   0.18949044    0.26411125    0.12655479    0.08933628    0.1867303     0.19604181    0.13401085    0.050346464   0.045025237   0.14882381\n",
       "specificity              0.9773479    0.030432565   0.962963      0.9285714     1.0           1.0           1.0           0.9375        1.0           1.0           1.0           0.9444444\n",
       "[22 rows x 13 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:49:15  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:49:15  1.625 sec   56333 obs/sec     1         1             338        0.220724         0.161335            0.795313       0.983929        0.974833           2.56061          0.0591716                        0.261688           0.239055              0.706587         0.968579          0.959368             2.69444            0.0927835\n",
       "    2025-05-26 14:49:15  1.649 sec   29391 obs/sec     2         2             676        0.183634         0.114438            0.858324       0.993013        0.989285           2.56061          0.0384615                        0.219306           0.160024              0.793932         0.984062          0.976568             2.69444            0.0618557\n",
       "    2025-05-26 14:49:15  1.686 sec   22043 obs/sec     3         3             1014       0.160532         0.0894164           0.891728       0.99566         0.993207           2.56061          0.0266272                        0.187724           0.120692              0.84901          0.992259          0.988974             2.69444            0.0309278\n",
       "    2025-05-26 14:49:15  1.728 sec   19314 obs/sec     4         4             1352       0.150642         0.0786731           0.904658       0.996911        0.995081           2.56061          0.0236686                        0.175117           0.104175              0.868609         0.993625          0.99069              2.69444            0.0309278\n",
       "    2025-05-26 14:49:15  1.757 sec   18988 obs/sec     5         5             1690       0.140411         0.0679485           0.917169       0.997279        0.995727           2.56061          0.0207101                        0.167328           0.0976448             0.880037         0.994536          0.991733             2.69444            0.0309278\n",
       "    2025-05-26 14:49:15  1.789 sec   18270 obs/sec     6         6             2028       0.136413         0.0656268           0.921818       0.997867        0.996593           2.56061          0.0177515                        0.17739            0.11005               0.865176         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:49:15  1.825 sec   17397 obs/sec     7         7             2366       0.126075         0.0565443           0.93322        0.997977        0.996766           2.56061          0.0177515                        0.153851           0.0798664             0.898582         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:49:15  1.856 sec   17006 obs/sec     8         8             2704       0.125444         0.0540615           0.933886       0.998198        0.997156           2.56061          0.0177515                        0.167442           0.0949686             0.879873         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:49:15  1.886 sec   16900 obs/sec     9         9             3042       0.128288         0.056089            0.930854       0.998419        0.997512           2.56061          0.0177515                        0.176155           0.114825              0.867046         0.995902          0.993656             2.69444            0.0309278\n",
       "    2025-05-26 14:49:15  1.916 sec   16732 obs/sec     10        10            3380       0.114993         0.0473662           0.944444       0.998786        0.998095           2.56061          0.0147929                        0.155279           0.0833018             0.896691         0.996357          0.994396             2.69444            0.0206186\n",
       "    2025-05-26 14:49:15  1.946 sec   16672 obs/sec     11        11            3718       0.116583         0.0465374           0.942897       0.99897         0.998365           2.56061          0.0118343                        0.15823            0.0878856             0.892727         0.997268          0.995599             2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "el-salvador-aid.?                                   1.0                    1.0                  0.027021235297789322\n",
       "duty-free-exports.?                                 0.9811990857124329     0.9811990857124329   0.0265132113690114\n",
       "crime.?                                             0.972650408744812      0.972650408744812    0.026282215557184525\n",
       "synfuels-corporation-cutback.n                      0.9533860087394714     0.9533860087394714   0.025761667671769482\n",
       "synfuels-corporation-cutback.?                      0.9520403146743774     0.9520403146743774   0.02572530535579774\n",
       "superfund-right-to-sue.y                            0.9136627316474915     0.9136627316474915   0.02468829565466781\n",
       "adoption-of-the-budget-resolution.y                 0.9100732207298279     0.9100732207298279   0.024591302635557637\n",
       "physician-fee-freeze.y                              0.8963868021965027     0.8963868021965027   0.024221478699984634\n",
       "mx-missile.y                                        0.8612557053565979     0.8612557053565979   0.023272193066004143\n",
       "mx-missile.n                                        0.8610665798187256     0.8610665798187256   0.023267082660344475\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[20,20,20], nfolds=10, activation=\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c06b1c437bd321",
   "metadata": {},
   "source": [
    "Params dataset = iris, features = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"], target = \"class\", hidden layers = [20,20,20], cross folds = 10, activation function = \"tanh\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "621ded7b12a25530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='margin: 1em 0 1em 0;'>Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_2510\n",
       "</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-208.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-208 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-208 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-208 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-208 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-208 .h2o-table th,\n",
       "#h2o-table-208 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-208 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-208\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>layer</th>\n",
       "<th>units</th>\n",
       "<th>type</th>\n",
       "<th>dropout</th>\n",
       "<th>l1</th>\n",
       "<th>l2</th>\n",
       "<th>mean_rate</th>\n",
       "<th>rate_rms</th>\n",
       "<th>momentum</th>\n",
       "<th>mean_weight</th>\n",
       "<th>weight_rms</th>\n",
       "<th>mean_bias</th>\n",
       "<th>bias_rms</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>1</td>\n",
       "<td>64</td>\n",
       "<td>Input</td>\n",
       "<td>0.0</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "<td></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.2540259</td>\n",
       "<td>0.4303598</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0028504</td>\n",
       "<td>0.1096520</td>\n",
       "<td>-0.0021215</td>\n",
       "<td>0.0164488</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0147293</td>\n",
       "<td>0.0152738</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0005918</td>\n",
       "<td>0.1013931</td>\n",
       "<td>-0.0022651</td>\n",
       "<td>0.0164130</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>100</td>\n",
       "<td>Tanh</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0467493</td>\n",
       "<td>0.1216998</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0011411</td>\n",
       "<td>0.1008218</td>\n",
       "<td>-0.0001001</td>\n",
       "<td>0.0070044</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>2</td>\n",
       "<td>Softmax</td>\n",
       "<td></td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0050792</td>\n",
       "<td>0.0015879</td>\n",
       "<td>0.0</td>\n",
       "<td>-0.0074746</td>\n",
       "<td>0.5522048</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0016043</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01766353281088727\n",
       "RMSE: 0.13290422420257103\n",
       "LogLoss: 0.05895289242602224\n",
       "Mean Per-Class Error: 0.007281553398058253\n",
       "AUC: 0.9994115916446014\n",
       "AUCPR: 0.9990783495028307\n",
       "Gini: 0.9988231832892027</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-209.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-209 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-209 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-209 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-209 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-209 .h2o-table th,\n",
       "#h2o-table-209 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-209 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-209\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7563318232968509</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>203.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0146</td>\n",
       "<td> (3.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>0.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.0</td>\n",
       "<td> (0.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>203.0</td>\n",
       "<td>135.0</td>\n",
       "<td>0.0089</td>\n",
       "<td> (3.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-210.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-210 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-210 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-210 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-210 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-210 .h2o-table th,\n",
       "#h2o-table-210 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-210 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-210\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.7563318</td>\n",
       "<td>0.9887640</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.7563318</td>\n",
       "<td>0.9954751</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9859220</td>\n",
       "<td>0.9889241</td>\n",
       "<td>86.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7563318</td>\n",
       "<td>0.9911243</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.7563318</td>\n",
       "<td>1.0</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.7563318</td>\n",
       "<td>0.9815999</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.7844913</td>\n",
       "<td>0.9854369</td>\n",
       "<td>95.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.7563318</td>\n",
       "<td>0.9927184</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>1.0000000</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.7563318</td>\n",
       "<td>132.0</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>269.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.7563318</td>\n",
       "<td>1.0</td>\n",
       "<td>96.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-211.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-211 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-211 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-211 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-211 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-211 .h2o-table th,\n",
       "#h2o-table-211 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-211 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-211\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 41.60 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0295858</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0454545</td>\n",
       "<td>0.0757576</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0757576</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9999999</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0075758</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9999998</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9999998</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1035503</td>\n",
       "<td>0.9999990</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999996</td>\n",
       "<td>0.1363636</td>\n",
       "<td>0.2651515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2651515</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9999881</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999966</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999986</td>\n",
       "<td>0.1212121</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9999458</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999701</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999915</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3076923</td>\n",
       "<td>0.9997911</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998883</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999558</td>\n",
       "<td>0.2727273</td>\n",
       "<td>0.7878788</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.7878788</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.7539871</td>\n",
       "<td>2.3128055</td>\n",
       "<td>2.5037037</td>\n",
       "<td>0.9032258</td>\n",
       "<td>0.9656966</td>\n",
       "<td>0.9777778</td>\n",
       "<td>0.9920889</td>\n",
       "<td>0.2121212</td>\n",
       "<td>1.0</td>\n",
       "<td>131.2805474</td>\n",
       "<td>150.3703704</td>\n",
       "<td>0.9854369</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0031774</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1946608</td>\n",
       "<td>0.7810651</td>\n",
       "<td>0.8316596</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>100.0</td>\n",
       "<td>0.8203883</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0004412</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0013818</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6925983</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0000569</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0002010</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5957800</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0000161</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000357</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.5207603</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000021</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000086</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4625184</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.4159929</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.020990264936718173\n",
       "RMSE: 0.14488017440877884\n",
       "LogLoss: 0.07440846452623437\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9972677595628415\n",
       "AUCPR: 0.9954183934389053\n",
       "Gini: 0.994535519125683</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-212.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-212 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-212 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-212 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-212 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-212 .h2o-table th,\n",
       "#h2o-table-212 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-212 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-212\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9180893861463741</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>60.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0164</td>\n",
       "<td> (1.0/61.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (1.0/36.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>61.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.0206</td>\n",
       "<td> (2.0/97.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-213.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-213 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-213 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-213 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-213 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-213 .h2o-table th,\n",
       "#h2o-table-213 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-213 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-213\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.9180894</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3395912</td>\n",
       "<td>0.9836066</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9869620</td>\n",
       "<td>0.9756098</td>\n",
       "<td>28.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.9180894</td>\n",
       "<td>0.9793814</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3395912</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.9180894</td>\n",
       "<td>0.9558288</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.9180894</td>\n",
       "<td>0.9722222</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.9180894</td>\n",
       "<td>0.9779144</td>\n",
       "<td>32.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999999</td>\n",
       "<td>61.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999999</td>\n",
       "<td>35.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000001</td>\n",
       "<td>61.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.3395912</td>\n",
       "<td>36.0</td>\n",
       "<td>35.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.9722222</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000001</td>\n",
       "<td>1.0</td>\n",
       "<td>91.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.3395912</td>\n",
       "<td>1.0</td>\n",
       "<td>35.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-214.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-214 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-214 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-214 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-214 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-214 .h2o-table th,\n",
       "#h2o-table-214 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-214 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-214\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 37.11 %, avg score: 38.78 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0103093</td>\n",
       "<td>0.9999998</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0277778</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0206186</td>\n",
       "<td>0.9999998</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999999</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0555556</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0309278</td>\n",
       "<td>0.9999997</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0833333</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0412371</td>\n",
       "<td>0.9999997</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1111111</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1111111</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0515464</td>\n",
       "<td>0.9999996</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1388889</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.1388889</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1030928</td>\n",
       "<td>0.9999993</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.2777778</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.2777778</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1546392</td>\n",
       "<td>0.9999990</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999991</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999995</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.4166667</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.4166667</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2061856</td>\n",
       "<td>0.9999803</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999947</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999983</td>\n",
       "<td>0.1388889</td>\n",
       "<td>0.5555556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.5555556</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.2989691</td>\n",
       "<td>0.9946464</td>\n",
       "<td>2.6944444</td>\n",
       "<td>2.6944444</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991288</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997284</td>\n",
       "<td>0.25</td>\n",
       "<td>0.8055556</td>\n",
       "<td>169.4444444</td>\n",
       "<td>169.4444444</td>\n",
       "<td>0.8055556</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.4020619</td>\n",
       "<td>0.2532767</td>\n",
       "<td>1.8861111</td>\n",
       "<td>2.4871795</td>\n",
       "<td>0.7</td>\n",
       "<td>0.8246338</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9548324</td>\n",
       "<td>0.1944444</td>\n",
       "<td>1.0</td>\n",
       "<td>88.6111111</td>\n",
       "<td>148.7179487</td>\n",
       "<td>0.9508197</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5051546</td>\n",
       "<td>0.0027746</td>\n",
       "<td>0.0</td>\n",
       "<td>1.9795918</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0363933</td>\n",
       "<td>0.7346939</td>\n",
       "<td>0.7673958</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>97.9591837</td>\n",
       "<td>0.7868852</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.5979381</td>\n",
       "<td>0.0006872</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6724138</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0012135</td>\n",
       "<td>0.6206897</td>\n",
       "<td>0.6485055</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.2413793</td>\n",
       "<td>0.6393443</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.7010309</td>\n",
       "<td>0.0001130</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4264706</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003342</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.5531862</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.6470588</td>\n",
       "<td>0.4754098</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7938144</td>\n",
       "<td>0.0000214</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2597403</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000512</td>\n",
       "<td>0.4675325</td>\n",
       "<td>0.4885340</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.9740260</td>\n",
       "<td>0.3278689</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8969072</td>\n",
       "<td>0.0000059</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1149425</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000138</td>\n",
       "<td>0.4137931</td>\n",
       "<td>0.4323823</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.4942529</td>\n",
       "<td>0.1639344</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000007</td>\n",
       "<td>0.3711340</td>\n",
       "<td>0.3878069</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'><pre style='margin: 1em 0 1em 0;'>ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.021493619957376083\n",
       "RMSE: 0.14660702560715186\n",
       "LogLoss: 0.08252652068703364\n",
       "Mean Per-Class Error: 0.02213886437187408\n",
       "AUC: 0.9952191821123859\n",
       "AUCPR: 0.9931319371015339\n",
       "Gini: 0.9904383642247718</pre>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-215.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-215 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-215 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-215 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-215 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-215 .h2o-table th,\n",
       "#h2o-table-215 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-215 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-215\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4018719239414743</caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>democrat</th>\n",
       "<th>republican</th>\n",
       "<th>Error</th>\n",
       "<th>Rate</th></tr></thead>\n",
       "    <tbody><tr><td>democrat</td>\n",
       "<td>200.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.0291</td>\n",
       "<td> (6.0/206.0)</td></tr>\n",
       "<tr><td>republican</td>\n",
       "<td>2.0</td>\n",
       "<td>130.0</td>\n",
       "<td>0.0152</td>\n",
       "<td> (2.0/132.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>202.0</td>\n",
       "<td>136.0</td>\n",
       "<td>0.0237</td>\n",
       "<td> (8.0/338.0)</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-216.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-216 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-216 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-216 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-216 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-216 .h2o-table th,\n",
       "#h2o-table-216 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-216 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-216\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Maximum Metrics: Maximum metrics at their respective thresholds</caption>\n",
       "    <thead><tr><th>metric</th>\n",
       "<th>threshold</th>\n",
       "<th>value</th>\n",
       "<th>idx</th></tr></thead>\n",
       "    <tbody><tr><td>max f1</td>\n",
       "<td>0.4018719</td>\n",
       "<td>0.9701493</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4018719</td>\n",
       "<td>0.9789157</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.9191611</td>\n",
       "<td>0.9740260</td>\n",
       "<td>114.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4018719</td>\n",
       "<td>0.9763314</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0026992</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4018719</td>\n",
       "<td>0.9508393</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4248318</td>\n",
       "<td>0.9708738</td>\n",
       "<td>128.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4018719</td>\n",
       "<td>0.9778611</td>\n",
       "<td>129.0</td></tr>\n",
       "<tr><td>max tns</td>\n",
       "<td>0.9999998</td>\n",
       "<td>206.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fns</td>\n",
       "<td>0.9999998</td>\n",
       "<td>131.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fps</td>\n",
       "<td>0.0000000</td>\n",
       "<td>206.0</td>\n",
       "<td>325.0</td></tr>\n",
       "<tr><td>max tps</td>\n",
       "<td>0.0026992</td>\n",
       "<td>132.0</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max tnr</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fnr</td>\n",
       "<td>0.9999998</td>\n",
       "<td>0.9924242</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max fpr</td>\n",
       "<td>0.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>325.0</td></tr>\n",
       "<tr><td>max tpr</td>\n",
       "<td>0.0026992</td>\n",
       "<td>1.0</td>\n",
       "<td>175.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-217.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-217 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-217 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-217 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-217 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-217 .h2o-table th,\n",
       "#h2o-table-217 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-217 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-217\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.05 %</caption>\n",
       "    <thead><tr><th>group</th>\n",
       "<th>cumulative_data_fraction</th>\n",
       "<th>lower_threshold</th>\n",
       "<th>lift</th>\n",
       "<th>cumulative_lift</th>\n",
       "<th>response_rate</th>\n",
       "<th>score</th>\n",
       "<th>cumulative_response_rate</th>\n",
       "<th>cumulative_score</th>\n",
       "<th>capture_rate</th>\n",
       "<th>cumulative_capture_rate</th>\n",
       "<th>gain</th>\n",
       "<th>cumulative_gain</th>\n",
       "<th>kolmogorov_smirnov</th></tr></thead>\n",
       "    <tbody><tr><td>1</td>\n",
       "<td>0.0118343</td>\n",
       "<td>0.9999990</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999995</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999995</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0303030</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0303030</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.9999968</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999981</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999989</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.0530303</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0530303</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.0325444</td>\n",
       "<td>0.9999948</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999960</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999978</td>\n",
       "<td>0.0303030</td>\n",
       "<td>0.0833333</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.0833333</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.0414201</td>\n",
       "<td>0.9999912</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999931</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999968</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1060606</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1060606</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.0502959</td>\n",
       "<td>0.9999814</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999858</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999949</td>\n",
       "<td>0.0227273</td>\n",
       "<td>0.1287879</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.1287879</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.1005917</td>\n",
       "<td>0.9998773</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999338</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999643</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.2575758</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.2575758</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.1508876</td>\n",
       "<td>0.9994328</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997126</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998804</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.3863636</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.3863636</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.2011834</td>\n",
       "<td>0.9973792</td>\n",
       "<td>2.5606061</td>\n",
       "<td>2.5606061</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9987339</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9995938</td>\n",
       "<td>0.1287879</td>\n",
       "<td>0.5151515</td>\n",
       "<td>156.0606061</td>\n",
       "<td>156.0606061</td>\n",
       "<td>0.5151515</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.3017751</td>\n",
       "<td>0.9826856</td>\n",
       "<td>2.4852941</td>\n",
       "<td>2.5355021</td>\n",
       "<td>0.9705882</td>\n",
       "<td>0.9915727</td>\n",
       "<td>0.9901961</td>\n",
       "<td>0.9969201</td>\n",
       "<td>0.25</td>\n",
       "<td>0.7651515</td>\n",
       "<td>148.5294118</td>\n",
       "<td>153.5502080</td>\n",
       "<td>0.7602971</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>0.3994083</td>\n",
       "<td>0.4064639</td>\n",
       "<td>2.1726354</td>\n",
       "<td>2.4468013</td>\n",
       "<td>0.8484848</td>\n",
       "<td>0.8351080</td>\n",
       "<td>0.9555556</td>\n",
       "<td>0.9573660</td>\n",
       "<td>0.2121212</td>\n",
       "<td>0.9772727</td>\n",
       "<td>117.2635445</td>\n",
       "<td>144.6801347</td>\n",
       "<td>0.9481465</td></tr>\n",
       "<tr><td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0056117</td>\n",
       "<td>0.1506239</td>\n",
       "<td>1.9848485</td>\n",
       "<td>0.0588235</td>\n",
       "<td>0.0772373</td>\n",
       "<td>0.7751479</td>\n",
       "<td>0.7802987</td>\n",
       "<td>0.0151515</td>\n",
       "<td>0.9924242</td>\n",
       "<td>-84.9376114</td>\n",
       "<td>98.4848485</td>\n",
       "<td>0.8079582</td></tr>\n",
       "<tr><td>12</td>\n",
       "<td>0.6005917</td>\n",
       "<td>0.0010397</td>\n",
       "<td>0.0753119</td>\n",
       "<td>1.6650246</td>\n",
       "<td>0.0294118</td>\n",
       "<td>0.0027013</td>\n",
       "<td>0.6502463</td>\n",
       "<td>0.6500607</td>\n",
       "<td>0.0075758</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.4688057</td>\n",
       "<td>66.5024631</td>\n",
       "<td>0.6553398</td></tr>\n",
       "<tr><td>13</td>\n",
       "<td>0.6982249</td>\n",
       "<td>0.0002711</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4322034</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006144</td>\n",
       "<td>0.5593220</td>\n",
       "<td>0.5592483</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.2203390</td>\n",
       "<td>0.4951456</td></tr>\n",
       "<tr><td>14</td>\n",
       "<td>0.7988166</td>\n",
       "<td>0.0000458</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2518519</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001391</td>\n",
       "<td>0.4888889</td>\n",
       "<td>0.4888420</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1851852</td>\n",
       "<td>0.3300971</td></tr>\n",
       "<tr><td>15</td>\n",
       "<td>0.8994083</td>\n",
       "<td>0.0000022</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1118421</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000137</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.4341704</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1842105</td>\n",
       "<td>0.1650485</td></tr>\n",
       "<tr><td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000005</td>\n",
       "<td>0.3905325</td>\n",
       "<td>0.3904965</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-218.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-218 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-218 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-218 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-218 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-218 .h2o-table th,\n",
       "#h2o-table-218 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-218 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-218\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Cross-Validation Metrics Summary: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>mean</th>\n",
       "<th>sd</th>\n",
       "<th>cv_1_valid</th>\n",
       "<th>cv_2_valid</th>\n",
       "<th>cv_3_valid</th>\n",
       "<th>cv_4_valid</th>\n",
       "<th>cv_5_valid</th>\n",
       "<th>cv_6_valid</th>\n",
       "<th>cv_7_valid</th>\n",
       "<th>cv_8_valid</th>\n",
       "<th>cv_9_valid</th>\n",
       "<th>cv_10_valid</th></tr></thead>\n",
       "    <tbody><tr><td>accuracy</td>\n",
       "<td>0.9870508</td>\n",
       "<td>0.0172429</td>\n",
       "<td>0.9714286</td>\n",
       "<td>0.9591837</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>aic</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9964746</td>\n",
       "<td>0.0047689</td>\n",
       "<td>0.9907407</td>\n",
       "<td>0.9897959</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9894180</td>\n",
       "<td>0.9947917</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0129492</td>\n",
       "<td>0.0172429</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0408163</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0243902</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7071068</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.9783821</td>\n",
       "<td>0.0333241</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9848485</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.981652</td>\n",
       "<td>0.0243426</td>\n",
       "<td>0.9411765</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.96</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.9853627</td>\n",
       "<td>0.0219831</td>\n",
       "<td>0.9756098</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.942029</td>\n",
       "<td>0.9836066</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6806576</td>\n",
       "<td>0.6947111</td>\n",
       "<td>4.375</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.6363637</td>\n",
       "<td>2.4166667</td>\n",
       "<td>2.9285715</td>\n",
       "<td>2.3333333</td>\n",
       "<td>2.0</td>\n",
       "<td>2.1764705</td>\n",
       "<td>3.2222223</td>\n",
       "<td>2.3846154</td></tr>\n",
       "<tr><td>loglikelihood</td>\n",
       "<td>nan</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.9718372</td>\n",
       "<td>0.0370614</td>\n",
       "<td>0.9251849</td>\n",
       "<td>0.9166667</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9462601</td>\n",
       "<td>0.9302605</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.9872851</td>\n",
       "<td>0.0173667</td>\n",
       "<td>0.9814815</td>\n",
       "<td>0.9583333</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9642857</td>\n",
       "<td>0.96875</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.0127149</td>\n",
       "<td>0.0173667</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0357143</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0198184</td>\n",
       "<td>0.0161641</td>\n",
       "<td>0.0340637</td>\n",
       "<td>0.0442037</td>\n",
       "<td>0.0053408</td>\n",
       "<td>0.0190852</td>\n",
       "<td>0.0354519</td>\n",
       "<td>0.0344692</td>\n",
       "<td>0.0148562</td>\n",
       "<td>0.0003279</td>\n",
       "<td>0.0000737</td>\n",
       "<td>0.0103114</td></tr>\n",
       "<tr><td>pr_auc</td>\n",
       "<td>0.9933923</td>\n",
       "<td>0.0105273</td>\n",
       "<td>0.9685857</td>\n",
       "<td>0.9883384</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9836690</td>\n",
       "<td>0.9933298</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.9764346</td>\n",
       "<td>0.0407937</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.9123107</td>\n",
       "<td>0.0743148</td>\n",
       "<td>0.8068146</td>\n",
       "<td>0.8195014</td>\n",
       "<td>0.9773149</td>\n",
       "<td>0.9213203</td>\n",
       "<td>0.8423422</td>\n",
       "<td>0.8592506</td>\n",
       "<td>0.9405751</td>\n",
       "<td>0.9986798</td>\n",
       "<td>0.9996557</td>\n",
       "<td>0.9576529</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.9880952</td>\n",
       "<td>0.0257172</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9285714</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1230109</td>\n",
       "<td>0.0721626</td>\n",
       "<td>0.1845636</td>\n",
       "<td>0.2102469</td>\n",
       "<td>0.0730811</td>\n",
       "<td>0.1381493</td>\n",
       "<td>0.1882868</td>\n",
       "<td>0.1856589</td>\n",
       "<td>0.1218862</td>\n",
       "<td>0.0181077</td>\n",
       "<td>0.0085837</td>\n",
       "<td>0.1015449</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9864749</td>\n",
       "<td>0.0229110</td>\n",
       "<td>0.962963</td>\n",
       "<td>0.9642857</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9375</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[22 rows x 13 columns]</pre></div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-219.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-219 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-219 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-219 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-219 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-219 .h2o-table th,\n",
       "#h2o-table-219 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-219 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-219\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Scoring History: </caption>\n",
       "    <thead><tr><th></th>\n",
       "<th>timestamp</th>\n",
       "<th>duration</th>\n",
       "<th>training_speed</th>\n",
       "<th>epochs</th>\n",
       "<th>iterations</th>\n",
       "<th>samples</th>\n",
       "<th>training_rmse</th>\n",
       "<th>training_logloss</th>\n",
       "<th>training_r2</th>\n",
       "<th>training_auc</th>\n",
       "<th>training_pr_auc</th>\n",
       "<th>training_lift</th>\n",
       "<th>training_classification_error</th>\n",
       "<th>validation_rmse</th>\n",
       "<th>validation_logloss</th>\n",
       "<th>validation_r2</th>\n",
       "<th>validation_auc</th>\n",
       "<th>validation_pr_auc</th>\n",
       "<th>validation_lift</th>\n",
       "<th>validation_classification_error</th></tr></thead>\n",
       "    <tbody><tr><td></td>\n",
       "<td>2025-05-26 14:49:20</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:20</td>\n",
       "<td> 2.221 sec</td>\n",
       "<td>4970 obs/sec</td>\n",
       "<td>1.0</td>\n",
       "<td>1</td>\n",
       "<td>338.0</td>\n",
       "<td>0.1499593</td>\n",
       "<td>0.0751439</td>\n",
       "<td>0.9055202</td>\n",
       "<td>0.9970947</td>\n",
       "<td>0.9955916</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0236686</td>\n",
       "<td>0.1316145</td>\n",
       "<td>0.0588840</td>\n",
       "<td>0.9257804</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9978354</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:20</td>\n",
       "<td> 2.315 sec</td>\n",
       "<td>4567 obs/sec</td>\n",
       "<td>2.0</td>\n",
       "<td>2</td>\n",
       "<td>676.0</td>\n",
       "<td>0.1413837</td>\n",
       "<td>0.0718852</td>\n",
       "<td>0.9160171</td>\n",
       "<td>0.9969476</td>\n",
       "<td>0.9951138</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1409968</td>\n",
       "<td>0.0648132</td>\n",
       "<td>0.9148216</td>\n",
       "<td>0.9981785</td>\n",
       "<td>0.9970529</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 2.409 sec</td>\n",
       "<td>4466 obs/sec</td>\n",
       "<td>3.0</td>\n",
       "<td>3</td>\n",
       "<td>1014.0</td>\n",
       "<td>0.1324967</td>\n",
       "<td>0.0600974</td>\n",
       "<td>0.9262432</td>\n",
       "<td>0.9980877</td>\n",
       "<td>0.9968429</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1386852</td>\n",
       "<td>0.0597066</td>\n",
       "<td>0.9175916</td>\n",
       "<td>0.9977231</td>\n",
       "<td>0.9961014</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 2.507 sec</td>\n",
       "<td>4347 obs/sec</td>\n",
       "<td>4.0</td>\n",
       "<td>4</td>\n",
       "<td>1352.0</td>\n",
       "<td>0.1257899</td>\n",
       "<td>0.0544589</td>\n",
       "<td>0.9335211</td>\n",
       "<td>0.9979038</td>\n",
       "<td>0.9965739</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1592843</td>\n",
       "<td>0.0947178</td>\n",
       "<td>0.8912932</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9932987</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 2.598 sec</td>\n",
       "<td>4344 obs/sec</td>\n",
       "<td>5.0</td>\n",
       "<td>5</td>\n",
       "<td>1690.0</td>\n",
       "<td>0.1372659</td>\n",
       "<td>0.0629276</td>\n",
       "<td>0.9208379</td>\n",
       "<td>0.9982348</td>\n",
       "<td>0.9973312</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0207101</td>\n",
       "<td>0.1538446</td>\n",
       "<td>0.0802435</td>\n",
       "<td>0.8985912</td>\n",
       "<td>0.9968124</td>\n",
       "<td>0.9943648</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 2.691 sec</td>\n",
       "<td>4342 obs/sec</td>\n",
       "<td>6.0</td>\n",
       "<td>6</td>\n",
       "<td>2028.0</td>\n",
       "<td>0.1203671</td>\n",
       "<td>0.0471079</td>\n",
       "<td>0.9391293</td>\n",
       "<td>0.9988600</td>\n",
       "<td>0.9982608</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1574384</td>\n",
       "<td>0.0790773</td>\n",
       "<td>0.8937981</td>\n",
       "<td>0.9986339</td>\n",
       "<td>0.9976512</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 2.783 sec</td>\n",
       "<td>4333 obs/sec</td>\n",
       "<td>7.0</td>\n",
       "<td>7</td>\n",
       "<td>2366.0</td>\n",
       "<td>0.1249248</td>\n",
       "<td>0.0527575</td>\n",
       "<td>0.9344324</td>\n",
       "<td>0.9992277</td>\n",
       "<td>0.9988124</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1413101</td>\n",
       "<td>0.0628661</td>\n",
       "<td>0.9144426</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9959837</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0103093</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 2.879 sec</td>\n",
       "<td>4305 obs/sec</td>\n",
       "<td>8.0</td>\n",
       "<td>8</td>\n",
       "<td>2704.0</td>\n",
       "<td>0.1134005</td>\n",
       "<td>0.0452435</td>\n",
       "<td>0.9459716</td>\n",
       "<td>0.9987129</td>\n",
       "<td>0.9981706</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0147929</td>\n",
       "<td>0.1682952</td>\n",
       "<td>0.1140999</td>\n",
       "<td>0.8786459</td>\n",
       "<td>0.9954463</td>\n",
       "<td>0.9924168</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 2.973 sec</td>\n",
       "<td>4296 obs/sec</td>\n",
       "<td>9.0</td>\n",
       "<td>9</td>\n",
       "<td>3042.0</td>\n",
       "<td>0.1224699</td>\n",
       "<td>0.0504858</td>\n",
       "<td>0.9369840</td>\n",
       "<td>0.9987496</td>\n",
       "<td>0.9980920</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0177515</td>\n",
       "<td>0.1855953</td>\n",
       "<td>0.1346172</td>\n",
       "<td>0.8524141</td>\n",
       "<td>0.9959016</td>\n",
       "<td>0.9932987</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2025-05-26 14:49:21</td>\n",
       "<td> 3.067 sec</td>\n",
       "<td>4289 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>10</td>\n",
       "<td>3380.0</td>\n",
       "<td>0.1329042</td>\n",
       "<td>0.0589529</td>\n",
       "<td>0.9257887</td>\n",
       "<td>0.9994116</td>\n",
       "<td>0.9990783</td>\n",
       "<td>2.5606061</td>\n",
       "<td>0.0088757</td>\n",
       "<td>0.1448802</td>\n",
       "<td>0.0744085</td>\n",
       "<td>0.9100649</td>\n",
       "<td>0.9972678</td>\n",
       "<td>0.9954184</td>\n",
       "<td>2.6944444</td>\n",
       "<td>0.0206186</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "</div>\n",
       "<div style='margin: 1em 0 1em 0;'>\n",
       "<style>\n",
       "\n",
       "#h2o-table-220.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-220 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-220 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-220 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-220 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-220 .h2o-table th,\n",
       "#h2o-table-220 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-220 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-220\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption>Variable Importances: </caption>\n",
       "    <thead><tr><th>variable</th>\n",
       "<th>relative_importance</th>\n",
       "<th>scaled_importance</th>\n",
       "<th>percentage</th></tr></thead>\n",
       "    <tbody><tr><td>physician-fee-freeze.y</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0233796</td></tr>\n",
       "<tr><td>physician-fee-freeze.?</td>\n",
       "<td>0.9718586</td>\n",
       "<td>0.9718586</td>\n",
       "<td>0.0227216</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.n</td>\n",
       "<td>0.9706545</td>\n",
       "<td>0.9706545</td>\n",
       "<td>0.0226935</td></tr>\n",
       "<tr><td>adoption-of-the-budget-resolution.?</td>\n",
       "<td>0.9601865</td>\n",
       "<td>0.9601865</td>\n",
       "<td>0.0224487</td></tr>\n",
       "<tr><td>religious-groups-in-schools.n</td>\n",
       "<td>0.9581099</td>\n",
       "<td>0.9581099</td>\n",
       "<td>0.0224002</td></tr>\n",
       "<tr><td>physician-fee-freeze.n</td>\n",
       "<td>0.9574404</td>\n",
       "<td>0.9574404</td>\n",
       "<td>0.0223845</td></tr>\n",
       "<tr><td>superfund-right-to-sue.n</td>\n",
       "<td>0.9554621</td>\n",
       "<td>0.9554621</td>\n",
       "<td>0.0223383</td></tr>\n",
       "<tr><td>handicapped-infants.y</td>\n",
       "<td>0.9485031</td>\n",
       "<td>0.9485031</td>\n",
       "<td>0.0221756</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.y</td>\n",
       "<td>0.9451935</td>\n",
       "<td>0.9451935</td>\n",
       "<td>0.0220982</td></tr>\n",
       "<tr><td>education-spending.n</td>\n",
       "<td>0.9410558</td>\n",
       "<td>0.9410558</td>\n",
       "<td>0.0220015</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>anti-satellite-test-ban.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>aid-to-nicaraguan-contras.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>mx-missile.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>immigration.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>synfuels-corporation-cutback.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>education-spending.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>superfund-right-to-sue.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>crime.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>duty-free-exports.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>export-administration-act-south-africa.missing(NA)</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n",
       "<pre style='font-size: smaller; margin-bottom: 1em;'>[64 rows x 4 columns]</pre></div><pre style=\"font-size: smaller; margin: 1em 0 0 0;\">\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.</pre>"
      ],
      "text/plain": [
       "Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1748263532696_2510\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting party, 2-class classification, bernoulli distribution, CrossEntropy loss, 26,902 weights/biases, 329.7 KB, 3,380 training samples, mini-batch size 1\n",
       "    layer    units    type     dropout    l1    l2    mean_rate             rate_rms              momentum    mean_weight            weight_rms           mean_bias                bias_rms\n",
       "--  -------  -------  -------  ---------  ----  ----  --------------------  --------------------  ----------  ---------------------  -------------------  -----------------------  ---------------------\n",
       "    1        64       Input    0.0\n",
       "    2        100      Tanh     0.0        0.0   0.0   0.25402592291752624   0.4303598403930664    0.0         0.002850416431990652   0.10965204238891602  -0.002121511415572303    0.01644880324602127\n",
       "    3        100      Tanh     0.0        0.0   0.0   0.014729274890525267  0.015273809432983398  0.0         0.0005918479439063504  0.10139307379722595  -0.002265132596098386    0.016413040459156036\n",
       "    4        100      Tanh     0.0        0.0   0.0   0.0467493204690516    0.12169978022575378   0.0         0.0011410521622886335  0.10082182288169861  -0.00010014555552796308  0.0070044007152318954\n",
       "    5        2        Softmax             0.0   0.0   0.005079214095603675  0.001587945967912674  0.0         -0.007474577883258462  0.5522048473358154   2.6020852139652106e-18   0.0016043470241129398\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.01766353281088727\n",
       "RMSE: 0.13290422420257103\n",
       "LogLoss: 0.05895289242602224\n",
       "Mean Per-Class Error: 0.007281553398058253\n",
       "AUC: 0.9994115916446014\n",
       "AUCPR: 0.9990783495028307\n",
       "Gini: 0.9988231832892027\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.7563318232968509\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    203         3             0.0146   (3.0/206.0)\n",
       "republican  0           132           0        (0.0/132.0)\n",
       "Total       203         135           0.0089   (3.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.756332     0.988764  96\n",
       "max f2                       0.756332     0.995475  96\n",
       "max f0point5                 0.985922     0.988924  86\n",
       "max accuracy                 0.756332     0.991124  96\n",
       "max precision                1            1         0\n",
       "max recall                   0.756332     1         96\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.756332     0.9816    96\n",
       "max min_per_class_accuracy   0.784491     0.985437  95\n",
       "max mean_per_class_accuracy  0.756332     0.992718  96\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      5.2036e-09   206       269\n",
       "max tps                      0.756332     132       96\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      5.2036e-09   1         269\n",
       "max tpr                      0.756332     1         96\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 41.60 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0118343                   1                  2.56061  2.56061            1                1            1                           1                   0.030303        0.030303                   156.061  156.061            0.030303\n",
       "2        0.0295858                   1                  2.56061  2.56061            1                1            1                           1                   0.0454545       0.0757576                  156.061  156.061            0.0757576\n",
       "3        0.0325444                   1                  2.56061  2.56061            1                1            1                           1                   0.00757576      0.0833333                  156.061  156.061            0.0833333\n",
       "4        0.0414201                   1                  2.56061  2.56061            1                1            1                           1                   0.0227273       0.106061                   156.061  156.061            0.106061\n",
       "5        0.0502959                   1                  2.56061  2.56061            1                1            1                           1                   0.0227273       0.128788                   156.061  156.061            0.128788\n",
       "6        0.10355                     0.999999           2.56061  2.56061            1                0.999999     1                           1                   0.136364        0.265152                   156.061  156.061            0.265152\n",
       "7        0.150888                    0.999988           2.56061  2.56061            1                0.999997     1                           0.999999            0.121212        0.386364                   156.061  156.061            0.386364\n",
       "8        0.201183                    0.999946           2.56061  2.56061            1                0.99997      1                           0.999992            0.128788        0.515152                   156.061  156.061            0.515152\n",
       "9        0.307692                    0.999791           2.56061  2.56061            1                0.999888     1                           0.999956            0.272727        0.787879                   156.061  156.061            0.787879\n",
       "10       0.399408                    0.753987           2.31281  2.5037             0.903226         0.965697     0.977778                    0.992089            0.212121        1                          131.281  150.37             0.985437\n",
       "11       0.5                         0.00317742         0        2                  0                0.194661     0.781065                    0.83166             0               1                          -100     100                0.820388\n",
       "12       0.600592                    0.000441163        0        1.66502            0                0.00138185   0.650246                    0.692598            0               1                          -100     66.5025            0.65534\n",
       "13       0.698225                    5.69231e-05        0        1.4322             0                0.000200981  0.559322                    0.59578             0               1                          -100     43.2203            0.495146\n",
       "14       0.798817                    1.6136e-05         0        1.25185            0                3.56799e-05  0.488889                    0.52076             0               1                          -100     25.1852            0.330097\n",
       "15       0.899408                    2.12591e-06        0        1.11184            0                8.64493e-06  0.434211                    0.462518            0               1                          -100     11.1842            0.165049\n",
       "16       1                           5.2036e-09         0        1                  0                4.96349e-07  0.390533                    0.415993            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.020990264936718173\n",
       "RMSE: 0.14488017440877884\n",
       "LogLoss: 0.07440846452623437\n",
       "Mean Per-Class Error: 0.0220856102003643\n",
       "AUC: 0.9972677595628415\n",
       "AUCPR: 0.9954183934389053\n",
       "Gini: 0.994535519125683\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.9180893861463741\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  ----------\n",
       "democrat    60          1             0.0164   (1.0/61.0)\n",
       "republican  1           35            0.0278   (1.0/36.0)\n",
       "Total       61          36            0.0206   (2.0/97.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.918089     0.972222  32\n",
       "max f2                       0.339591     0.983607  35\n",
       "max f0point5                 0.986962     0.97561   28\n",
       "max accuracy                 0.918089     0.979381  32\n",
       "max precision                1            1         0\n",
       "max recall                   0.339591     1         35\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.918089     0.955829  32\n",
       "max min_per_class_accuracy   0.918089     0.972222  32\n",
       "max mean_per_class_accuracy  0.918089     0.977914  32\n",
       "max tns                      1            61        0\n",
       "max fns                      1            35        0\n",
       "max fps                      5.53105e-08  61        91\n",
       "max tps                      0.339591     36        35\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.972222  0\n",
       "max fpr                      5.53105e-08  1         91\n",
       "max tpr                      0.339591     1         35\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 37.11 %, avg score: 38.78 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift     cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain     cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  -------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  -------  -----------------  --------------------\n",
       "1        0.0103093                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0277778                  169.444  169.444            0.0277778\n",
       "2        0.0206186                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0555556                  169.444  169.444            0.0555556\n",
       "3        0.0309278                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.0833333                  169.444  169.444            0.0833333\n",
       "4        0.0412371                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.111111                   169.444  169.444            0.111111\n",
       "5        0.0515464                   1                  2.69444  2.69444            1                1            1                           1                   0.0277778       0.138889                   169.444  169.444            0.138889\n",
       "6        0.103093                    0.999999           2.69444  2.69444            1                1            1                           1                   0.138889        0.277778                   169.444  169.444            0.277778\n",
       "7        0.154639                    0.999999           2.69444  2.69444            1                0.999999     1                           0.999999            0.138889        0.416667                   169.444  169.444            0.416667\n",
       "8        0.206186                    0.99998            2.69444  2.69444            1                0.999995     1                           0.999998            0.138889        0.555556                   169.444  169.444            0.555556\n",
       "9        0.298969                    0.994646           2.69444  2.69444            1                0.999129     1                           0.999728            0.25            0.805556                   169.444  169.444            0.805556\n",
       "10       0.402062                    0.253277           1.88611  2.48718            0.7              0.824634     0.923077                    0.954832            0.194444        1                          88.6111  148.718            0.95082\n",
       "11       0.505155                    0.00277465         0        1.97959            0                0.0363933    0.734694                    0.767396            0               1                          -100     97.9592            0.786885\n",
       "12       0.597938                    0.000687246        0        1.67241            0                0.00121352   0.62069                     0.648505            0               1                          -100     67.2414            0.639344\n",
       "13       0.701031                    0.000113003        0        1.42647            0                0.000334153  0.529412                    0.553186            0               1                          -100     42.6471            0.47541\n",
       "14       0.793814                    2.13585e-05        0        1.25974            0                5.1168e-05   0.467532                    0.488534            0               1                          -100     25.974             0.327869\n",
       "15       0.896907                    5.92055e-06        0        1.11494            0                1.37787e-05  0.413793                    0.432382            0               1                          -100     11.4943            0.163934\n",
       "16       1                           5.53105e-08        0        1                  0                7.31785e-07  0.371134                    0.387807            0               1                          -100     0                  0\n",
       "\n",
       "ModelMetricsBinomial: deeplearning\n",
       "** Reported on cross-validation data. **\n",
       "\n",
       "MSE: 0.021493619957376083\n",
       "RMSE: 0.14660702560715186\n",
       "LogLoss: 0.08252652068703364\n",
       "Mean Per-Class Error: 0.02213886437187408\n",
       "AUC: 0.9952191821123859\n",
       "AUCPR: 0.9931319371015339\n",
       "Gini: 0.9904383642247718\n",
       "\n",
       "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4018719239414743\n",
       "            democrat    republican    Error    Rate\n",
       "----------  ----------  ------------  -------  -----------\n",
       "democrat    200         6             0.0291   (6.0/206.0)\n",
       "republican  2           130           0.0152   (2.0/132.0)\n",
       "Total       202         136           0.0237   (8.0/338.0)\n",
       "\n",
       "Maximum Metrics: Maximum metrics at their respective thresholds\n",
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.401872     0.970149  129\n",
       "max f2                       0.401872     0.978916  129\n",
       "max f0point5                 0.919161     0.974026  114\n",
       "max accuracy                 0.401872     0.976331  129\n",
       "max precision                1            1         0\n",
       "max recall                   0.00269919   1         175\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.401872     0.950839  129\n",
       "max min_per_class_accuracy   0.424832     0.970874  128\n",
       "max mean_per_class_accuracy  0.401872     0.977861  129\n",
       "max tns                      1            206       0\n",
       "max fns                      1            131       0\n",
       "max fps                      1.72743e-09  206       325\n",
       "max tps                      0.00269919   132       175\n",
       "max tnr                      1            1         0\n",
       "max fnr                      1            0.992424  0\n",
       "max fpr                      1.72743e-09  1         325\n",
       "max tpr                      0.00269919   1         175\n",
       "\n",
       "Gains/Lift Table: Avg response rate: 39.05 %, avg score: 39.05 %\n",
       "group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov\n",
       "-------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------\n",
       "1        0.0118343                   0.999999           2.56061    2.56061            1                0.999999     1                           0.999999            0.030303        0.030303                   156.061   156.061            0.030303\n",
       "2        0.0207101                   0.999997           2.56061    2.56061            1                0.999998     1                           0.999999            0.0227273       0.0530303                  156.061   156.061            0.0530303\n",
       "3        0.0325444                   0.999995           2.56061    2.56061            1                0.999996     1                           0.999998            0.030303        0.0833333                  156.061   156.061            0.0833333\n",
       "4        0.0414201                   0.999991           2.56061    2.56061            1                0.999993     1                           0.999997            0.0227273       0.106061                   156.061   156.061            0.106061\n",
       "5        0.0502959                   0.999981           2.56061    2.56061            1                0.999986     1                           0.999995            0.0227273       0.128788                   156.061   156.061            0.128788\n",
       "6        0.100592                    0.999877           2.56061    2.56061            1                0.999934     1                           0.999964            0.128788        0.257576                   156.061   156.061            0.257576\n",
       "7        0.150888                    0.999433           2.56061    2.56061            1                0.999713     1                           0.99988             0.128788        0.386364                   156.061   156.061            0.386364\n",
       "8        0.201183                    0.997379           2.56061    2.56061            1                0.998734     1                           0.999594            0.128788        0.515152                   156.061   156.061            0.515152\n",
       "9        0.301775                    0.982686           2.48529    2.5355             0.970588         0.991573     0.990196                    0.99692             0.25            0.765152                   148.529   153.55             0.760297\n",
       "10       0.399408                    0.406464           2.17264    2.4468             0.848485         0.835108     0.955556                    0.957366            0.212121        0.977273                   117.264   144.68             0.948147\n",
       "11       0.5                         0.00561167         0.150624   1.98485            0.0588235        0.0772373    0.775148                    0.780299            0.0151515       0.992424                   -84.9376  98.4848            0.807958\n",
       "12       0.600592                    0.00103974         0.0753119  1.66502            0.0294118        0.00270133   0.650246                    0.650061            0.00757576      1                          -92.4688  66.5025            0.65534\n",
       "13       0.698225                    0.00027113         0          1.4322             0                0.000614409  0.559322                    0.559248            0               1                          -100      43.2203            0.495146\n",
       "14       0.798817                    4.5804e-05         0          1.25185            0                0.000139101  0.488889                    0.488842            0               1                          -100      25.1852            0.330097\n",
       "15       0.899408                    2.167e-06          0          1.11184            0                1.37262e-05  0.434211                    0.43417             0               1                          -100      11.1842            0.165049\n",
       "16       1                           0                  0          1                  0                5.32647e-07  0.390533                    0.390497            0               1                          -100      0                  0\n",
       "\n",
       "Cross-Validation Metrics Summary: \n",
       "                         mean         sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid     cv_9_valid    cv_10_valid\n",
       "-----------------------  -----------  -----------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------  ------------  -------------\n",
       "accuracy                 0.9870508    0.01724293   0.9714286     0.9591837     1.0           1.0           0.9756098     0.96428573    1.0           1.0            1.0           1.0\n",
       "aic                      nan          0.0          nan           nan           nan           nan           nan           nan           nan           nan            nan           nan\n",
       "auc                      0.9964746    0.004768888  0.9907407     0.9897959     1.0           1.0           0.98941797    0.9947917     1.0           1.0            1.0           1.0\n",
       "err                      0.012949228  0.01724293   0.028571429   0.040816326   0.0           0.0           0.024390243   0.035714287   0.0           0.0            0.0           0.0\n",
       "err_count                0.5          0.70710677   1.0           2.0           0.0           0.0           1.0           1.0           0.0           0.0            0.0           0.0\n",
       "f0point5                 0.97838205   0.03332415   0.90909094    0.95238096    1.0           1.0           0.9848485     0.9375        1.0           1.0            1.0           1.0\n",
       "f1                       0.981652     0.02434257   0.9411765     0.95238096    1.0           1.0           0.962963      0.96          1.0           1.0            1.0           1.0\n",
       "f2                       0.98536265   0.02198311   0.9756098     0.95238096    1.0           1.0           0.942029      0.9836066     1.0           1.0            1.0           1.0\n",
       "lift_top_group           2.6806576    0.6947111    4.375         2.3333333     2.6363637     2.4166667     2.9285715     2.3333333     2.0           2.1764705      3.2222223     2.3846154\n",
       "loglikelihood            nan          0.0          nan           nan           nan           nan           nan           nan           nan           nan            nan           nan\n",
       "---                      ---          ---          ---           ---           ---           ---           ---           ---           ---           ---            ---           ---\n",
       "mcc                      0.9718372    0.037061352  0.9251849     0.9166667     1.0           1.0           0.9462601     0.93026054    1.0           1.0            1.0           1.0\n",
       "mean_per_class_accuracy  0.9872851    0.0173667    0.9814815     0.9583333     1.0           1.0           0.96428573    0.96875       1.0           1.0            1.0           1.0\n",
       "mean_per_class_error     0.012714947  0.0173667    0.018518519   0.041666668   0.0           0.0           0.035714287   0.03125       0.0           0.0            0.0           0.0\n",
       "mse                      0.019818382  0.016164107  0.034063715   0.04420374    0.0053408407  0.019085221   0.0354519     0.034469232   0.01485624    0.00032788806  7.368074e-05  0.010311363\n",
       "pr_auc                   0.9933923    0.010527349  0.96858567    0.9883384     1.0           1.0           0.98366904    0.99332976    1.0           1.0            1.0           1.0\n",
       "precision                0.97643465   0.040793747  0.8888889     0.95238096    1.0           1.0           1.0           0.9230769     1.0           1.0            1.0           1.0\n",
       "r2                       0.9123107    0.074314825  0.80681455    0.8195014     0.9773149     0.92132026    0.8423422     0.8592506     0.94057506    0.99867976     0.9996557     0.9576529\n",
       "recall                   0.9880952    0.025717225  1.0           0.95238096    1.0           1.0           0.9285714     1.0           1.0           1.0            1.0           1.0\n",
       "rmse                     0.12301089   0.07216264   0.18456358    0.21024686    0.073081054   0.13814928    0.18828675    0.18565892    0.12188618    0.01810768     0.008583749   0.10154489\n",
       "specificity              0.9864749    0.022910964  0.962963      0.96428573    1.0           1.0           1.0           0.9375        1.0           1.0            1.0           1.0\n",
       "[22 rows x 13 columns]\n",
       "\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_r2    validation_auc    validation_pr_auc    validation_lift    validation_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------  -----------------  --------------------  ---------------  ----------------  -------------------  -----------------  ---------------------------------\n",
       "    2025-05-26 14:49:20  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan                              nan                nan                   nan              nan               nan                  nan                nan\n",
       "    2025-05-26 14:49:20  2.221 sec   4970 obs/sec      1         1             338        0.149959         0.0751439           0.90552        0.997095        0.995592           2.56061          0.0236686                        0.131615           0.058884              0.92578          0.998634          0.997835             2.69444            0.0103093\n",
       "    2025-05-26 14:49:20  2.315 sec   4567 obs/sec      2         2             676        0.141384         0.0718852           0.916017       0.996948        0.995114           2.56061          0.0207101                        0.140997           0.0648132             0.914822         0.998179          0.997053             2.69444            0.0206186\n",
       "    2025-05-26 14:49:21  2.409 sec   4466 obs/sec      3         3             1014       0.132497         0.0600974           0.926243       0.998088        0.996843           2.56061          0.0147929                        0.138685           0.0597066             0.917592         0.997723          0.996101             2.69444            0.0206186\n",
       "    2025-05-26 14:49:21  2.507 sec   4347 obs/sec      4         4             1352       0.12579          0.0544589           0.933521       0.997904        0.996574           2.56061          0.0177515                        0.159284           0.0947178             0.891293         0.995902          0.993299             2.69444            0.0206186\n",
       "    2025-05-26 14:49:21  2.598 sec   4344 obs/sec      5         5             1690       0.137266         0.0629276           0.920838       0.998235        0.997331           2.56061          0.0207101                        0.153845           0.0802435             0.898591         0.996812          0.994365             2.69444            0.0206186\n",
       "    2025-05-26 14:49:21  2.691 sec   4342 obs/sec      6         6             2028       0.120367         0.0471079           0.939129       0.99886         0.998261           2.56061          0.0177515                        0.157438           0.0790773             0.893798         0.998634          0.997651             2.69444            0.0103093\n",
       "    2025-05-26 14:49:21  2.783 sec   4333 obs/sec      7         7             2366       0.124925         0.0527575           0.934432       0.999228        0.998812           2.56061          0.0147929                        0.14131            0.0628661             0.914443         0.997268          0.995984             2.69444            0.0103093\n",
       "    2025-05-26 14:49:21  2.879 sec   4305 obs/sec      8         8             2704       0.1134           0.0452435           0.945972       0.998713        0.998171           2.56061          0.0147929                        0.168295           0.1141                0.878646         0.995446          0.992417             2.69444            0.0206186\n",
       "    2025-05-26 14:49:21  2.973 sec   4296 obs/sec      9         9             3042       0.12247          0.0504858           0.936984       0.99875         0.998092           2.56061          0.0177515                        0.185595           0.134617              0.852414         0.995902          0.993299             2.69444            0.0206186\n",
       "    2025-05-26 14:49:21  3.067 sec   4289 obs/sec      10        10            3380       0.132904         0.0589529           0.925789       0.999412        0.999078           2.56061          0.00887574                       0.14488            0.0744085             0.910065         0.997268          0.995418             2.69444            0.0206186\n",
       "\n",
       "Variable Importances: \n",
       "variable                                            relative_importance    scaled_importance    percentage\n",
       "--------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "physician-fee-freeze.y                              1.0                    1.0                  0.023379555016416732\n",
       "physician-fee-freeze.?                              0.9718586206436157     0.9718586206436157   0.02272162208951629\n",
       "synfuels-corporation-cutback.n                      0.9706545472145081     0.9706545472145081   0.022693471388536664\n",
       "adoption-of-the-budget-resolution.?                 0.9601864814758301     0.9601864814758301   0.022448732669683776\n",
       "religious-groups-in-schools.n                       0.9581098556518555     0.9581098556518555   0.022400182081983647\n",
       "physician-fee-freeze.n                              0.9574403762817383     0.9574403762817383   0.02238452995221764\n",
       "superfund-right-to-sue.n                            0.9554620981216431     0.9554620981216431   0.022338278689135915\n",
       "handicapped-infants.y                               0.9485031366348267     0.9485031366348267   0.022175581266197765\n",
       "aid-to-nicaraguan-contras.y                         0.9451934695243835     0.9451934695243835   0.022098202721903135\n",
       "education-spending.n                                0.9410557746887207     0.9410557746887207   0.022001465257851613\n",
       "---                                                 ---                    ---                  ---\n",
       "anti-satellite-test-ban.missing(NA)                 0.0                    0.0                  0.0\n",
       "aid-to-nicaraguan-contras.missing(NA)               0.0                    0.0                  0.0\n",
       "mx-missile.missing(NA)                              0.0                    0.0                  0.0\n",
       "immigration.missing(NA)                             0.0                    0.0                  0.0\n",
       "synfuels-corporation-cutback.missing(NA)            0.0                    0.0                  0.0\n",
       "education-spending.missing(NA)                      0.0                    0.0                  0.0\n",
       "superfund-right-to-sue.missing(NA)                  0.0                    0.0                  0.0\n",
       "crime.missing(NA)                                   0.0                    0.0                  0.0\n",
       "duty-free-exports.missing(NA)                       0.0                    0.0                  0.0\n",
       "export-administration-act-south-africa.missing(NA)  0.0                    0.0                  0.0\n",
       "[64 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "run_experiment(dataset=votes, features=features, target=target, hidden=[100,100,100], nfolds=10, activation=\"tanh\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f0f7247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| Activation Function   | Cross Validation   | Hidden Layers   | Training Error %                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Validation Error %                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | Cross Validation Mean Error %                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Training Time   |\n",
      "+=======================+====================+=================+=======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+=======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+=======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================+=================+\n",
      "| rectifier             | None               | [5, 5, 5]       | [[0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484], [0.47264731686597217, 0.024566048837893484]]% | [[0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677], [0.30527271696447134, 0.030282331511839677]]% | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0.558 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | None               | [20, 20, 20]    | [[0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645], [0.6217807910813363, 0.01349661665195645]]%                                                                                                                                                                                                         | [[0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437], [0.6199494827109913, 0.02208561020036437]]%                                                                                                                                                                                                         | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0.419 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | None               | [100, 100, 100] | [[0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465], [0.8012458466893759, 0.01971167990585465]]%                                                                                                                                                                                                         | [[0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884], [0.8748662997053561, 0.01388888888888884]]%                                                                                                                                                                                                         | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0.946 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | 5-folds            | [5, 5, 5]       | [[0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067]]%                                                                                                     | [[0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677]]%                                                                                                     | [[0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645], [0.6758263066539283, 0.0535083848190645]]%                                                                                                                                                                                                                                                                                                             | 0.271 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | 5-folds            | [20, 20, 20]    | [[0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082]]%                                                                                                     | [[0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437]]%                                                                                                                                                                                                                                                                                                                                                                                                                 | [[0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765], [0.22126370768862047, 0.04883789349808765]]%                                                                                                     | 0.372 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | 5-folds            | [100, 100, 100] | [[0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666], [0.9625960973110883, 0.009708737864077666]]%                                                                                                     | [[0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838], [0.7588237642672655, 0.016393442622950838]]%                                                                                                     | [[0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111], [0.19840922521394078, 0.0332082965578111]]%                                                                                                                                                                                                         | 0.855 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | 10-folds           | [5, 5, 5]       | [[0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067], [0.4651299332629031, 0.022138864371874067]]%                                                                                                     | [[0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677], [0.2668740561060711, 0.030282331511839677]]%                                                                                                     | [[0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755], [0.32908119382314016, 0.04670491320976755]]%                                                                                                     | 0.241 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | 10-folds           | [20, 20, 20]    | [[0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082], [0.3643252864977982, 0.012135922330097082]]%                                                                                                     | [[0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437], [0.55041510917735, 0.02208561020036437]]%                                                                                                                                                                                                                                                                                                                                                                                                                 | [[0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115], [0.28813296823683565, 0.03427478670197115]]%                                                                                                     | 0.287 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| rectifier             | 10-folds           | [100, 100, 100] | [[0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617], [0.35701591035352204, 0.008642247719917617]]% | [[0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884], [0.81124600114364, 0.01388888888888884]]%                                                                                                                                                                                                                                                                                                                                                                                                                 | [[0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111], [0.2315598519990075, 0.0332082965578111]]%                                                                                                                                                                                                                                                                                                             | 0.895 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | None               | [5, 5, 5]       | [[0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818]]%                                                                                                     | [[0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884]]%                                                                                                                                                                                                         | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0.244 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | None               | [5, 5, 5]       | [[0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818], [0.5700888974598675, 0.014857310973815818]]%                                                                                                     | [[0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884], [0.6952516404269884, 0.01388888888888884]]%                                                                                                                                                                                                         | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0.224 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | None               | [20, 20, 20]    | [[0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603], [0.6693947349504704, 0.018645189761694603]]%                                                                                                     | [[0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677], [0.2640113037066277, 0.030282331511839677]]%                                                                                                     | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0.289 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | None               | [100, 100, 100] | [[0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804], [0.6304233638481587, 0.024860253015592804]]%                                                                                                     | [[0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884], [0.6765892901996935, 0.01388888888888884]]%                                                                                                                                                                                                         | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | 0.973 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | 5-folds            | [5, 5, 5]       | [[0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645]]%                                                                                                                                                                                                         | [[0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884]]%                                                                                                                                                                                                         | [[0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365], [0.2740680998715461, 0.030486907914092365]]%                                                                                                     | 0.241 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | 5-folds            | [20, 20, 20]    | [[0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034]]%                                                                                                     | [[0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437]]%                                                                                                                                                                                                         | [[0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809], [0.37223444271222816, 0.04321123859958809]]%                                                                                                     | 0.281 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | 5-folds            | [100, 100, 100] | [[0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867], [0.08438767889091867, 0.015923801117975867]]% | [[0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437], [0.13930074519982527, 0.02208561020036437]]%                                                                                                     | [[0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317], [0.19247125311646474, 0.029420417769932317]]% | 0.866 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | 10-folds           | [5, 5, 5]       | [[0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645], [0.4126378161683046, 0.01349661665195645]]%                                                                                                                                                                                                         | [[0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884], [0.5951267160204192, 0.01388888888888884]]%                                                                                                                                                                                                         | [[0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532], [0.3774709315100019, 0.025632538982053532]]%                                                                                                     | 0.253 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | 10-folds           | [20, 20, 20]    | [[0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034], [0.3079197538244427, 0.011069432185937034]]%                                                                                                     | [[0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437], [0.1662999056749567, 0.02208561020036437]]%                                                                                                                                                                                                         | [[0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005], [0.5718110822865685, 0.031075316269491005]]%                                                                                                     | 0.352 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n",
      "| tanh                  | 10-folds           | [100, 100, 100] | [[0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249], [0.7563318232968509, 0.007281553398058249]]%                                                                                                     | [[0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437], [0.9180893861463741, 0.02208561020036437]]%                                                                                                                                                                                                         | [[0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067], [0.4018719239414743, 0.022138864371874067]]%                                                                                                     | 0.945 s         |\n",
      "+-----------------------+--------------------+-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from IPython.display import Markdown, display, HTML\n",
    "headers = [\"Activation Function\", \"Cross Validation\", \"Hidden Layers\", \"Training Error %\", \"Validation Error %\", \"Cross Validation Mean Error %\", \"Training Time\"]\n",
    "#print(metrics)\n",
    "print(tabulate(mean_error_metrics, headers=headers, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d4abe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| Activation Function   | Cross Validation   | Hidden Layers   |   Training Mean Square Error |   Validation Mean Square Error | Cross Validation Mean Square Error   |\n",
      "+=======================+====================+=================+==============================+================================+======================================+\n",
      "| rectifier             | None               | [5, 5, 5]       |                    0.0248412 |                      0.0322698 | -                                    |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | None               | [20, 20, 20]    |                    0.0145144 |                      0.0254836 | -                                    |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | None               | [100, 100, 100] |                    0.0212235 |                      0.0174329 | -                                    |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | 5-folds            | [5, 5, 5]       |                    0.0235707 |                      0.03137   | 0.045365285386998806                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | 5-folds            | [20, 20, 20]    |                    0.0124804 |                      0.0249778 | 0.03850106687593611                  |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | 5-folds            | [100, 100, 100] |                    0.0375987 |                      0.0273102 | 0.030483246542344196                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | 10-folds           | [5, 5, 5]       |                    0.0235707 |                      0.03137   | 0.040075001035739556                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | 10-folds           | [20, 20, 20]    |                    0.0124804 |                      0.0249778 | 0.03196380751758517                  |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| rectifier             | 10-folds           | [100, 100, 100] |                    0.0103934 |                      0.0111146 | 0.030805097823323052                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | None               | [5, 5, 5]       |                    0.0154889 |                      0.0138909 | -                                    |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | None               | [5, 5, 5]       |                    0.0154889 |                      0.0138909 | -                                    |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | None               | [20, 20, 20]    |                    0.0158948 |                      0.0236703 | -                                    |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | None               | [100, 100, 100] |                    0.0224878 |                      0.0173224 | -                                    |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | 5-folds            | [5, 5, 5]       |                    0.0149842 |                      0.0145375 | 0.03209160930097024                  |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | 5-folds            | [20, 20, 20]    |                    0.0135916 |                      0.0250369 | 0.034726718350793405                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | 5-folds            | [100, 100, 100] |                    0.0149989 |                      0.0344456 | 0.025870828321756082                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | 10-folds           | [5, 5, 5]       |                    0.0149842 |                      0.0145375 | 0.02516950720561065                  |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | 10-folds           | [20, 20, 20]    |                    0.0135916 |                      0.0250369 | 0.027379532890430474                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n",
      "| tanh                  | 10-folds           | [100, 100, 100] |                    0.0176635 |                      0.0209903 | 0.021493619957376083                 |\n",
      "+-----------------------+--------------------+-----------------+------------------------------+--------------------------------+--------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = [\"Activation Function\", \"Cross Validation\", \"Hidden Layers\", \"Training Mean Square Error\", \"Validation Mean Square Error\", \"Cross Validation Mean Square Error\"]\n",
    "\n",
    "print(tabulate(mse_metrics, headers=headers, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43d48e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| Activation Function   | Cross Validation   | Hidden Layers   |   Training Root Mean Square Error |   Validation Root Mean Square Error | Cross Validation Root Mean Square Error   |\n",
      "+=======================+====================+=================+===================================+=====================================+===========================================+\n",
      "| rectifier             | None               | [5, 5, 5]       |                          0.157611 |                            0.179638 | -                                         |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | None               | [20, 20, 20]    |                          0.120476 |                            0.159636 | -                                         |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | None               | [100, 100, 100] |                          0.145683 |                            0.132034 | -                                         |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | 5-folds            | [5, 5, 5]       |                          0.153527 |                            0.177116 | 0.21299128007267998                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | 5-folds            | [20, 20, 20]    |                          0.111716 |                            0.158044 | 0.19621688733627415                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | 5-folds            | [100, 100, 100] |                          0.193904 |                            0.165258 | 0.17459452036746226                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | 10-folds           | [5, 5, 5]       |                          0.153527 |                            0.177116 | 0.2001874147786008                        |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | 10-folds           | [20, 20, 20]    |                          0.111716 |                            0.158044 | 0.1787842485164316                        |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| rectifier             | 10-folds           | [100, 100, 100] |                          0.101948 |                            0.105426 | 0.1755138109190358                        |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | None               | [5, 5, 5]       |                          0.124454 |                            0.11786  | -                                         |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | None               | [5, 5, 5]       |                          0.124454 |                            0.11786  | -                                         |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | None               | [20, 20, 20]    |                          0.126075 |                            0.153851 | -                                         |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | None               | [100, 100, 100] |                          0.149959 |                            0.131615 | -                                         |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | 5-folds            | [5, 5, 5]       |                          0.12241  |                            0.120572 | 0.17914131098373218                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | 5-folds            | [20, 20, 20]    |                          0.116583 |                            0.15823  | 0.18635106211340305                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | 5-folds            | [100, 100, 100] |                          0.12247  |                            0.185595 | 0.16084411186535888                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | 10-folds           | [5, 5, 5]       |                          0.12241  |                            0.120572 | 0.1586490063177537                        |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | 10-folds           | [20, 20, 20]    |                          0.116583 |                            0.15823  | 0.16546761885768005                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n",
      "| tanh                  | 10-folds           | [100, 100, 100] |                          0.132904 |                            0.14488  | 0.14660702560715186                       |\n",
      "+-----------------------+--------------------+-----------------+-----------------------------------+-------------------------------------+-------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "headers = [\"Activation Function\", \"Cross Validation\", \"Hidden Layers\", \"Training Root Mean Square Error\", \"Validation Root Mean Square Error\", \"Cross Validation Root Mean Square Error\"]\n",
    "\n",
    "print(tabulate(rmse_metrics, headers=headers, tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
